For clarity, maybe explicitly write the proposed python interface here?
there is no ',' at the end, is this intentional?
Thanks for being this careful. I added the coma.
Good idea! Added the interface.
maybe extract a function to print the list and reuse with the case of '()' below? Could also make it a bit functional by first construct a slice of stringyfied  components and use strings.join https://golang.org/pkg/strings/#Join. I don't feel strongly though.
we probably don't need to export these variables to subprocess. could just remove the 2 'export' keywords
为什么要把TRAIN放在SELECT之前呢？和放在SELECT之后相比有什么好处吗？
From the following description, there is nothing related to scheduling. Do you mean extended SQL executor/runner instead of scheduler?
I see no metadata in train.json. Do you mean SQL_PARSING_RESULT_FILE? 
It seems that we should pass in SQL engine connection information via command line options?
scheduler.py => runner.py
这是获取select query的结果并且全部放进内存？日后我们需要改成有个 TensorFlow Dataset operator（比如叫 ODBC DatasetOp）对吧？
feature columns 应该是从 COLUMN clause 得到的，不是从 fields。
get_model => create_estimator
前面我看到 METADATA_FILE=train.json。这里为什么inference 的 metadata 也存在 train.json 里？
我理解这样一系列的docker run命令恐怕不能算是scaffold。脚手架应该勾勒出最终的用户使用流程，只是其中有些环节的实现可以简化。

作为scaffold，我想首先得想清楚用户如何输入SQL语句，如何看到结果。至于其中的步骤，不论训练得到的模型文件是放在文件系统里，还是encode之后放进一个RDBMA table里，我觉得一开始是可以随意的——用一种能快速实现的方式即可。
我脑海中有三种可能的方式让用户和SQLFlow系统交互（可能有更多更好的选择）：

1. 一个命令行工具 sqlflow，类似mysql命令，允许用户输入SQL statements，并且调用 goyacc 生成的parser，parsing result输出成JSON。通过检查JSON里的内容，得知这个statement是否是标准SQL statement。如果是，则proxy给mysql，并且利用bash pipe截获mysql进程的stdin、stdout、stderr，并且显示在 sqlflow 的控制台上。

1. 一个Web 页面，后面接 mysql。

1. 在JupyterNotebook里允许用户写扩展SQL语法的SQL语句。那么我们得提供一个Go或者Python写的interpreter，供JupyterNotebook调用。这个interpreter后面还是得接mysql和我们的parser。其实这个interpreter就是1.中的 sqlflow。
我原来脑海中考虑的思路是2，其中 Web server 用Go写，是因为Go适合写Web server，所以比较容易实现上述方案2。这个Go server 可以通过本地函数调用的方式调用 Go写的parser，结果输出成 JSON，pipe 给一个Python 进程。这个Python进程执行 @tonyyang-svail 写的一个 runner 程序。

不过最近既然说要支持JupyterNotebook，那么可能得走方案3.，也就是需要方案1.
这个Go Web server和Python解释器以及mysql程序都运行在同一个Docker container里。因为 runner程序调用TensorFlow，所以这个Docker image里得有 mysql 和 TensorFlow。
我希望把MySQL server（mysqld）和SQLFlow 运行在两个不同的containers里，是希望展示SQLFlow 和具体SQL engine（如MySQL）是解耦的。
是全部放入内存。我们要对整个dataset做shuffle，我没想到其他的方法。
当然最好是从COLUMN clause。但是当前的语法并没有指出哪几个field是X，哪几个field是Y（label）。

```sql
SELECT employee.age, last_name, salary
FROM   employee
LIMIT  100
WHERE
  employee.age % 10 < (salary / 10000)
  AND
  strings.Upper(last_name) = "WANG"
TRAIN DNNClassifier
WITH
  n_classes = 3,
  hidden_units = [10, 20]
COLUMN
  employee.name,
  bucketize(last_name, 1000),
  cross(embedding(emplyoee.name), bucketize(last_name, 1000))
INTO
  my_dnn_model
;
```

我的初步想法是默认select出来的table的前 n - 1列是X，最后一列是Y
Yes, it should be renamed to SQL_PARSING_RESULT_FILE.
"extended SQL runner" is a better name.
上面这个SQL语句是非法的，因为 COLUMN 里用到的 employee.name 没有出现在SELECT 后面。只是我们的parser现在还没有做这类检查，不过肯定是要加上的。无论如何，feature column 调用是得依据 COLUMN clause的内容，而不是 SELECT clause 里的。实际上，我们的parser还得运行一个 DESCRIBE employee 命令来获取每个 field 的type，从而推断出field data type，以决定调用哪个feature column API函数。
Please also check `assert.Equal([]string{"*"}, parseResult.fields)`
According to 

https://github.com/wangkuiyi/sqlflow/blob/b7ee49d4e087cb6beeab4fbf58af4dabce39da53/sql/sql.y#L176-L177

we are supposed to test that `len(parseResult.fields)==0`.
If we are going to use columnType in the execution of the template, I am not sure but am afraid that we might need to write

```go
ColumnTypes columnTypes
```
connectionConfig => mysql.Config
My intention is that users could write attributes with the prefix `train.` in `WITH` to specify parameters to `tf.Estimator.train`.  Those attributes without the `train.` prefix are parameters of the Estimator constructor.  

For example, in the following SELECT statement

```sql
WITH
   train.step = 1000
```

Similarly, we might write

```sql
WITH
   train_input.batch_size = 32
```

Not sure if my intention is a good choice. Just write it down for your reference.
I guess we do not need to import json now.
I am not sure but it seems that this section duplicates with the `init` defined in `verifier_test.go`. Please be aware that `verifier_test.go` and `code_generator_test.go` are in the same package.
I suppose that currently we can only handle cases like

```
COLUMN numeric_field, another_numeric_field, ...
```

but not cases having categorical features and feature functions like `cross`

```
COLUMN a_string_typed_field, cross(a_field, another_field), ...
```

Am I correct?
Good point to have this section added.

I realized that gorm is not working with `DESCRIBE table`; instead, the standard `database/sql` package works. So I am wondering we don't need gorm.
I noticed that `mysql.Config.FormatDSN` is convenient.

```go
	testConfig = &mysql.Config{
		User:   "root",
		Passwd: "root",
		Addr:   "localhost:3306",
	}
       db, e := sql.Open("mysql", testConfig.FormatDSN())
       if e != nil {
           log.Fatal(e)
       }
       defer db.Close()
```
Changed the doc to using `database/sql` only
done
correct
got it. Will remove it in the next PR.
are `testCfg` and `testBD` the same instances as in `db_test.go`?
assuming `r.rows` only has 4 bytes, does `Scan` automatically resize `r.buf`'s length to 4?
No, they are not. `sql` and `sql/sqlfile` are two different Go packages.
Good question! In short, yes.

For more information, slice is kind of a "smart" pointer, whose definition is here:

https://github.com/golang/go/blob/47df645473210267fd7512c5b92de00908198974/src/runtime/slice.go#L13-L17

As you can see, a slice is a pointer plus two integers -- len and cap.  It looks to me that Scan would allocate a buffer for the field whose type is BLOB and let `r.buf->array` points to this buffer.
do we need to allocate a backing array for the slice? i think below in scan(), it will reassign buf anyway. can you change this line to buf: []byte and run the test?
using file analogy, the existence of the table alone doesn't tell us if the "file" exists. the 'file' exists if any only if the tale exists and in the table there is a 'block' column. we could use information_schema meta table to do the check:
https://dev.mysql.com/doc/refman/8.0/en/information-schema.html
the we don't need to hard code the error number here.
 
usually it is better to build on an ORM instead of constructing queries from raw input strings to avoid SQL injection attack. e.g. use this http://gorm.io/ . current implementation is ok if we don't need to worry about SQL injection.  
The variable assert shadows the package name assert.
The comment of lexer is about a type, but not the package.
The type item is not used.
I should have been using NoError instead of Nil for checking errors.
ignore is never used.
Unify the convention of creating a from assert.New.
In double-quoted string constants, the percentage sign has to be escaped as `%%`.  Or, we could use backquotes.
All returned errors must be checked.
Check returned error.
Use short variables, while keeping variable definitions near to where they are used.
do we need to check `e` from `db.Close()`
Yes. The idea here is to by assigning the recovered error to the return value, we return the error, if there is any, for the callers to check.
Just for curiosity, why do we need `--network=host` here?
How about we use a well-known and well-maintained image like `tensorflow/tensorflow:1.12.0" here instead of our own?
great point!
A training job requires loading data from mysql server. In our case, our server is bind to localhost, so I exposed the localhost to the container. Please let me know if there are other work around.
we still need `sqlflow` because `tensorflow` image doesn't have `python`'s `mysql.connector`
`ContainsAny` => `Contains`
I am not sure if it is legal to return a pointer pointing to an on-stack variable -- text is allocated in the stack frame, which will be popped after the function call.
You might want to have a look at https://github.com/wangkuiyi/sqlflow/pull/78, which further simplified the API, so no need to return a buffer, and is more Go idiotic -- it doesn't assume that the writer must be a bytes.Buffer.
We can write the unit test as 


```go
pr, pw := io.Pipe()
cmd := tensorflowCmd()
cmd.Stdin = pr
generateCode(pw, ...)
cmd.Run()
```

Please be aware that there could be no bytes.Buffer at all.
> I am not sure if it is legal to return a pointer pointing to an on-stack variable -- text is allocated in the stack frame, which will be popped after the function call.

pointer escape analysis is a feature of Golang. https://stackoverflow.com/questions/13715237/return-pointer-to-local-struct
> You might want to have a look at #78, which further simplified the API, so no need to return a buffer, and is more Go idiotic -- it doesn't assume that the writer must be a bytes.Buffer.

followed design in #78 
maybe add `func hasPythonMyConnector` due to https://github.com/wangkuiyi/sqlflow/pull/72#discussion_r236506236
Thanks for the reminder! Fixed it.
What https://github.com/wangkuiyi/jupyterbroker needs is an HTTP handler function like the following

```go
func ProcessRunnerHandler(rw http.ResponseWriter, req *http.Request) 
```

To make this function easier to test, we might separate its body into two pieces

1. a `run` function, which is similar to this `executeTrain` function, but the input should be a SQL statement, and
1. the HTTP handler that calls the run function.
Remove comments before merging.
You might want to call `tensorflowCmd` defined in #76. It might be a good idea to merge #76 ASAP.
This function is too long. It seems it could be separated into small functions, which would be easier to test.
Done
Done.
Done.
Execute => run
Per our discussion, we do not expose "evaluation" to users via our extended SQL syntax.
executeTrain => train
Check if the checkpoint file is a YAML file. If it is, we can call Go's library to decode the content, other than using hacky regexp.
https://godoc.org/gopkg.in/yaml.v2
`defer db.Close()`
```go
func saveModel(....) (e error) {
...
        defer func() { e = db.Close() }()
```
Need to comment the fact that the filename rewrite rule is actually reversible.
```go
src, e := os.Open(filepath.Join(modelDir, f.Name()))
if e != nil {
    ....
}
defer func() { e = src.Close() }()
io.Copy(w, src)
```
defer func() { e = w.Close() }()
```go
run(sql string, cfg *mysql.Config, w io.Writer) error {
```
Done
Done.
I am afraid that I am making a too complicated comment. Let us simplify the work in this PR to be defining a `run` method.
Done
Not sure if we should use `defer` inside a loop. https://stackoverflow.com/questions/45617758/defer-in-the-loop-what-will-be-better
Done.
Done.
"-" means output the `tar`ed content to stdout
After abstracting `modelConfig` at `filler`, the original constructor give the following error
```
./codegen.go:53:3: cannot use promoted field modelConfig.StandardSelect in struct literal of type filler
./codegen.go:54:3: cannot use promoted field modelConfig.Estimator in struct literal of type filler
./codegen.go:55:3: cannot use promoted field modelConfig.Attrs in struct literal of type filler
./codegen.go:56:3: cannot use promoted field modelConfig.Save in struct literal of type filler
```
So I changed the initialization method
Why not using Go idiotic way of creating a struct variable?
dir => fn
Seem forgot to close the file.
We can write two lines instead of three and without messing the scope with unuseful variable e.

```go
if e := saveModelConfig(pr); e != nil {
    return e
}
```
For the record:
https://medium.com/golangspec/promoted-fields-and-methods-in-go-4e8d7aefb3e3

Fields and methods of anonymous (embedded) field are called promoted. They behave like regular fields but can’t be used in struct literals.
Good catch!
```go
r := &filler{
     modelConfig : &modelConfig{
        Estimator: pr.estimator,
```
Good catch!
👍 
```go
r := &filler{
   modelConfig : modelConfig{
     Estimator: pr.estimator
   ...
}
```
Done.
我感觉可以把tar过之后的TF model dir 作为 GOB 里的一个field，类型是[]byte。
SQLFlow = tar(TFModel) + len(sql) + sql + ...

而不是 

SQLFlow = tar(TFModel)
TFModel = TFModel + len(sql) + sql ...
Since we are writing model and the tared model directory into the same stream `sqlf`, how do we separate them when reading from `sqlf`?
```go
var m model
gob.NewDecoder(sqlf).Decode(&m)
Untar(sqlf, "/tmp/target_dir")
```

gob decoder knows how many bytes it should read into `&m`. The rest data will be read by `Untar`.
excellent.
Change the type of parseResult into a pointer. Not necessary, just making it slightly faster to refresh its value. Also removing the `&` in `&parseResult` for parameters of `verify` and `run`.
Better indentation using Emacs Go mode + yacc mode.
这样包装一层并没有解决其实有一个全局变量的问题。即使把parseResult调换一下，parsing 本身仍然不是 reentrant 的，只是后面的verification 和 codegen 可以流水作业起来。不过这个流水真正实现，得用go channel。

其实我又搜了一下，根据 goyacc 文档，我们应该可以写一个reentrant parser的。具体咋么做，我还得再看看。不过有如下信息：

https://godoc.org/golang.org/x/tools/cmd/goyacc 里说：

> The generated parser is reentrant. 

具体做法应该是要看明白最高层rule里的$$对应的变量存在哪儿了。文档里没有说，得看看 parser.go 的源码。我今晚看看。
好的。希望改成reentrant parser不会太麻烦。不行的话我们能否通过mutex来保证threadsafe？
我没有搞明白如何实现 reentrant parser，文档太不详尽了。我发了 https://github.com/tonyyang-svail/sqlflow/pull/1 来merge 到这个PR。用的办法是 mutex。
已merge
这里直接return了？
如果不给返回值赋值的话，这里可以写 `defer sqlf.Close()` 就足够，不需要 `func()` 了。但是如果这么写，gometalinter 会抱怨说 `sqlf.Close()` 的返回值没有被check或者用到。
Good catch!
Sorry for the late fixing of this issue. I tried today, but haven't found the reason yet.
对 verifyColumnTypes 要不要放在 verifier.go 里？—— 我也不确定，只是粗粗一想。
应该放在verifier里的，我想先写个skeleton出来，然后再挪位子。
The current approach is acceptable if we are working with small models. Maybe loop back to this FIXME when it becomes the bottle neck.
This is a leftover. I will remove it in the next PR.
Please consider the following snippet.
```go
func foo() (e error) {
	...

	defer func() { e = sqlf.Close() }

	...

	return fmt.Errorf("This error would be overwritten by sqlf.Close()")
}
```
`defer func() { e = sqlf.Close() }` will overwrite the original returned error.
明白了！赞发现！学到了。所以说，如果真要写全了，得是：

```go
defer func() {
    if err := sqlf.Close(); err != nil {
        if e != nil {
            e = fmt.Errorf("(1) %s; (2) %s", e, err)
        } else {
            e = err
        }
    }
}()
```

这样确实也太麻烦了，还不如不check error了。
如果传进来 db *sql.DB 而不是 cfg *mysql.Config 会不会总体减少 establish MySQL connections 的次数？
这里可否调用 sqlfs 的 createTable 和 dropTable 啥的？

https://github.com/wangkuiyi/sqlfs/blob/develop/writer.go#L90

貌似要改个名字 createTable => CreateTable

另外，确实应该把 sqlfs 挪回 sqlflow，独立成一个 repo 对 CI 没有帮助，因为CI 需要用 sqlflow 里的一个 MySQL container。

我先挪回来。再来做这些修改吧。这个 PR 可以先merge 了
是的，跑通一边了之后我来refactor吧。
嗯，挪回来吧。对于复用，跑通一边了之后我来refactor。
fmt.Fprintf(&b, “create table ...”)
For the long term we might add a concept *project*, which corresponds to a database, and make tables belongs to the project. Otherwise, if the CI runs two tests at the same time, they might create the same table simultaneously.
Added https://github.com/wangkuiyi/sqlflow/issues/138
trainSlct?
改名成TrainSelect了。
在这里 https://github.com/wangkuiyi/sqlflow/pull/156/files#diff-d77fda4265f0434c48d4fe6252700e7dR15，你把 Run 改成了返回两个values；但是在这里，你认为它只返回一个值。所以编译报错。类似的错误还有几处：

```
yi@WangYis-iMac:~/go/src/github.com/wangkuiyi/sqlflow/sql (fix_155)$ go test -c
# github.com/wangkuiyi/sqlflow/sql [github.com/wangkuiyi/sqlflow/sql.test]
./executor_test.go:12:11: multiple-value Run() in single-value context
./executor_test.go:20:11: multiple-value Run() in single-value context
./executor_test.go:28:11: multiple-value Run() in single-value context
```
赞同把这个函数移到 sql package 里！
对报错代码作了订正，是低级错误 : (
👍 
maybe change `"./sqlflow.log"` to a global constant variable.
`err` => `e`
We log an error if we can't handle it.

In the current line, we handle the error by returning it to the caller. And it is definitely possible the caller can gracefully handle the error, so no error should be logged.

However, we can add context information to the error message, the native way in golang is to use `fmt.Errorf` function to wrap it. This process effectively generates a trace:
```golang
return fmt.Errorf("[pred] load sqlflow models failed|error: %s", e)
```

I would suggest we do error logging only at the top level function `Run`, where we can conclude we can't deal with the error.

Similar reasoning.
如果要输出log到文件，得至少有一个commandline option，还得有生成默认文件路径的能力；否则unit tests 的时候多个instances可能写进同一个文件。
如果打不开文件，只是打印出错信息就可以了吗？还是应该 log.Panicf 呢？
如果在这一行之前panic了，这一行就不会被执行了。对日后分析log有影响吗？
只是日志文件无法打开，我认为不该影响正常流程执行。
这行日志，当前只记录正常执行的时间开销，暂不关心异常流程的时间开销
同意。加了两个逻辑:
1) command line option 支持设置日志目录 `-logdir=/path/to/log`
2) [日志文件名附带pid信息](https://github.com/wangkuiyi/sqlflow/pull/160/files/623bfade48c25b591f794d977f21ac71b86ce5f3..177e4aae4a955ab3fce01e038e675ff9f3dd7a3e)
返回的错误信息格式建议与上下保持一致，即无需 \n
等同于 `for i := range cols {`，小建议
Done.
Done.
Only use `go-fmt`, `go-lint` for now.
需要handle非row的返回值，比如"delete","insert"
Discussed offline, solved by https://github.com/wangkuiyi/sqlflowserver/issues/19
如果只是string，就用string好了，不需要定义新类型，尤其不需要struct Log
赞同
type Row {} interface 即可。不需要struct
这里要不要考虑把执行中产生的log messages也流给jupyter？我没有特别明确的倾向。可以日后改。
其实不仅仅是string，完整的应该是
```go
struct Log {
    log string
    err error
}
```
runExtendedSQL的error才能通过channel传过来。
sqlflow的Row是要expose出去给sqlflowserver的，我觉得`type Row {} interface`会使代码变得难读懂。
我们会支持stream给jupyter。这是102行的TODO。
Golang => Go
common assert mistake: `<stdin>:54: SyntaxWarning: assertion is always true, perhaps remove parentheses?`
类型还有更多
https://golang.org/pkg/database/sql/#Rows.Scan
@weiguoz 赞！我们是不是应该改回到 https://stackoverflow.com/a/17885636/6794675 的两层的interface{}？这样可以支持所有的type。还是我们先安全点只支持这几个type然后把整个全部跑通？这边先留一个TODO
同意，我们先往前走
Great TODO. 👍 
maybe add a few comments explaining possible data types.
The control flow look cumbersome to me. What if `e == nil` and `pr.extended == false`?

Try
```golang
func Run(slct string, db *sql.DB, cfg *mysql.Config) (Response, error) {
	slctUpper := strings.ToUpper(slct)
	if strings.Contains(slctUpper, "TRAIN") || strings.Contains(slctUpper, "PREDICT") {
		return runExtendedSQL(slct, db, cfg)
	}
	return runStandardSQL(slct, db)
}
```

and move `pr, e := newParser().Parse(slct)` into `runExtendedSQL`. Something like

```golang
func runExtendedSQL(slct string, db *sql.DB, cfg *mysql.Config) (Response, error) {
        ...
	go func() {
		...

		err := func() error {
			startAt := time.Now()
			log.Infof("Starting runExtendedSQL:%s", slct)

			pr, e := newParser().Parse(slct)
			if e != nil {
				return e
			}
			if !pr.extended {
				return fmt.Errorf("try to parse a non-extended SQL %v: %v", slct, pr)
			}
```

By doing so, we also avoided passing `pr` into `runExtendedSQL`
Looks like `error` is always `nil`. Please change to
```golang
func Run(slct string, db *sql.DB, cfg *mysql.Config) Response
```
For log consistency: move this log to `runExtendedSQL`, also add `log.Errorf("runStandardSQL error:%v", e)` in `runStandardSQL`
Looks like `error` is always `nil`.
Looks like `error` is always `nil`.
Not sure if we need to `make` all channels. What if the someone calls `<- rsp.stdout`?
Reminder: we are no longer need to expose `Log`, change to `log` or some other meaningful names. The same applies to `Row`.
refactor `Response` in [this commit](https://github.com/wangkuiyi/sqlflow/pull/188/commits/f0319124056454a75da0a3c727b136d6a1577246),
```go
type Response struct {                                                                                                                                                                                                                                                          
    data interface{}                                                                                                                                                                                                                                                            
    err  error                                                                                                                                                                                                                                                                  
}      
```
and using [Type switches](https://tour.golang.org/methods/16) to differentiate types of `data`
The *cumbersome way* follows [this issue](https://github.com/wangkuiyi/sqlflowserver/issues/6#issuecomment-451192647)
The receiver of Response should always start by looking at `if rsp.err == nil`, so `rsp <- Response{err: err}` is sufficient.
=> `rsp <- l`
=> `rsp <- l`
@weiguoz Got it. Let's see if this logic provides a good user experience.
👍 
sure 👍 
Add a few lines explaining how SQLFlow determine which code generator to use.
remove the empty line.
This summarization is awesome!
Prepare Prediction Table
tensorflow => TensorFlow 
From four #'marks to three.
have provided => provide
Databases => SQL engines, or DBMSes
froms ... => work with different SQL engines.
Each SQLFlow service deployment works with only one SQL engine. In the rest of this document, we refer statements that the SQL engine recognizes to *standard-syntax SQL statements*.
`## Save Prediction Result`
Most 是说哪些？应该列一下
不需要这么多级别的 sections。我看全部都是 `##` 就可以了，每个section是一种操作。就像我上面总结的 Data Retrieval 和 Metadata Retrieal。

下文中的四个 # 我感觉都是不必要的缩进级别。

或者有两个 `##`，一个是 Data Operations in SQLFlow，另一个是 Data Operations in Submitter。每个下面有几个 `###`，分别列出两类下的各种操作。
columnType 不是一个英语单词。要么是 column type，要么是code写成 `columnType`。这里没有贴代码，没有code的上下文，貌似应该是 column type
这个section说的是load，但是这段代码完全没做 load 的事儿？
这段代码里的注释应该从代码里提出来，作为正文。写在代码里太偷懒了。
Changed title to `Create Python Database Connector`
Done
Changed all to `##`
listed.
Done.
Done.
一般不用被动语态
Connect to SQL Engines
这个应该和save prediction result写在一起吧？
save prediction result的前两部是go负责的。这边insert rows是由python负责的。

我认为save prediction result可以改回为prepare prediction table
我觉得这里还是改回 `Prepare Prediction Table`比较好。因为go并没有在prediction table里面插入数据。只是准备了prediction table。
那我改成 we can derive TensorFlow's feature column type via a mapping .... ?
update：已改为Connect to SQL Engines，因为整个section在Data Operations in Python下了，不需要重复强调python。
~~我认为这里是需要强调db connector是在python里的。~~
Where is this Scan method called? I cannot grep it in the source code. I cannot find it as any method in some interface types in database/sql/driver too.
relies => resides
I feel that this paragraph can be simplified as

> This Docker image is designed to build source code on the host, so we can use any of our favorite editor on the host.
Edit on the Host
Build in the Container
May be a link https://golang.org/doc/code.html#GOPATH
Run Tests
https://stackoverflow.com/questions/43705442/is-it-redundant-in-a-dockfile-to-run-user-root-since-youre-already-root
Looks great!
如果写成 `sqlflow_advocators_team.a_dnn_model` 会不会意思更明确一点？突出数据库可以对应于团队或者项目？
是不是这两行合并成

```go
sqlf, e := sqlfs.Create(db.DB, table)
```

就可以了？
类似的，sqlfn 这个变量定义是不必要的？
It is great to see that Travis CI can do CI and nightly release. It seems a good idea for us to have two Dockerfiles: one for releasing and one for development.
这里是想调用test.sh吗？
`bash scripts/deploy.sh`是应该放在deploy下的。

因为deploy只有在merge了之后才能触发，为了在PR里面测试`deploy.sh`我暂时将其放在了script下。
Could you add a few lines explaining the context of this design doc? For example, what is ALPS? Why sqlflow needs a alps submitter (e.g., ALPS supports distributed training; ALPS has rich data preprocessing functionalities)?


This is an experimental design. How about changing the title to "Proof of Concept: ALPS Submitter"
Please change passive voice to active voice such as "For machine learning models, we only consider [Tensorflow premade estimator](https://www.tensorflow.org/guide/premade_estimators)."
Please change passive voice to active voice.
"needs" => "need".

The reader may not know when to use `dense`. How about changing it to 
"If a table cell is encoded, we assume the user always provides enough decoding information such as dense/sparse, shape via expression such as `DENSE`, `SPARSE`, `IDENTITY_SPARSE`."
What is "Estimator Args"?
The following could be an excellent feature request in the future. Maybe file it as a separate PR.
I am not sure where is this code snippet used? Should sqlflow generated code include this code snippet?
"implemented" or "declared"? Change to "In `COLUMN` clause we declare parsing type such as ... "?
Should `DENSE(c1, shape=[5], dtype=float)` include `separator=","`?

If not, does it mean all dense features are encoded in a string and separated by commas?
How are `CROSS`, `NUMERIC` and `BUCKETIZED` translated into `graph.conf`?
I am not sure how can we implement this feature. Do you have a concrete design?
We don't need to translate these expressions to `graph.conf`,  they should be translated to a snippet code using [tensorflow feature columns api](https://www.tensorflow.org/guide/feature_columns). ALPS framework will execute it and pass the result to the constructor method of the estimator.
Sorry, we have no concrete design right now. This part may be implemented by an AST checker or something else. After the simplest case is done, we will give a supplement design.
ALPS framework will execute this code snippet and pass the result to the constructor method of the estimator.
Sorry for the mistake, it's actually the parameters of the constructor method of the estimator.
Yes. So it is not supported in this design.
done
感觉是否这里加上一个带sqlflow keyword的sql能够进一步验证方案的正确性。
好主意！我这就加上。 
`DENSE(c1, shape=3, dtype=float, delimiter=',')`
or
`DENSE(c1, 3, float, ',')`
How about changing the following sentence to

## Future Development

For now, we will combine the `feature_columns` as one dense tensor and feed it to the model. If we want to support models with multiple inputs, we will need an `AS` keyword annotate different inputs.
Should we expose `GraphConfig` struct? If no, turn it to `graphConfig` with lowercase.
Since we know interfaceList's length. You might want to define a bounded dest array for more efficiency.
"SPARSE" appears more than once. Perhaps we should define a const. (Same to "DENSE") 
Should we allow the users to config `"double"`?
Golang coding style: avoid `else if`.
```go
if headExpr == "DENSE" {
    return ...
}

if headExpr == "SPARSE" {
    return ....
}

return ...
```
Do we need a field `Separator` for `DENSE`?
Code style: avoid else if.
```golang
if headName == "" {
    return ...
}

switch headName {
case "DENSE":
    return ...
default:
    return ...
}
```
Could you also check the content of the result?
Check the length of `el`, `(*el)[2]`will panic if a user writes `DENSE(c2)`.
Fixed
Fixed
Fixed
Add a TODO here, let's make the POC working firstly.
Fixed
Fixed
Fixed
Yes, just added a commit for this kind of situation, please take a review. @tonyyang-svail 
Fixed. 
In Go, we encourage using snake_case for constant. ([mixed caps](https://github.com/golang/go/wiki/CodeReviewComments#mixed-caps)).
Fixed
Why not just `fmt.Sprint(bc.Boundaries)`?
why removing the following assertion?
The `fmt.Sprint` results a string with space separator which I want it to be a comma .
That is a previous mistake. All keys of `cross` must be either string or categorical column except HashedCategoricalColumn, given `NumericColumn` which is not supported.
Should we change `cross` to `CROSS` to make the feature column naming consistent?
does sqlflow has click and scroll down. Probably a sample more fit for sqlflow is more helpful.
Run sqlflow on mobile phones? If we does not support it, may we just remove this session?
it may not an error. I suggest move this to section actually behavior so it’s comparable with expected behavior 
Is this optional?
Yes.
Do not like actual behavior for comparison?
The purpose of this is to check if resolver can handle lowercase correctly.
I like this revision. :)
dev => development
via => by running the following command
Each of the three URLs doesn't point to a model repository, but a model.
What is the reason for switching to 2.0.0-alpha, for that we can use `keras.layers.DenseFeatures`? I noticed that ElasticDL is still using 1.13, which also has Eager Execution. We might need a comment there explaining the reason.
Thank you for this informative point. @yuyicg @skydoorkai @zou000   please have a look at @tonyyang-svail 's point.
Because DenseFeature is a new feature in tf 2.0alpha0, it is not mature. model.build(input_shape) cannot accept dict of shapes, which is required by DenseFeature.
I believe when 2.0 releases, it should support:
```
    shape = {'c1': (1,1), 'c2': (1,1), 'c3': (1,1), 'c4': (1,1), 'c5': (1,1)}
    model.build(shape)
```

I modified tf code `tensorflow/python/keras/engine/network.py` to add dict support, in `def build(self, input_shape):`
```
    # hack to add dict
    valid_types = (tuple, list, dict, tensor_shape.TensorShape)
    if not isinstance(input_shape, valid_types):
      raise ValueError('Specified input shape is not one of the valid types. '
                       'Please specify a batch input shape of type tuple or '
                       'list of input shapes. User provided '
                       'input type: {}'.format(type(input_shape)))

    if input_shape and not self.inputs:
      # We create placeholders for the `None`s in the shape and build the model
      # in a Graph. Since tf.Variable is compatible with both eager execution
      # and graph building, the variables created after building the model in
      # a Graph are still valid when executing eagerly.
      if context.executing_eagerly():
        graph = func_graph.FuncGraph('build_graph')
      else:
        graph = backend.get_graph()
      with graph.as_default():
        # hack
        if isinstance(input_shape, dict):
            x = {key: base_layer_utils.generate_placeholders_from_shape(input_shape[key])
               for key in input_shape}
        elif isinstance(input_shape, list):
          x = [base_layer_utils.generate_placeholders_from_shape(shape)
               for shape in input_shape]
        else:
          x = base_layer_utils.generate_placeholders_from_shape(input_shape)
```
After that, using dict of shapes as input for model.build works.
@skydoorkai This workaround looks great. Is it possible to contribute this patch to Tensorflow official repo?
Sorry for the confusion. This PR should only contain the design doc.

To explain the switch, TensorFlow 2.0.0-alpha uses `keras.layers.DenseFeatures`, while TensorFlow 1.13 uses `tf.feature_column.input_layer`, to transform feature columns to dense tensors. As mentioned [here](https://stackoverflow.com/a/54718798), Keras is becoming the de-facto high-level API for TensorFlow. So I would suggest using `keras.layers.DenseFeatures`, which is in TensorFlow 2.0.0-alpha.

Upgrading the Tensorflow version will cause failure in CI. I will remove this line change and file it in a separate PR.
Sure, I have changed "model repository" to "model".
We can file an issue for this. Not sure if the workaround is the right solution for it.
Why "not suitable for long term development"? Could you please elaborate?
I was confused by the point here. Obviously, subclasses support many more than `save_weights` and `load_weights` -- we can see `call` and `__init__`.

After reading the links you provided, I got that you didn't complete your sentence, which seems should have been:

> Please be aware that Keras Model subclasses allow us to save and load model parameters but not model topologies.
Do we need to add `build` to this example to make it complete for the discussion here?
Does this point mean that we cannot call do

```python
x = tf.keras.layers.DenseFeatues(feature_columns)
y = tf.keras.layers.Dense(n, activation='relu')(x)
```

because x is returned by `tf.keras.layers.DenseFeature`?
@skydoorkai could you share your modification? It is good to have it in your personal repo or in an issue in the TensorFlow repo. Anyway, more engineers in the community could understand the requirement and your solution.
I will create a dockerfile in my repo and file an issue in tensorflow repo.
Put the repro example and the solution here:
https://github.com/skydoorkai/tests_and_issues/tree/master/tensorflow/densefeature

Also filed a tf bug:
https://github.com/tensorflow/tensorflow/issues/28111

`sql/alps_submitter.go:242: unreachable code`
Should we assign `error` returned by `submitALPS` to `e` and make later logging code working?
We probably shouldn't modify pip index URL in the Dockerfile.
agree
> "Because this repo contains Go code, please make sure that you have the directory structure required by Go. "

This sentence should come after the bullet points.
Fixed. 
"joing force" => "joining forces"?
You may need to clarify `upstream` and `origin`. For example, if one `go get github.com/sql-machine-learning/sqlflow`. In his local repo, the `origin` refers to the official repo https://github.com/sql-machine-learning/sqlflow, instead of his fork.

Since our `build.md` recommends `go get` to download the source code, I would suggest adjusting `upstream` and `origin` accordingly. Also, adding a sample of `.git/config` will also help. Here is mine:
```
$ cat .git/config
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = https://github.com/sql-machine-learning/sqlflow
	fetch = +refs/heads/*:refs/remotes/origin/*
	fetch = +refs/pull/*/head:refs/remotes/pr/*
[remote "tonyyang-svail"]
	url = https://github.com/tonyyang-svail/sqlflow
	fetch = +refs/heads/*:refs/remotes/origin/*
	fetch = +refs/pull/*/head:refs/remotes/pr/*
```
Will fix. 
Sure, will use your git config as an example here. Sounds good?
Resolved and committed in the PR, please review. 
Please be aware that everything in the `.git` subdirectory is subject to change with the version of Git. It might not be a good idea to reveal the details like `.git/config` file.
Usually, developers don't need to type such a command. When we do `git clone`, our local repo would be set to track the default branch of the remote repo.
It's a good working style to clean up. To make it cleaner, we also need to delete the remote branch:

```bash
git push origin :new_feature_branch_issue_000
```
Sure, will add clean up for remote branch. 
Do you mean, when people do ```git clone```, remote branch will be checked out automatically? If so I will add a note here, here this command is to explicitly check out remote branch and make sure we have the latest code. 
Good idea, will make a change. 
`go install` is only required for releasing Docker image. It is not required for building and testing SQLFlow.
My suggestion: 

Select the "New" drop-down menu on the right side, and open the "Python 3" development environment in a new Notebook cell (also in a new tab). In the new cell, type in below SELECT statement to fetch 5 records from train table in Iris database. 
FYI: I found using a python version manager, such as conda, pyenv,  is more convenient.  For example, we are using this approach in tf-plus: https://github.com/tensorflow/io/blob/master/dev/Dockerfile#L19
@zou000 Thanks for the suggestion. Indeed, adding `source activate tfio-dev` to `~/.bashrc` neatly isolate the Linux built-in Python2 and our Python3. This approach avoids the error-prone
```bash
# Make python3 as default Python interpreter
RUN ln -s /usr/bin/python3 /usr/bin/python
RUN chmod +x /usr/bin/python
``` 
Should we also updated the doc telling user to use python3 and the latest pip version? 
@zou000  enabling python env in `.bashrc` has certain drawbacks. For example, if you do `docker run image_name bash test.sh` i.e. non-interactive bash, `.bashrc` is skipped, so the python env is not activated. One workaround is to define the `source activate` in `entrypoint`.
Absolutely.
I can think of 2 other ways:

1. Invoke bash interactively e.g. ` docker run image_name bash -i test.sh`
2. The idea of a pyenv is very simple, it just needs to find the python binary under the env root dir, e.g. in your case, you just need to modify PATH:
```bash
ENV PATH=/miniconda/envs/sqlflow-dev/bin:$PATH
```  
I like the PATH approach better. You can verify the result by:
```
docker run image_name python -c 'import sys; print(sys.path)'

```
If we are duplicating some code in .Dev, can we group the duplicated ones and add some notes in case when they need to be synchronized? 
In `newAlpsFiller`, the system is referred to as `Alps`; in `genALPS`, it is `ALPS`. Which one should we use?

To my understanding, if the system is named after the name of the mountain, it should be `Alps`; or, if it is a synonym, it should be `ALPS`.
Is the `scratch_dir` the current working directory (`cwd`)? 

If so, it seems that the function `genALPS` should take an addition parameter `cwd`  and uses the value to replace the value of `scratch_dir` here.

If not, please make sure that multiple locally-running Alps jobs spawned from the same SQLFlow server process would not write to the same `./scratch` directory.
Will Alps support prediction/inference soon? 

If so, we might want to add a check here

```go
if pr.training {
```

If not, we might not need the function `submitALPS` in addition to `trainALPS`.
You are right, they should be unified into `ALPS`

`scratch_dir` is the directory where `checkpoint` and `model` are stored. Fixed directories are really inappropriate. Thank you for pointing out.
Yes, ALPS will support inference in the next few days. This check already exists in the `submitALPS` function. To avoid misunderstanding, what do you think about renaming `newAlpsFiller` to `newALPSTrainerFiller`?
It would great to remove the temporary directory after the training. Maybe move these lines to `trainALPS` so that we can remove it using defer.
```go
dir, err := ioutil.TempDir("/tmp", "alps_scratch_dir")
if e != nil {
	return e
}
defer os.RemoveAll(dir)
```
Also, is it possible to combine `dir` and `cwd`?
The `scratch_dir` will be deleted after model saving in the next PR.
> Also, is it possible to combine `dir` and `cwd`?

In my opinion, no matter which `submitter` is used, the "current working directory" which is stateful should be managed (created, saved, deleted) by `runExtendedSQL` in SQLFlow, but the `scratch_dir` which is an inner attribute in `ALPS submitter`.
Maybe we only need time elapsed for the `slct` statement in the log, so this line can be `Debugf`? And below elapsed log can log together with `slct`, or it maybe harder to figure out which statement this time was.
Sounds good. :)
Maybe also output the `slct` string?
My bad..
This PR conflicts PR #353, please take a look at that PR first. 
Should we also make a note in developer facing doc as this .md doesn't present directly to end users, pretty hard to find. 
My personal suggestions for the content: 

SQLFlow will love to support as many mainstream ML frameworks and data sources as possible, but we feel like the expansion would be hard to be done merely on our own, so we would love to hear your options on what ML frameworks and data sources you are currently using and build upon. Please refer to our [roadmap](https://github.com/sql-machine-learning/sqlflow/issues/327) for specific timelines, also let us know your current scenarios and interests around SQLFlow project so we can prioritize based on the feedback from the community. 




ok,I will check it!
Just ignore my comment and check in, it could be done in the future. 
@hungry1526 If use PR#353, my PR will be nothing! It just fix the old version network problem of containers. So best is I cancel it!
Shall we release `sqlflow/quickstart:latest` to DockerHub on every successful build? This can be done at `scripts/deploy.sh`.
Sure, will add!
Should we leave option -RM up to user? In some cases, developers want to re-run docker
good point, or shall we run the container in the background, adding `-d` so that the service will survive long?
I personally agree, but removing -rm should also sync up other folks. I personally want to play around for a while but forgot we using -rm when it starts. 

We should probably simplified all the possible options for each commands and leave most of decisions to users with sufficient notes. 
Seems `docker start` to restart the container will run the script again when first-time `docker run` ran: https://stackoverflow.com/questions/26032929/does-docker-start-execute-the-cmd-command. So removing `--rm` should be fine.

Adding `-d` will cause user to have to run `docker logs` to get the notebook token, so will remove `--rm` in this PR only.
Question, is 1s enough? What are the factors for length of sleep time? 
Sounds good. 
below lines will wait until the connection is ready. So sleep 1 here is OK~
Can we then remove line 5 as we have the until loop to wait for the DB connection.
Some times mysqld starts very fast, so line 5 here can reduce the annoying error logs.
I see, we could use 1s for sleep time for now, but it would be nice to explicitly catch/handle the MySQL connection error instead of waiting for 1s. Guess it is hard to decide if 1s is enough for the wait before entering into until execution. 

:-) 
How about we name it `sqlflow/sqlflow:quickstart`? Because we are naming gohive image as `sqlflow/gohive`, `sqlflow/quickstart` is not clear which repo it refers to.
I believe `example/` directory will be moved to `doc/` and all the website content will be built from `doc/`.

So shall we put this Dockerfile to PROJECT_ROOT, right next to other Dockerfiles, and name it `Dockerfile.quickstart`?

Sure.
Sure.
=> `docker pull sqlflow/sqlflow:quickstart`
You are very welcome, we encourage PR like this, please keep doing it!
I'm not sure what the effect is.
Maybe we just run `go test -v ./...`, because the default `SQLFLOW_log_dir` is "" 
Shall we also add `SQLFLOW_log_level=debug`?
Thanks @weiguoz @tonyyang-svail , Done.
Thanks @tonyyang-svail for sample code here, it helped me alot: https://github.com/typhoonzero/sqlflow/pull/1/files
Is it also possible to incorporate this line?
how about use a constant map to define the type transform, like:
```
var column2feature = map[string]string{
  "FLOAT":            "numeric_column",
  "FLOAT_TYPE" : "numeric_column"   // for hive only
}
```
seems No.2 is done already?
nod
Just curious that if we are writing multiple versions of model parameters to DB ( have many flushIDs) then how to determine which model to use when running prediction?
Is there already checks that can enure allways writing parameters of the same model? Like if a user trained a `DNN` model first, then he change the model type to `LR` but didn't change the table name where we save the model parameters?
Maybe we need `DriverType` type to unify these checks in order to avoid things like coding mistakes like `"Hive" == "hive"`
What is thrift used for?
We should probably return an error if we can't map a `ctype` to a feature column, so that we can make error message like https://github.com/sql-machine-learning/sqlflow/issues/350 more informative.
Good catch.
This will be fixed in [Unify DriverType name](https://github.com/sql-machine-learning/sqlflow/issues/374).
Why removing the last semicolon? 
`pyhive` relies on `thrift`, or a `ModuleNotFoundError` will be reported, but `impyla` does not.
Since we won't use `pyhive` at this moment, `thrift` should be removed.
why do we need this change? Looks like `columnType.Name` is redundant.
Could you explain the necessity of the following changes?
In `hive`, a statement with the last semicolon will cause a `ParseException` error.
You're right.
It is an outdated definition.
Since `p` is unchangeable in a loop. Then we just reuse the result of `len()`.
return error like "unsupported field XXX with type XXX"
Also include field name `ident` in the error message?
This might be a leftover for debugging. Could you change back to `return n, fmt.Errorf("writer flush failed: %v", e)`? A writer has many functions, the error message should include the function name. :)
I see. Since `len()` is O(1), we might not need this level of optimization. :)
We are considering using [independent storage media](https://github.com/sql-machine-learning/sqlflow/issues/377) to save models. Let's keep on discussing in that thread.
`sql/db_test.go` is responsible for data population.
I'm not sure `db_test.go` can always run before `main_test` since `main_test` depend on these sample data.
Good point. Let me try it out.
Have you tested adding `set -e` in travis.yml? if that works we may reduce the level of script calls.
You are right. I forgot the tests in `cmd/` also need the populated data. My bad.
Maybe we need to run big stages independent to speed up.
How about connecting the sub stages by `&&`
typo `kubeflow/mpi-operator.git`?
"setup" => "Setup"
Users don't need to build from source, only contributors need to.
I agree that we should merge the content of this file into build from source doc. but I am not sure the docker command in this file runs now. I'd suggest we confirm it works before moving it into the build from source file 
I am afraid this file is not ready to merge into the build from source file 
Users and developers seem be inter-changable,  I agree we can keep it under contribution. 
Will create an issue to track changes. For now, I will undo delete. 
I noticed that and I filed [an issue](https://github.com/sql-machine-learning/gohive/issues/39)  in `gohive`.
Not sure we need to add this level of abstraction: `OdpsConf.Dict["Key"]` vs `OdpsConf["Key"]`. I think the latter is more concise. If we need to define a method, such as `Get(key, defaultValue string)`, on `map[string]string`, we can simply give `map[string]string` a name. For example,

```golang
package main

import "fmt"

type collection map[string]string

type collections struct {
	name string
	c2 collection
}

func (c collection) Get(key, fallback string) string {
	if v, ok := c[key]; ok {
		return v
	}
	return fallback
}

func main() {
	config := make(map[string]string)
	config["k1"] = "v1"
	var c collection = config
	fmt.Println(c.Get("k1", "fallback1")) // v1
	fmt.Println(c.Get("k2", "fallback2")) // fallback2
	cs := collections{name: "hi", c2: config}
	fmt.Println(cs) // {hi map[k1:v1]}
}
```
By doing so we can avoid the redundant `Dict` field.
Add `//FIXME(uuleon): Train and Eval should use different dataset.`
Should we remove `scratchDir` after the training?
That is a great idea! Thanks for pointing it out.
The `scratchDir` will be deleted until the output model is saved using `sqlfs` which is blocking by `ODPS DB`.
Would you please at least add a TODO?
Ok, thanks
Could you please provide an example on `args []string`?
Indentation changes?
I don't think the following changes are relevant to this PR.
What is the purpose of `env.global.secure`?
As commented in `deploy.sh`, shall we delete all `go get`s in the Dockerfile?
Please check out https://docs.coveralls.io/go for details about this.
I updated the description of this PR, this change try to fix randomly fails in PR CI check, or pull requests would take several re-runs to pass the checks.
Sure, Done.
Done.
Do we need to import the driver?
Maybe add test case for wrong standard SQL statement and wrong SQLFlow statement to test if the parser can catch expected error in these cases?
Followed https://github.com/pingcap/parser/blob/master/parser_example_test.go
Correct me if I am wrong. We are no longer using `sqlflow/sqlflow:dev`. For CI, we need to
1. ` docker build -t sqlflow/sqlflow:latest -f Dockerfile .`
1. `docker run  ... sqlflow/sqlflow:latest bash scripts/test.sh`
Production code shouldn't include commented code unless led by TODO or FIXME.
The logic here is rather complicated. Maybe explain it more:
```
# Build SQLFlow binaries by git clone the latest develop branch.
# During development, /go will be overridden by -v.
```
Since we have `ENV PATH $PATH:/usr/local/go/bin:/go/bin`, no need to move it to `/usr/bin`.

A developer may test his package using `go install ./... && demo ...`, this command updates the package at `/go/bin/demo` but not `/usr/bin/demo`. Since `/go/bin` comes after `/usr/bin`, the developer may get confused.

Removing `mv /go/bin/demo /usr/bin && mv /go/bin/sqlflowserver /usr/bin` will solve this issue.
I put compiling SQLFlow develop branch into the `Dockerfile` so that SQLFlow binaries are located in the docker image. If do `docker build` in CI then, it's actually building the code twice, one for develop branch, one for current PR branch. Thought would omit one.
I added `docker build` back since we need to also test `Dockerfile` during pull requests.
Done.
Thanks, that's very clear.
Done!
Is there a way to combine `sql/testdata` and `example/datasets/*.sql`?
Should be. Since https://github.com/sql-machine-learning/sqlflow/issues/404 is describing the same thing, I'll try to fix this in another PR.
Sounds good!
For every TODO, would it be better to create an issue and we can track it without going through the code? 
Unnecessary alias?
Would multiple simultaneous Alps jobs share the same directory? If so, would they conflict with each other?
It seems that this Go template is becoming longer.

It seems to me we need the following stuff in this Python template:

1. the Estimator builder class
1. the train function
1. the predict function
1. the main function

To make it easy to maintain and test, I would move 1., 2., and 3. out from this .go file into a Python file `python/alps_codegen.py`. So we could have `python/alps_codegen_test.py` for unit testing these facilities. To make this happen, we need to remove all template syntax from 1., 2., and 3. to make them legal Python code. I think this should be pretty easy -- we can change template placeholders into function parameters or class data members.

And, I would leave all template syntax in 4., and keep 4. in this .go file.

Following the above steps, this alps_codegen.go file would generate a short .py file which contains only a main function, which, calls functions/classes defined in python/alps_codegen.py.

To make this solution complete, we should remember that we need to pack python/alps_codegen.py into our release Docker image, so it could be called by the generated Alps submitter programs.

I has this idea few months ago and talked to @tonyyang-svail at that time. Now I believe this is a must-go way, because following our feature derivation design, we have to make feature derivation a Python package instead of a Go package, as it must scan the data in order to derive features. As we'd have to have Python package called by submitters, we'd put alps_codegen.py part of this Python package.

@uuleon please feel free to talk to @tonyyang-svail and me for more about this idea.
Just being curious -- can we actually run train.sql from within the Go slide?
Can we move these very long commands into a shell script file so we could have a chance to write comments explaining like why we'd export ports like 10002, 8040, 9846, 9866, and 9867?
Added comments in `.traivs.yml`
I don't think so.
Since we are switching back to `sqlflow/sqlflow:latest`, the following lines can be removed.
```
set -e
. /miniconda/etc/profile.d/conda.sh
source activate sqlflow-dev
```
Thanks, will clean up in next PR.
Yes，it's unnecessary.
You are right. That's why a `FIXME` is added here, and the confliction will be resolved after the DB of `MaxCompute` is available.
Thanks for this comment which is reasonable and valuable, I will close this PR and do the refactoring of the code template at first.
Why do we need meta programming?
SQLFlow only supports Python3. I don't think `__future__` is necessary. Python2 is retiring in 7 months anyway. :(
Which part of the codegen needs this method?
Python has DBAPI specification, which already standardize functions such as `execute`. Why adding another layer?
prediction job needs this function.
`_retrieve_fields_and_value_from_cursor` I found this function is exactly the same across `MySQLDataBase`, `SQLite3DataBase` and `HiveDataBase`...
Which part of the submitter needs to create a table?
Should we create a table first before saving the prediction result?
The current implementation does this in Go.

https://github.com/sql-machine-learning/sqlflow/blob/652aaaa4096f2bc2cb580ed7aa39ad81148c959d/sql/executor.go#L304-L306
No, `HiveDataBase ` is different
Ok
> @uuleon I have no idea why things need to be implemented in such an overwhelming way, where
> 
> 1. Metaprogramming: `@six.add_metaclass(abs.ABSMeta)`
> 2. OOP : `classSQLDataBase(DataBase)`
> 3. ORM: `create_table`
> 
> are involved. Not to mention many methods are not implemented...
> 
> The goal of extracting python snippet from code template is to make the code more readable and testable. Please keep it simple... Readability matters...
> 
> I would suggest starting from simply taking out the code from the template like what @wangkuiyi did.
> 
> https://github.com/sql-machine-learning/sqlflow/blob/652aaaa4096f2bc2cb580ed7aa39ad81148c959d/sql/python/db.py#L1-L16

With all due respect, I don' think it's an overwhelming design. The goal of designing `DataBase` is to hide all the specific details between databases, to make the code template of the `submitter` clean and simple.

Here are two differences between databases:
1. get `field_names` from `cursor`
Hive:  [i[0][i[0].find('.')+1:] for i in cursor.description]
Others: [i[0] for i in cursor.description]

2. template of the insert statement
MySQL: insert into table_name (features, labels) values (%s, %s)
SQLite3: insert into table_name (features, labels) values(?, ?)
Hive: insert into table table_name (featuers, labels) values (%s, %s)

That's why class `DataBase` is created and OOP is involved. If OOP is removed, some methods still have to exist for resolve the conflictions mentioned above and the code is not simple as you wish, or maybe leave it in the code template of the submitter? I don't think it's a good idea.

Should we have to use `create_table` method before saving prediction result? Correct me if I am wrong, please.

At last,  only one method which is `_gen_insert_table_statement` in `HiveDataBase` is not implemented, not many as you mentioned.

> At last, only one method which is _gen_insert_table_statement in HiveDataBase is not implemented, not many as you mentioned.

@uuleon I apologize for the statement "Not to mention many methods are not implemented". It is inaccurate. I didn't realize most `NotImplementedError` lives in the base class.
My bad.
> Should we have to use `create_table` method before saving prediction result? Correct me if I am wrong, please.

In the current implementation, we don't. Table creation is done at Go, so the Python program doesn't need to create_table. A few month ago @wangkuiyi and I discussed keeping the database complication in Go and leaving the Python program small.

> Here are two differences between databases: ...

You are right. I feel (2) is relatively easy to solve in Go by using different statements for different SQL engines. However, we haven't figured out how to solve (1) in Go. @weiguoz has a detailed description of (1) at https://github.com/sql-machine-learning/sqlflow/issues/318.
Would you mind enabling this test in our CI? This can be done at `scripts/test.sh`.

If you wanna test against Hive, please refer to modify `scripts/test_hive.sh`.
Given that db.py is not a "template", but a "real" Python program that is runnable and testable, the directory name should be `sql/python/sqlflow` instead of `sql/python/sqlflow/template`.
I am a little confused about why we need two test files for db.py.

Then I realized that is because .travis.yml called two shell scripts: scripts/test.sh and scripts/test_hive.sh.

However, I still feel that we can have only one test file, say, test_db.py, which contains

```python
class TestDB(TestCase):
   def test_mysql(self):
      ...
   def test_sqlite(self):
      ...
   def test_hivel(self):
      ...
```

where in each method, say, `test_mysql`, it judges the value of environment variable `SQLFLOW_TEST_DB`:

```python
def test_mysql(self):
    if os.environ['SQLFLOW_TEST_DB'] == "" OR os.environ['SQLFLOW_TEST_DB'] == "mysql:
        go_on_test
```
ok
```
test_hive (sqlflow.db_test.TestDB) ... ok
test_mysql (sqlflow.db_test.TestDB) ... ERROR
test_sqlite3 (sqlflow.db_test.TestDB) ... ok
======================================================================
ERROR: test_mysql (sqlflow.db_test.TestDB)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/go/src/github.com/sql-machine-learning/sqlflow/sql/python/sqlflow/db_test.py", line 29, in test_mysql
    self._do_test(driver, conn)
  File "/go/src/github.com/sql-machine-learning/sqlflow/sql/python/sqlflow/db_test.py", line 44, in _do_test
    execute(driver, conn, self.drop_statement)
  File "/go/src/github.com/sql-machine-learning/sqlflow/sql/python/sqlflow/db.py", line 36, in execute
    field_columns = list(map(list, zip(*cursor.fetchall())))
  File "/miniconda/envs/sqlflow-dev/lib/python3.6/site-packages/mysql/connector/cursor_cext.py", line 489, in fetchall
    raise errors.InterfaceError("No result set to fetch from.")
mysql.connector.errors.InterfaceError: No result set to fetch from.
```

@uuleon 
CI failed on MySQL with `No result set to fetch from.`. Maybe add `coursor.commit()` after `executemany()`?
Reference: https://stackoverflow.com/questions/384228/database-does-not-update-automatically-with-mysql-and-python
I don't think so. From the error stack information, the result of `fetchall` is indeed None because of the query is `drop table ***`, I have added code to handle this situation.
Great!
The actual reason for this failure is the syntax of `fetchall` is different for `MySQL` and `Sqlite3` when there are no results from `execute`, `None` is returned from `Sqlite3` and `InterfaceError` is raised by `MySQL`.
Fix the indentation? 
Hi @hungry1526, string constant is supposed to be indented like this. :) Otherwise, the statement will become
```
SELECT *
    FROM iris.train
    ...
```
@hungry1526 Thanks for review, sorry for the late reply due to I was debugging some errors in this PR. As @tonyyang-svail commented, this indentation is expected, so I'll keep it.
thanks guys. 
Is this a leftover for debugging?
Suggested feature, maybe adding in the future PR:
Is it possible to add `model_dir` parameter to our self-defined model? So that `my_model.h5` will be stored at `model_dir` as `modir_dir/my_model.h5`. Later on, if we need to save training logs and visualize ten, we can also save them at `model_dir`.
Correct me if I am wrong, both self-defined and premade models need `{{range $key, $value := .Attrs}}{{$key}} = {{$value}},{{end}}`, is it possible to combine them?
Please clean up the commented code. :)
What is the purpose of `by_name=True`? In the [official document](https://keras.io/models/about-keras-models/):

>  model.load_weights(filepath, by_name=False) loads the weights of the model from a HDF5 file (created by save_weights). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use by_name=True to load only those layers with the same name.

I am not sure if we are expecting to change the architecture.
It's useful to leave it here to ensure `sqlflow_models` is installed, or the following `go test` is not going to output a meaningful error message.

Adding pretty debug information when training script fails seems another work to do, I'll create an issue if needed.
Should we make a git submodule in the sqlflow repo pointing to the models repo? -- just a reminder, no need to reply in this PR.
I could be wrong but submodule I thought should be a **required** dependency, but in this case, SQLFlow can still work if `sqlflow_models` is not installed.
Good point. I take back my suggestion.
Created an issue: https://github.com/sql-machine-learning/sqlflow/issues/432 to track this.
Done
Done
Removed
Maybe change this to `tryRun("python", "-c", "import pyodps")` and update the Dockerfile? This can be done in the next PR. :)
I vaguely remember Hive client requires SQL statement ending without `;`. Will Hive CI fail due to this change? 
maybe move these strings to some constant vars in next PR?
Good idea!
I tested several extended SQL cases with the hive, it works.

In fact, hive SQL does not need the last `;`, so :
1. In Go: Gohive removes the last semicolon, [ref](https://github.com/sql-machine-learning/gohive/blob/develop/connection.go#L83)
2. In Python: SQLFlow removes the last semicolon for hive db-api, [ref](https://github.com/sql-machine-learning/sqlflow/blob/develop/sql/codegen.go#L135)

Great!
I filed an issue [Unify DriverType name](https://github.com/sql-machine-learning/sqlflow/issues/374) 11 days ago, but ... I'm pretty sure this will be implemented.
Cool!
Does `sh` includes `*.sh` files in `PROJECT_ROOT/scripts`?
The script currently do not add copyright header if the first line starts with `#!`. Or should we add copyright string after `#!/bin/bash`?
Let's add it after `#!/bin/bash`. Like [`go/src/run.bash`](https://github.com/golang/go/blob/master/src/run.bash)
`$PYTHONPATH` => `PYTHONPATH`
Can we move this if-else logic into db.py? Something like

```python
def connect(..., database, ...):
    if database == "":
        database = None
    ...
```
How about in the future PRs, let us do something more:

- Move the following code snippet that constructs `feature_columns` and `feature_column_name` into a Python file, say, `naive_feature_dreivation.py`, and make it a function `derive_features`?

- Move the code snippet that constructs the classifier into `create_estimator.py` and make it a function `create_estimator`?

- Move the function `train_input_fn` and `eval_input_fn` and the logic that calls them to train and to evaluate the model into `train.py`?
Ok
Yes, I will do this in the future PRs after both considering the code in `codegen.go` and `codegen_alps.go`.
SQLFlow server exposes [port 50051](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/installation.md#use-your-own-database) already. I would suggest taking another port.
Done
should be 'tidb'?
It is MySQL. We used TiDB parser for MySQL.
~~I would suggest putting the right part before the left part to reduce several network latency. 
Because of the `SQLFlow.Parse` run **locally** but `sql_engine.Parse` not.~~
Maybe can use `FindAllStringIndex` to get the matched index directly?
Agree with `packing the two calls into one` to reduce time-consuming.
But I would suggest keeping the parses as simple as possible:
1. for a correct extended SQL: latency is mainly caused by the execution phase
2. I'm not sure if `SQLFow` would expand keywords like `yet_another_train`. If yes: we should update `SQLFlow` & `external parsers`, which means more complicate for deploy.
Just curious, in order to retrieve the `abstract syntax tree`, the RPC reply like `CalciteParserReply` should return a tree structure that can be serialized by protobuf, maybe can be a [protobuf map](https://developers.google.com/protocol-buffers/docs/proto3#maps)
We might make the RPC server traverse the AST and return two lists -- fields and tables.
I see, Thanks!
Good point!
I see this file is named toutiao. Is this from ByteDance Inc.?
How if there is a statement in the file `sqlfile` which contains `;` in a string constant? For example,

```sql
INSERT INTO toutiao.train_processed VALUES ('news;music;video')
```

there are `;` in the inserted value.
It's from an open source dataset: https://github.com/fate233/toutiao-text-classfication-dataset
This function does not consider this case, I just move it out from the original file. I'll add some comments here because we only need to process some sample data files, if we want to put it into general use, we should probably update this function.
If the only use of the function `Popularize` is in `cmd/sqlflowserver/`, it seems that we should move it there. The directory `sql` doesn't seem the right place for a hacky test-only function.
How about we rename `toutiao` into `text`? It would be even better if we use English text dataset.
Sure. Will add English dataset in next PR.
I see how comes the content of this file. I would recommend to move it from `sql/popularize.go` into `sql/testdata/popularize.go`.
Could we move `CREATE DATABASE IF NOT EXISTS iris` in `sql/testdata/iris.sql`, other than in this .go file?
Not related to this PR...where is this variable defined in this go file?
`port` is defined here: https://github.com/sql-machine-learning/sqlflow/blob/develop/cmd/sqlflowserver/main.go#L33
~~typo?~~
Put `Popularize` in package `sql` but not in `testdata` so that would not generate cycle import
Copyright should come before `package testdata`. Is this a bug in `scripts/copyright.py`?
Copyright should come before `package testdata`. Is this a bug in `scripts/copyright.py`?
This `.sql` is needed for SQLFlow quickstart. We need to `CREATE DATABASE IF NOT EXISTS sqlflow_models;` in advance so that `sqlfs` can save a model into `sqlflow_models.my_dnn_model`.
This `.sql` is needed for SQLFlow quickstart.
You can use `database/sql` to avoid circular import. In `package testdata`
```go
package testdata

import (
	"strings"
	"database/sql"    // not github.com/sql-machine-learning/sqlflow/sql
)

func Popularize(db *sql.DB, sqlcontent string) error { ... }
```

Then in other packages,

```go
package main

import (
	"github.com/sql-machine-learning/sqlflow/sql"
	"github.com/sql-machine-learning/sqlflow/sql/testdata"
)

func main() {
	sqlflowDB := sql.Open(...)
	testdata.Popularize(sqlflowDB.DB, testdata.IrisSQL) // notice sqlflowDB.DB
}
```

and

```go
package sql

import (
	"github.com/sql-machine-learning/sqlflow/sql/testdata"
)

func main() {
	sqlflowDB := Open(...)
	testdata.Popularize(sqlflowDB.DB, testdata.IrisSQL) // notice sqlflowDB.DB
}
```

Comments done, thanks for advices.
Done.
Seems so. Will do more tests and try to fix this this week.
Added back, maybe unify these later in another PR.
Done.
What is the purpose of this skip? Is `CaseTrainTextClassification` time consuming?
Not sure we need to support both `BATCHSIZE` and `BATCH_SIZE`..
What if `STEPS` is larger than the eval dataset batch numbers?

I don't think `steps` should be configurable. A `PREDICT` should always go through the whole selected data. If a user wants a subset of the select, (s)he can put the restriction on the StandardSelect
```sql
SELECT ...
WHERE ...
LIMIT ...
PREDICT...
```

`EPOCHES` or `EPOCHS`?
In the current configuration, I think `classifier.default_training_epochs()` will never be used...  Given `EPOCHS` has been initialized to a number, this line is equivalent to
```python
epochs = EPOCHS
```

How about we rewrite line 208 to `EPOCHS = None` then rewrite here as
```python
epochs=EPOCHS if EPOCHS else classifier.default_training_epochs()
```
So the logic becomes
```
if user_defined:
    epochs = user_defined_epochs
else:
    epochs = model_default_epochs
```
Determine the actual dataset size ( total number of elements ) sometimes is time-consuming especially on very large datasets ( like dataset stored in Hive ), if user didn't provide `LIMIT` clause then we must execute `SELECT count(*)  FROM table WHERE ...` then calculate `STEPS`.

I'm not sure whether we should do this now, so put `STEPS` configurable for now and move on to an automatic solution.
Just for test, removed after clean.
Done
Done

Thanks, that's clever. Done!
Actually, we cannot use FindAllStringIndex here. The goal is to parse the substring after the keyword "near" in the error string, so could we find the index of the substring in the SQL statement.
Indeed. Yet I found another problem, and maybe you have already noticed before: the snippet below shows that, SQL like `SELECT * FROM iris.mytable2 TRAIN..` can not get a proper index of substatement before`TRAIN`.

```go
package main

import (
	"fmt"
	"regexp"
	"strings"

	"github.com/pingcap/parser"
	_ "github.com/pingcap/tidb/types/parser_driver" // As required by https://github.com/pingcap/parser/blob/master/parser_example_test.go#L19
)

func testParse(psr *parser.Parser, sql string) {
	_, _, e := psr.Parse(sql, "", "")
	fmt.Printf("error msg: %s\n", e.Error())
	re := regexp.MustCompile(`.* near "([^"]+)".*`)
	matched := re.FindAllStringSubmatch(e.Error(), -1)
	idx := strings.Index(sql, matched[0][1])
	fmt.Printf("Index: %d, sql before: %s\n", idx, sql[:idx])
	fmt.Println("---------------------------")
}

func main() {
	psr := parser.New()
	testParse(psr, "SELECT * FROM iris.mytable2 TRAIN DNNClassifier COLUMN c1,c2,c3 LABLE class INTO mymodels.dnn1")
	testParse(psr, "SELECT * FROM iris.mytable2 LIMIT 100 TRAIN DNNClassifier COLUMN c1,c2,c3 LABLE class INTO mymodels.dnn1")
}

```
Yes, I noticed this, as stated in 

https://github.com/sql-machine-learning/sqlflow/blob/1424350537aaf42ebf86fba10d1a61469937be5a/parser/tidb/tidb_parser_test.go#L59-L65

Still, I don't have a solution in my mind. But anyway, thanks for reminding me about this issue. Let us find a solution to it.
We don't need to determine the actual dataset size. If we don't specify `steps`, `classifier.evaluate` will consume all the data points returned by`eval_input_fn`.

> steps: Integer or None. Total number of steps (batches of samples) before declaring the evaluation round finished. Ignored with the default value of None.
Checked keras's document: https://keras.io/models/model/#fit `model.fit` can accept `steps_per_epoch=None` also. Removing this in the next PR while I'll refine the data reading part
Normally, in `Java` an `exception` is thrown out instead of returning like `go`. In that way, the `pair` in `JavaFX` is also unnecessary.  What do you think?
Is the `sqlNode` necessary? Why not remove it?

`SqlParser.create(query).parseQuery();`
Will fix it in the next PR.
Do you mean returning multiple values by throwing an exception? I am afraid that the exception is not designed for returning values?
maybe use subtests like in :https://github.com/sql-machine-learning/sqlflow/blob/develop/cmd/sqlflowserver/main_test.go#L174
`testDB` is used in other tests such as `verifier_test.go` and `executor_test.go`. So we shouldn't defer in this function. :)
Thx, moved the defer to the main function.

`:=` => `=`. I made the same mistake several days ago... >_<
emmm...missing the global var -.-
Maybe can we use `np.fromstring` instead to make it efficiency?
It seems like this `reader` function and `execute` function looks similar, maybe we can combine them into a single function which can be controlled by argument to return all data or iterator.
If the situation when `label_column_name` is null can be handled correctly, can we remove `db_generator_predict `?
The `test.sh` script runs in the container of the latest `sqlflow` image, we need to commit the update of `db.py` firstly in another PR before using the newly added API, otherwise `CI` will fail.
I think `db.py` could be covered by CI because the PR's code branch is mounted under `$GOPATH` and we always import from `$GOPATH` in the dockerfile env settings.
Good point! Wil do that!
You are right, this is not a problem.
I've been thinking about this when I'm writing this PR, adding this type if conditional check may let this generator function a bit hard to understand, and inside the generator, adding runtime checking string compare also slow down the execution.
I'll do this in next PR so that it's cleaner
Would you mind adding tests to these two functions? :)
How are `.shuffle` and `.repeat` implemented if the whole dataset is not loaded in the memory?
Answer: to achieve `.repeat`, `dataset` will call `gen` multiple times, which execute the SQL statements multiple times.
`train_input_fn` and `eval_input_fn` are becoming more and more complicated. Shall we move it to `sql/python/sqlflow_submitter/input_fn.py` and create corresponding tests?
It looks like `eval_input_fn` and `train_input_fn` are similar.
I would like to keep it in here because these functions are using a lot of global variables defined above, moving it to another file means we must pass those variables as parameters. These parameters including:

- `feature_column_names`
- `column_name_to_type`
- `"""{{.StandardSelect}}"""`
- `"{{.Y.Name}}"`
- `driver`
- `conn`
Done!
Done.
shall we also rename `testDB` in `testHiveSQL` to `db`? So that the global `testDB` is not assigned twice.
I understand @tonyyang-svail 's comment as to rewrite

```go
testDB, e = Open("hive://root:root@localhost:10000/churn")
```

in function `testHiveSQL` as

```go
db, e := Open("hive://root:root@localhost:10000/churn")
```

I agree with him and likewise we should change the assignments to testDB in other functions -- testSQLLiteSQL and testMySQLSQL.

-----

It seems that we should also rename 

- testHiveSQL into testHiveDatabase
- testSQLLiteSQL into testSQLLiteDatabase
- testMySQLSQL into testMySQLDatabase
Thx @tonyyang-svail and @wangkuiyi ! Done.

Python tests shouldn't assume the existence of `iris` database which is created by go test.
Seems `test_generator` I added before need this update too. Would you mind updating that part please? Thanks
@typhoonzero thanks for reminding. Will do!
Can put in directory `doc` and rename to `run_on_kubernetes.md`?
Kubernetes cluster => Setup a Kubernetes cluster
You can check the ... => You can refer to the official page to set up a full cluster or use a local quick start tool: minikube. In this tutorial .....
which can run Kubernetes
pull the official Docker image or build ... should be better? Since we don't quite likely want to bother users to build images.
instance => service?
Maybe add some notes about if they are using a "real" cluster, how to access the notebook web page?
This is dangerous, can you put mysql server and notebook in one pod but in different containers?
I am no expert in k8s. Are different containers in the same pod visible to each other via `localhost`?
@typhoonzero Good idea, will do that.

> I am no expert in k8s. Are different containers in the same pod visible to each other via localhost?

@tonyyang-svail Yes, the containers would share the same network stack.

What is the difference between this image and `sqlflow/sqlflow:latest`?
Just used to test, change to the official image.

done, but maybe we also need the `k8s` directory so that we can put the yaml files in it ?

done, thx.

done.
done.
done.
I think we cannot remove the phrase of "paste the token printed by the Notebook server".
> 1. A MySQL server instance with some example data loaded,
> 1. The SQLFlow gRPC server, and
> 1. The Jupyter Notebook server with SQLFlow magic command installed.
the kubectl => kubectl
Preparation => Prerequisites
I am not sure if we need to docker pull the Docker image to the local computer. I think we need to make sure that the Kubernetes nodes, but not our local computer, could pull the image.
We need an explanation on what the above command does, like

> The above command starts a pod with two containers, both running the `sqlflow/sqlflow:latest` Docker image, but on container runs the MySQL server instance and the other one runs the SQLFlow server instance.

I am not sure if my above suggested edit matches the sqlflow-mysql.yaml, but I am curious as it seems not starting the Jupyter Notebook server?
Please comment why this differs from tidbparser, can help future work, Thanks~
Done.

FYI, Calcite follows the SQL standard. I commented in tidb_parser_test.go to note that TiDB and MySQL don't conform with SQL standard.
Copyright section comes after the import. Lets manually adjust this before https://github.com/sql-machine-learning/sqlflow/issues/459 is fixed.
Great practice! Always adding tests when introducing a new function. 👍 
Just FYI, usually, if we are going to print text, especially formatted text, we would write `fmt.Fprintf(wr, "OK")`.
```go
fmt.Fprintf(wr, "%d row affected", affected)
```
The `wr` type is `*PipeWriter`, which can't be used as type `io.Writer` in argument to `fmt.Fprintf`
Maybe we don't need the token authorization here? Users don't need to find the token text from the Docker container logs (local computer) or the Pod logs (k8s), it's easier to use. And I removed the token auth: https://github.com/sql-machine-learning/sqlflow/pull/475/files#diff-ce186285de1e4082474a97a1fa4b74ecR47
Thanks for your remind, you're right, we don't need to pull the Docker image on the host.

Thanks, will add some comment to explain the k8s command.
Currently, this PR would start the Jupyter Notebook server and sqlflow-server in the same container, but as your [comment](https://github.com/sql-machine-learning/sqlflow/pull/475#discussion_r289538186), I think to separate the two process in the different container is a better way.

I removed the `GRANT` command just because all the containers would be in the same Pod on k8s.

Maybe `switch` statement ?
how about using one line?
```golang
if err := xxx; err != nil {
}
```
Thx for the fix!
seems testdata.IrisHiveSQL is not added to commit?
Thanks for the suggestion. I think `testdata.IrisHiveSQL` is in the commit.
delete the debug code ?
Sure.
Sure.
I find myself adding and deleting this line every time I try to debug CI. So I think it is helpful to keep it.

In deployment, this line will be skipped, since we only do `log.Error` and `log.Warning`. :) 
If you really want to capture all outputs (stderr + stdout), you can replace `os/exec.Run` by `os/exec.Output`, without the need to create `errBuf`.

However, the problem is that either method (setting `cmd.Stderr` to a buffer or calling `os/exec.Output`) might cause memory overflow when the output is lengthy.

What I have in my mind is to write a io.Writer implementation which keeps only the most recent N bytes. And call it like the following:

```go
cmd.Stderr := NewLastNBytesBuffer(N)
```
Maybe something like

```go
type LastNBytesBuffer {
    *bytes.Buffer // inherits all methods from bytes.Buffer.
    n int // the fixed-size.
}

func NewLastNBytesBuffer(n int) *LastNBytesBuffer {
    return &LastNBytesBuffer{new(bytes.Buffer), n}
}

func (w *LastNBytesBuffer) Write(s []byte) (int, error) {
    if w.Len() + len(s) > w.n {
        if len(s) > n {
            w.Buffer = bytes.NewBuffer(s[len(s)-w.n:])
            return len(s), nil
        } else {
            w.Buffer = bytes.NewBuffer(w.Bytes()[w.Len() + len(s) - w.n:])
            return w.Write(s)
        }
    }
    return w.Write(s)
}
```
I thought too much more than needed -- this is just for capturing errors from `tar`, which couldn't be too much.
Just curious about is indexing reader like `r[i: i+expected]` read only a part from the table?
Can remove this line
I think this is just a hotfix right, maybe should refine the `insert` function to insert predict result with original feature data.
Sure. I just recovered it by the former code here.
It would be great if we can add a comment here explaining the requirement of the certain version.
The comment is on top of `RUN` line since we cannot add a comment inside one `RUN` command.
There is a problem with this change, as it makes our parser accepts the following writings


```
TRAIN DNNClassifiere LABEL a INTO model1
TRAIN DNNClassifiere LABEL a INTO model1 LABEL b INTO model2
TRAIN DNNClassifiere LABEL a INTO model1 LABEL b INTO model2 LABEL c INTO model3
```

However, we want only one LABEL clause and one INTO clause.

My understanding is that we may not change too much of the rule train; instead, we might want just a little change from `COLUMN columns` into `column_clause`:

```
train : TRAIN IDENT column_clause LABEL IDENT INTO IDENT
```

where 

```
column_clause
: COLUMN exprlist
: column_groups

column_groups
: COLUMN exprlist FOR IDENT
| column_groups COLUMN exprlist FOR IDENT
````

Please be aware that the above rules don't accept

```
COLUMN a, b COLUMN c, d
```

which is what we want.
If `name` is the identifier after `FOR`, I think it would be better named `target` or `purpose` than `name`.
I vaguely remember that the `JSON` functions were for some old purpose are no longer needed. Could @tonyyang-svail please confirm.
Right. It's safe to remove it. :)
Thanks for pointing that out, it's indeed a problem, will fix it.
Ok
As your suggestion, I have recovered the rule of `train_clause` and do the change only in `column_clause`.

Because I don't want to do the restriction that the location of `COLUMN ... FOR` must be after the anonymous `COLUMN` or there must be only one anonymous `COLUMN`, the rule of `column_clause` looks like this:
```
column_clause
: COLUMN columns
| COLUMN columns FOR IDENT
| column_clause COLUMN columns
| column_clause COLUMN columns FOR IDENT
```

If there is more than one anonymous `COLUMN` or `COLUMN`s which have the same `FOR IDENT`, the latter one makes effects.

@wangkuiyi What do you think? 

cc => columns, or some other more meaningful name.
Why do we need the assignment to `cols`? Can we have just one line as the following?

```go
	fcList, fsMap, err := resolveTrainColumns(&(pr.cc[""]))
```

There are a few more cases below.
This COLUMN clause doesn't have the FOR keyword. Is that alright?
cc => columns or some other more meaningful name.
If there is only one column in the column clause, and there is no FOR in that column, how do we handle the case? Are we going to have only one entry in the map[string]exprlist and the key is ""?  If so, please add a comment here to explain.
We can merge the above two lines into 

```go
$$ = map[string]exprlist{"" : $2}
```
Again,

```go
$$ = map[string]exprlist{$4 : $2}
```
You are right, will add a comment here.
Ok
That's alright, the `FOR` keyword is optional.
GO forbid to take the address of a `map` member because of the address may be invalid if the map grows or shrinks. 
Ok
Ok
Ok
This rule accepts the case that the first COLUMN doesn't have FOR but the subsequent COLUMNs have FORs, like the following example:

```
COLUMN a, b COLUMN b, c FOR in1 COLUMN d, f FOR in2
```

However, I think it is alright at this time. If we realize we do need more strict grammar rules, we can change later.


Since we are removing sql_data and the test, should we move the readme.md under submitter folder? Or we will rename python folder to submitter and move python code on level up
Better to use "./" so it will be more meaningful
remove commented code
Should output using log, see `log.go`
done.
"./" is also a director name, how about representing **don't save model on the local file system** using empty string "" ? 
That will be hacky too I think, since the argument is called `xxxDir` it should behave like a directory, "./" and "" should both mean current directory here. use "./" is more meaningful in the code.
`image_build.sh` => `build.sh ` or `build_sqlflow.sh` ? It doesn't build the Docker image.

Maybe don't need souce pyenv here? It's already configurated in the Dockerfile: https://github.com/sql-machine-learning/sqlflow/pull/494/files#diff-3254677a7917c6c01f55212f86c57fbfR11
Remove this will cause CI error. Not sure why.
`build.sh` and `build_sqlflow.sh` seems to be a name that build all sqlflow binaries. Can't find a better name than `image_build.sh` I think?
`/miniconda/bin:/miniconda/envs/sqlflow-dev/bin` => `/miniconda/envs/sqlflow-dev/bin:/miniconda/bin`.

Otherwise, `sqlflow-dev` virtual environment's Python will be hidden by `/miniconda/bin/python`
@typhoonzero https://github.com/sql-machine-learning/sqlflow/pull/494/files#r291730654
Please remove `source activate sqlflow-dev`
Please remove `source activate sqlflow-dev`
Please include this fix the `image_build.sh`. Jupyter server needs this.
Are these two `export`s necessary?  I found they are already specified at 

https://github.com/sql-machine-learning/sqlflow/blob/24c22aa4592d27450f1c049cbd0141cd3b1428c5/Dockerfile#L10-L11

If the `ENV` doesn't work. You may need to also export `IPYTHON_STARTUP` here.
Move to `numpy==1.16.1 \ # keras.datasets.imdb only works with numpy==1.16.1`
shall we `cd ..` at the end of this function? Just in case, later on, we wanna add command after `setup_sqlflow_notebook`.
Tested, this will cause `ERROR: Invalid requirement: '#'`
I see. Please ignore my comment.
Thanks, done.
done.
Done.
Awesome to highlight part of the real code.
The iterator in the loop calls [function: read](https://github.com/aliyun/aliyun-odps-python-sdk/blob/master/odps/models/instance.py#L808) which returns a generator here to read records on demand.
Better to use relative paths? Former code redirect from `/` so that it was not working I guess.
I see.
Relative paths work on the markdown file but won’t work on the actual website since the source code is not available under https://sqlflow.org. It depends on how the website is set up. As I mentioned in the description, this should be a temporary solution so at least no 404 is returned.
"save the model to SQL engine as a human-unreadable table if this option is empty"
Is it a better idea to create the modelDir in `sql.Run` than here in `main`? I vaguely feel that it is easier to maintain the code if we allocate the resource right before we use it.
The fact is that currently, our parser doesn't accept anything statements other than SELECT. It will support parsing any SQL statements and even dialects in the future.

I think we can either copy-n-paste the above explanation after the call to `a.Error(e)` as a comment, or simply remove this test.
Sure. Copy-n-pasted the explanation.
catIDColumn => categoricalIdColumn
catID => categoryId
CAT_ID => CATEGORY_ID
typo `Luanch`
insecurate => insecure
thx, done.

thx, done.

If CreateRPCConn is going to be used out of this unit test, it should be moved to somewhere else. Otherwise, it should not be an exported symbol and should be renamed to createRPCConn or connect.
It might make the code more readable if we move L59-L71 into a new function `newServer(caCrt, caKey string) *grpc.Server`.
Given the fact that we always call `ioutil.TempDir` and `generateCA` together, how about we merge them into one:

```go
// generateTempCA creates a pair of CA certificate and key in a temporary directory. It is the caller's responsibility to remove this directory.
func generateTempCA() (tmpDir, caCrt, caKey string, err error) {
```

So we can call it as

```go
tmpDir, caCrt, caKey, err := generateTempCA()
defer os.RemoveAll(tmpDir)
```
Thanks, done. `createRPCConn ` is only used in `main_test.go`
Done.
Done.
Good idea.
SQLFlow needs a model directory only a SQL is extended.
Since the `execute` is removed, we may remove it from the [import line](https://github.com/sql-machine-learning/sqlflow/pull/510/files#diff-a9c90abc2107d6cd0f30e093777900bfR200) either. 
What is more, I would suggest move the `execute` from `db.py` and `maxcompute.py` to `db_test.py`.
I like this good practice!
This hard-coded `insert_batch_size=64` probably needs to be exposed to users?
Thanks, this should be chosen automatically, added TODO comment.
Done.
Is it related to the hive server?
Should we change the version number here as a hive server's version is 1.2.1?
Yes, I tried. It works with Hive 1.2.1 too. I will update the version in the next PR. Thanks for the reminder.
After ran
```bash
java -jar target/hiveql-parser-1.0-SNAPSHOT-jar-with-dependencies.jar < (echo "select count(*) as count, myfield from &0rz") 2>/dev/null
```
I got result: `bash: syntax error near unexpected token `('`
I see, `<(` cannot be separated by a space.
Will fix this by changing the command line into `-jar target/hiveql-parser-1.0-SNAPSHOT.jar` in the next PR. Thanks for the reminder!
I think `DENSE` and `SPARSE` only work for ALPS. You can refer to the generated code at https://github.com/sql-machine-learning/sqlflow/pull/502#issuecomment-501077347 where `DENSE` and `SPARSE` are translated to `DenseColumn` and `SparseColumn` in `DataX`, instead of `tf.feature_column.*` in the model constructor.

@uuleon I am not sure if ALPS has a plan for releasing these `DENSE` and `SPARSE` as part of the extension for feature column.
Here should use `Response` instead of `Reply`? Also for the following one
configration -> configuration 
1.7 or 1.8? 1.6 seems too old.
Got it. Will fix them in the next PR.
Got it. Will fix in the next PR. Thank you for being very detail-oriented!
I see. Will change to 1.8 in the next PR!
You may use local sub project dependency which do not need care version if the whole project share same release version. Same in hivesql
Move all same plugins into parent pom 
Any reason to use inner class here?
blank line is unnecessary here
Would you mind to org dependencies to 3 sections? Java system, third party, sql flow
Unused variable sqlNode
Unused sqlNode
move all version to parent pom, so there is one central place to manage all dependencies’ version.
Do you need main to start server?
Use logger 
Use logger 
All review in calcite Pom May apply here too
Unused variable node
Unused variable node 
I have no idea what is a local subproject. May I have some examples?
Got it. Will do in the next PR.
I see. I will do in the next PR.
No idea. Will move it to an outer level in the next PR.
Will enable http://www.jutils.com/ and google-java-format in .pre-commit in the next PR and fix all such problems.
Got it.
Will set up lint tools in the next PR.
I see. Will do.
I think so. Just the main function would not throw that many exceptions, because I catched them already.
Will do.
Will do.
I see. Will do.
Will remove.
Will remove.
Thanks for reminding, I am moving on to make this resolver work for both submitters in later PRs.
Just curious, is gRPC java protobuf-compiler plugin requires protoc `v3.7.1`?
No. It works with 3.6 too. Just trying to keep everything up-to-date.
Cool.
SQLFlow extends the syntax of the SELECT statement of SQL to support training a model:
Currently, we have the following syntax allowing users to provide necessary information for the training.
SQLFlow server passes the above information to code generators like `sql/codegen.go` and `sql/codegen_alps.go`, which generates the training program.
In this document, we summarize information necessary for the code generators.
```
## Necessary Information for Training
```
What's the shape of `numeric` column, should it always be a scalar?  Actual training shape should be `(batch_size, 1)`
cat_id -> categorize

and, why always need bucket size, the column may be enumerated, like `Male, Female, NULL`
should we also support `sequence(filed, padding_size)`?
maybe add data samples to indicate the column type?
We would also like to support keras models, and the generated code could have a lot of difference than estimator code. Will the "resolver" also consider dealing with keras models?
`resolving.go` is not telling what to resolve, maybe `resolveTrainClause.go` is better?
In the original design, the `cat_id` is short for `categorical_column_with_identity ` which needs `bucket size`. Does renaming to `categorize` means it has to support all the APIs of `categorical_column_*`?
It should be a list of integer, thanks.
I was thinking maybe to support resolving `predictClause` in the future.
It is in the `sqlflow/doc/alps_submitter.md`.
Thanks, fixed.
What's the `ClientEndpoint`?
I'm not sure if a user inputs the credential in the notebook is a good way, due to such credential information might be exposed. 
Don't mind too much about this, just take it as a reminder.
Should we consider the expired time to eliminate those `zombie` sessions?
Usually means `IP:port`, see: https://docs.oracle.com/javase/tutorial/networking/sockets/definition.html
Well, we should let user set the application keys, usually access key and secret key, please refer to: https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html and https://usercenter.console.aliyun.com/#/manage/ak
We should! Thanks!
Maybe we can implement the Authentication and Authorization separated, for my brief idea:

![image](https://user-images.githubusercontent.com/1426912/59276331-b0bf0a00-8c90-11e9-8d62-577a2c986f95.png)


1. Uses can go the SQLFlow website such as `https://sqlflow.domain.com`, the auth-server would process the request and check the user.
2. If the user has not logged in, auth-server would redirect to the SSO URL with 302 redirections.
3. If the user has logged in, the SQLFlow auth-server (maybe another name) would launch the notebook Pod if not exists with the user token as environment vars, and then redirect to the notebook URL.
4. notebook would call the SQLFlow server with Session struct (fill the user token)
5/6. SQLFlow server instance would auth MySQL/kubernetes and etc. with the user token.

Updated the design with some modifications.
Is the schema "mysql://" what we invented to help identify the *kind* of SQL engines? I ask because I think an address of MySQL server is something like `http://user:passwd@127.0.0.1:3306`, but not beginning with `mysql://...`.

If so, how about we have

```protobuf
DBKind string // can be "mysql", "hive", ...
DBConnStr string // e.g., "http://user:passwd@127.0.0.1:3306"
```
Good to know that Django has so many features. Do we need to write code on top of Django, or we only need to configure and run the Django server for authentication?
Why should SQLFlow use SSO? What are other choices?
Do we need only one pair of AK and SK? Or do we need multiple pairs, like one for the SQL engine and the other one for Kubernetes?
What is a side-car design?

Does the token identify an SQLFlow service user who has logged in?
Is the above figure illustrating the case of "with a simple jupyter notebook", or the "production deployments"?
I am confused by "the web IDE". Is it the Jupyter Notebook server? Or the SQLFlow magic command? How about let's be very specific and use "Jupyter Notebook server" or "the SQLFlow magic command" to replace the phrase "the web IDE"?
Does the "to create a new session" imply that we need to change the gRPC service definition to add a remote call named `SQLFlowService.CreateSession`?
I assume that we should clarify the concept of the "client" in this section. A client of SQLFlow server might be the SQLFlow magic command, which is an extension to Jupyter Notebook server, or a Windows-native or macOS-native GUI program. It looks to me that we introduce an authentication server because we want to support both kinds of clients?
Why would "the web IDE" redirect a user to the SSO service"? Is it configured to do so? Could users use Jupyter Notebook as their "web IDE"? If so, how should they configure it to work with SSO? And, how comes the SSO service? Who is supposed to build it?
I know how to connect to a Jupyter Notebook server running on my laptop -- I need to copy-and-paste a URL containing a token printed by the Jupyter Notebook server on my console into my Web browser, so could I access the server while identify myself. However, I don't understand how am I supposed to identify myself to a Jupyter Notebook server running remotely as part of a Kubernetes service. Do you know how could we do that? Or, does this document imply that there is a Jupyter Notebook service there on a Kubernetes cluster?
To where "the session will be stored"? To the etcd cluster?
> Is the schema "mysql://" what we invented to help identify the kind of SQL engines?

Yes. The string before `://` is the "driver string, can be `mysql://`, `hive://` or `odps://`
Oh, I need to delete these lines, the latest design does not involve a Django server. All the authentication and authorization should be done by the jupyter notebook
Yes, I'll add the new RPC defination in this doc
@wangkuiyi I've updated the design doc on the basis of recent surveys.
Removed, it's not useful anymore.
Done.
Using JupyterHub, we can add any type of authenticators including SSO, Kerbros, etc, :https://github.com/jupyterhub/jupyterhub/wiki/Authenticators
Removed all "web IDE" stuff and move to "JupyterHub"
Maybe change to "Contribute to SQLFlow Models"?
How about 
- "SQL Engine communication" => "Database community"
- "ML Engine community" => "ML community"
Looks like `go present` doesn't support nested bullet point.
![Screen Shot 2019-06-19 at 3 17 45 PM](https://user-images.githubusercontent.com/29932814/59806184-5b928200-92a8-11e9-8323-8dd9e084f2c0.png)

Not sure we need to present the challenge in an introduction oriented slide.
Maybe move the second slide `* SQLFlow Open Source Community` here. So we can present our git workflow right after the introduction of the open source community.
The *feature column* is related to the models, maybe users also would like to know how to support the certain feature type or how to custom the feature type, we can also listen to our users, how about changing the title to `Feature Column`

done.
done.
Maybe  "ML community" is too wide? Seems we only consider the ML System/Engine here.

Need to kill this `sqlflowserver` process when the test is finished, because mutiple test scripts need to run.
How can use one line code directly in `.slide` file?
Looks like `test_e2e.sh` is ran in an isolated container. I am wondering: after the execution of `ipython sql/python/test_magic.ipy`, will Docker stop the container by killing all the running process?
Yes, The Travis would run these test scripts in the separate Docker containers, maybe we can execute these test in one Docker container in the future.

  
What happens if `db == nil`? Or, should we change to
```go
if db == nil {
        return nil, fmt.Errorf(...)
}
odpsConfig, err := gomaxcompute.ParseDSN(db.dataSourceName);
if err != nil {
        return nil, err
}
```
`db == nil` happens in UnitTest
Maybe add a global settings variable when starting the sqlflowserver process.
sessionDB => `getCachedDBConn`

and should add a global mapping to store the cached connections.
maybe also need to test sending session message throught RPC
done.
Maybe we can enable session when the Flag `--datasource` is an empty string, that we don't need another new flag.

FYI, the Hive driver and ODPS driver don't maintain long connections on each `DB` object. So adding cache may not help on the performance.
The cache is nothing related to "session struct". It should be in a separate PR, one with thorough unit test and a benchmark to verify the performance improvement. Please remove the cache from this PR.
Not only the performance,  to cache the `DB` object can save the SQL context, such as `USE DB1` if we can load balance the requests to the same SQLFlow server instance according to the `Token`. And as the comment: https://github.com/sql-machine-learning/sqlflow/pull/530#discussion_r296898832 ,  I will remove the `db_conn_cache` from this PR, and implement it in another PR with a benchmark.

Done, removed the `DBCache`.
done.
Is it right to name this struct `Session`? Should we rename it into `Cookies`?

According to https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies

> An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to the user's web browser. The browser may store it and send it back with the next request to the same server. 

It sounds similar to what this struct is meant to.
Good catch!
@uuleon why do we need to test `db == nil`?
Better to change code templates to indent using 4 spaces for all lines.
Better to print the desired format when got unexpected inputs.
I am using `expression_resolver` in `codegen.go` too, and seems `ColumnSpec` is only used for `DENSE/SPARSE` columns in ALPS, it'll be good to separate `ColumnSpec` and `FeatureColumn` structs.
Seems `session` is more appropriate: 
1. a cookie is the concept of HTTP proto, a session is the Broader concept, according to https://en.wikipedia.org/wiki/Session_(computer_science)
     > a session is a temporary and interactive information interchange between two or more communicating devices, or between a computer and user

1. We also want to store the SQL context on the server side in the session struct in the future,  and the cookie is stored on the browser, according to the design: https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/auth_design.md#session 

1. This PR is a crude implement of Session, hasn't included saving the context on the server side, because of: 
    >  the Hive driver and ODPS driver don't maintain long connections on each DB object

    according to the comment: https://github.com/sql-machine-learning/sqlflow/pull/530#discussion_r296859071 , and I think we need to implement this in the future.

Just curious, is the parenthesis necessary of the if template? 
Yes, tested on my environment. Or the number `-1` will be recognized as an argument of the function call `.TrainClause.MaxSteps`
可以不设置，因为不设置表示自动从X/Y中推导出来。
OK, will remove this fixme comment in next PR.
To avoid this additional user creation step, you may wanna config `dummyauthenticator` by https://github.com/jupyterhub/kubespawner/blob/master/jupyterhub_config.py#L32 .

Please remember to install it using `pip install jupyterhub-dummyauthenticator`
[ref](https://github.com/jupyterhub/dummyauthenticator)
I'm not sure we can use the DummyAuthenticator to demonstrate the SQLFlow on k8s, seems PAMAuthenticator is more similar to the production environment.
Unfinished line?
Maybe add tips about configuring this with care in production env.
done.
done.
Use [pre-commit](https://pre-commit.com) to automatically fix style checks.
TODO comment should look like `// TODO(user): ...`
Need to get `feature_map` table name from SQL
Is `Metadata` for getting `columnSpec` automatically, not by using SQL lines in `COLUMN` clause?

Can we use `COLUMN` clause first and move to this auto way in another PR?
@joyyoj could you please add `metadata_test.go`?
How is this function different from 
https://github.com/sql-machine-learning/sqlflow/blob/3867f64c17e852671acadc5d4ab6d68438aba5cc/sql/expression_resolver.go#L641-L644
We use [logrus](github.com/sirupsen/logrus) to log errors
https://github.com/sql-machine-learning/sqlflow/blob/3867f64c17e852671acadc5d4ab6d68438aba5cc/sql/executor.go#L149
`defer sqlDB.Close()` should follow `sql.Open(...)`

fixed
Talked with @joyyoj , that this feature seems needed for the model we are going to support.
Can remove this line.
Maybe can call one function here to wrap generated code to a list like:
```go
return ToOneElementList(nc.GenerateCode)
```
can remove commented code.
GenerateCode return (string, error)
GenerateAlpsCode return ([]string, error)
for multi group,
category_column(deep) needs return category_column(deep0), category_column(deep_1) ...
so i introduce generateAlpsCode.

I thinks GenerateCode be a function of feature column is a bad idea. GenerateCode should be a part of physical-plan.
i think `defer sqlDB.Close()` should not be called if error occurs ?
Encouraged by:
https://github.com/go-sql-driver/mysql/wiki/Examples#a-word-on-sqlopen
forgot it
should process variable `MAXCOMPUTE_AK` as secure variable: https://docs.travis-ci.com/user/encryption-keys/
I configurated the `MAXCOMPUTE_AK ` in the Travis env and the Travis would process the env as a secure variable: https://docs.travis-ci.com/user/pull-requests/#pull-requests-and-security-restrictions 

The build logs like:
``` text
Setting environment variables from repository settings
$ export DOCKER_PASSWORD=[secure]
$ export DOCKER_USERNAME=[secure]
$ export MAXCOMPUTE_AK=[secure]
$ export MAXCOMPUTE_SK=[secure]
```
How about using the explicit separator, such as COMMA =>`","` it's better to support the other separators: `|`, `\t`
We use "," to identify the `COLUMN` clause and get the parts of the clause, so setting delimiter to a comma to use an identifier like `COMMA` or `TAB`
Looks like with `exit=False` flag, the python test will exit with code 0 even though the tests have failed.
`test_e2e.sh` is running inside a separate container, the `iris.train` is not populated
`.` will match any character. What we want is the exact match of character `.`.
does that mean should `\.` also works?
One thing to discuss is, whether we need to involve `featureSpec` in `codegen.go`, in `codegen_alps.go` `featureSpec` and `featureColumn` are both needed to:

- `featureSpec`: Used to generate code for `input_fn` and dataset
- `featureColumn`: Used to generate `feature_column` code to pass to `Estimators`

for one column, `DENSE(col)` and `NUMERIC(col)` must both appear to generate correct code, and it's a bit hard to use.

So I'd like to consider use only one structure to store all column's meta information.
> So I'd like to consider using only one structure to store all column's meta information.

Sure, I will try to implement it as `NUMERIC(field_name, 4)`.
Done.
maybe use data `text_cn.train_processed` to test dense column with delimiter?
I think one advantage of using `iris.train_dense` is we are able to check the training accuracy.
I mean, both tests are needed to cover dense column with a delimiter and without should be helpful. Thanks!!
maybe the name `CustomEstimatorImportCode` make more sence?
What if `SELECT *`?
please clean commented code
I think ImportCode is better for it is more general. It's probable not limited to custom estimator imports In future.
I know this problem. I try use 'desc table' clause to get fields but maxcompute report "not support instance type". I add a TODO here.
Use `select * from table limit 1 `clause to get fields. if table is not empty, it works
Cool~
How about we change it to `close(driver, insert_curser)` and in the `db.py`, we add
```python
def close(driver, insert_curser):
    if driver != "maxcompute":
        insert_cursor.close()
```
So that we can avoid `if driver != "maxcompute":` in the codegen_template.
Is there a way to let the submitter just return the yarn job URL and exit? then the status can be fetched on the web page and do not wait on the sqlflow client (e.g. jupyter notebook)
I can modify to exit immediately, but how the web page can get the status?
~~do we need~~
```python
if driver != "maxcompute":
    cursor.close()
```
~~here?~~
Will find out why keras model predict will hang at the end using `tensorflow==2.0.0b1`
typo `pred_gen = gen = ...`?
For the record, maybe file an issue.
Added in https://github.com/sql-machine-learning/sqlflow/issues/573
comment here why hard code batchsize=1?
Will add in next PR
Curious why need to `++` the shape?
Maybe add comments that user column definitions are used firstly.
Should add todo comment here, we can use the parser to do mostly these validations work.
fixed
typo: broken link.
Markdown doesn't support merged cells, HTML does:
<table>
  <tr>
    <th colspan="4">temp_table</th>
  </tr>
  <tr>
    <td>col1</td>
    <td>col2</td>
    <td>col3</td>
    <td>train_val_split</td>
  </tr>
  <tr>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>0.3</td>
  </tr>
  <tr>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>0.9</td>
  </tr>
  <tr>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>&lt;data&gt;</td>
    <td>0.5</td>
  </tr>
  <tr>
    <td>...</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</table>
Maybe the intro could be a little bit more concise like:

"A common ML training job usually involves two kinds of datasets: training data and validation data. These two datasets will be generated automatically by SQLFlow through randomly splitting the select results."
Training and validation belong to one Python program. The program's pseudo code looks like

```python
for step in range(10000):
    model.train(batch_data)
    if step % 1000 == 0: # validation will be run 10 times in a training job
        model.eval(val_dataset)
```
1. Maybe elaborate on how we generate the temporary table name. Something like `fmt.Sprintf("temp_table%d", rand.Int())`.
1. Which database does the temporary table belong to?
No need to split runExtendedSQL. Training and validation belong to one Python program.
Add a drop table section.
For TensorFlow submitter, we generate training dataset and validation dataset according to `extendedSelect.training` and `extendedSelect.validation`.
Done.
1. I agree with generating an elaborate name for the temporary table. Because multi-users run SQLFlow with their own isolated dataset at the same time.
2.1 For common databases, like MySQL. SQLFlow creates a temporary table with the attribute [TEMPORARY ](https://dev.mysql.com/doc/refman/8.0/en/create-temporary-table.html), and we don't need to specify an existed database name.
I also made a test in hive: `CREATE TEMPORARY TABLE what_ever_tbl AS SELECT *, rand() AS rdm FROM iris.train;`, It works.

2.2 For Maxcompute.  SQLFlow saves the temporary table into the `current project`  which must be specified by the user.

Plus, we do not have to test if the temporary table exists for common databases. Let me add some details to this doc.
database?
Maybe we can generate a different random number for each epoch, that can make the train/validation more exhaustive:
1. start an epoch and random range: [a, b];
1. train with `sqlflow_random < a and sqlflow_random > b`
1. validation with `sqlflow_random >= a and sqllfow_random <= b`
1. re-random [a1, b1] and back to step `1`

more methods about the cross-validation: https://en.wikipedia.org/wiki/Cross-validation_(statistics)

I am afraid `TEMPORARY` doesn't work in our case. From the documentation

> You can use the `TEMPORARY` keyword when creating a table. A `TEMPORARY` table is visible only within the current session, and is dropped automatically when the session is closed. 

We create tables in Go and read the contents in Python. They are different sessions. Therefore the Python session can't see the temporary table created by Go.
Please change the link to the public doc: https://www.alibabacloud.com/help/doc-detail/55297.htm

Some training jobs take more than a day. How about setting it to 14 days? I vaguely remember the default lifecycle of a Maxcompute table is 14 days?
Why not use this column directly, for cases that the dataset is already partitioned to training set and validation set like IMDB.
`If no lifecycle is specified, the table or partition cannot be automatically recycled by MaxCompute.`
14 days is enough. Also, `lifecycle` can be adjusted.
For common databases(excludes Maxcompute), I turned to save the temporary table to sqlflow_workspace(a database maintained by SQLFlow)
I'm not sure if the existing sqlflow_random's data type or randomness will help to split.
The method that Yancey1986 proposed here seems better. No tmp table needed.
I think @typhoonzero means the users should be able to specify which row to be used as training or validation by deliberately adding the sqlflow_random column.

So for SQLFlow, if sqlflow_random already exists, it should use it directly.
> we can generate a different random number for each epoch

@Yancey1989 I am not sure it is common to change training&validation dataset during a training process, it lets the model see the validation data... The k-fold cross validation I learned in college usually runs the whole training process k times.

> The method that Yancey1986 proposed here seems better. No tmp table needed.

@joyyoj  Looks like we still need to construct a temporary table by adding the sqlflow_random column. 
Maybe add a link to what "iris" is and what the features stand for.
transpile => translate ?
Into clause?
Actually, feature columns descriptions also include descriptions of feeding and processing input data (delimiter, shape).
Good point.
I feel "transpile" is better since SQLFlow does verification of the statement.
Sure.
typo: optional preprocessing
Thanks. Fixed.
Unnecessary `\n`
=> `logger.info("Server started, listening on %d", port);`
The table in the `maxcompute` may not exist or without reading permission, why not creating a temporary table with fixed data before test running? 
Good shot, will do
Done
Should we use `TO TRAIN` to minimize the possibility that `TRAIN IDENT WITH` are all column names? It's a very tiny chance that this could happen but what we need should be a 100% sure the statement is split as we expected.
NOTE: related PR: https://github.com/sql-machine-learning/sqlflow/pull/583
`TestEnd2EndMySQL` also starts an SQLFlow server. They will conflict on port 50051.
Good point.

@wangkuiyi could you please file an issue explaining why we need to change from `TRAIN` to `TO TRAIN`? Then I will submit a PR to fix that issue.
Thanks for fixes!
Capitalize the first letter in the titles.
This is a design doc, the title and file name should be like `# Design: ....` so that readers won't think it's a tutorial or manual.
I am not sure if XgBoost is compatible with `tf.feature_column`. What kind of feature columns are you planning to support?
Please add the documentation links of these features. Maybe also note how these features will benefit SQLFlow users.
SQLFlow hasn't supported `AS` keyword yet.
I am no expert in XgBoost. Is it common to bucketize input when training a tree model? I feel a tree model is able to learn the decision boundary.
Similarly for `CROSS` feature. Looks like cross feature is equivalent to a multi-level tree, I feel a tree model is able to learn the cross.
There is no `COLUMN` clause in prediction.
Please add the documentation links of "an extendable, cloud-native XgBoost based machine learning pipeline".
Maybe add a "Distributed training" section.
Add a few sentences summarizing the content of this doc. [ref](https://www.freecodecamp.org/news/how-to-write-a-good-software-design-document-66fcf019569c/)

> A high-level summary that every engineer at the company should understand and use to decide if it’s useful for them to read the rest of the doc. It should be 3 paragraphs max.


Please be consistent on the naming: `xgboost`, `XGBoost` or `XgBoost`?
How is this class different from XgBoost's `save/load`? [ref](https://xgboost.readthedocs.io/en/latest/python/python_intro.html#training)
We want to support as many `feature_columns` as sqlflow semantic does.
Although feeding xgboost with vectorized features like bucketized vectors is not always a good idea, xgboost can handle them anyway.  Since linear model is available in xgboost as an alternative to tree model,  I think it is reasonable to train xgboost models with vectorized features.
`ModelSource`is a wrapper of `booster.save/load`,  it integrate saving work of booster binary, booster info and  feature scores.  The purpose of `MdoelSource` is providing an interface to save/load xgboost models on different stores. 
Here is the full implemention:  https://github.com/alipay/ant-xgboost/blob/ant_master/xgboost-launcher/launcher/model_source.py
Bucketization helps the training process; it's a standard technique used by almost all boosted tree implementations. The question here is whether a user should explicitly do bucketization. I know some cases where bucketization is done on user side so this actually looks okay to me. If you think it adds confusion, we can take it off from this example?
Agreed tree can automatically learn feature interaction, although empirical study often finds adding human-crafted interactions can further improve accuracy.
Doc of xgblauncher will be available in antxgboost soon.
I am curious why XgBoost's `save` doesn't save the booster info...
Sure, you can find the list of currently supported feature column here: https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/user_guide.md#feature-columns.
Great. Let's keep it in the example since `BUCKETIZED` is commonly used.
Cool, let's take `CROSS` off since AntXgBoost is aiming for full AutoML.
Currently, SQLFlow using the env `SQLFlow_submittor` to support the different submitters(`alps` for ALPS lib or Tensorflow Keras by default): 

https://github.com/sql-machine-learning/sqlflow/blob/317ef496f36f5412f47d9f56ba894d590844bfa4/sql/executor.go#L223-L225

Maybe we can follow this logic instead of using the prefix of the model name. In addition, SQLFlow will support the different backend by passing  the `submitter` field in the Session struct: https://github.com/sql-machine-learning/sqlflow/issues/539 
_Tensorflow_  => TensorFlow
We can save the column info while saving the model so that don't need to specify the COLUMN repeatedly in the PREDICT statement.
@sperlingxx , I found [xgboost operator](https://github.com/kubeflow/xgboost-operator), do you have any experience on it? Or maybe you have some best practices about distributed xgboost?
Sounds great!

@tonyyang-svail  I have reorganized the doc, splitting it into _overview_, _context_ and _proposed solution_.
Using `log.panic` instead of `panic`
This would change users' habit, for the current implementation,  `.. TRAIN modelname ...` would train the [premade estimator mode](https://www.tensorflow.org/guide/premade_estimators), and `... TRAIN sqlflow_models.modelname` to train the [SQLFlow models](https://github.com/sql-machine-learning/models) which defined by Kears API.

Maybe you can create an issue first to discuss how to distinguish **TF Estimator Model**. ** SQLFlow custom model**, **XGBoost** and **ALPS**, after that we can implement this feature and update the user guide doc also.

In this PR, maybe we can use the prefix `XGBOOST` to train the XGBoost model, and TF model by default. 
Maybe `estimatorKey` is not a meaningful name.

Upper the struct name if it's public.

Better to not use capitalized words in the model name, to fit the general SQL rules that not case sensitive.
Currently, `ALPS` uses the environment variable `SQLFLOW_submitter` to determine which `codegen` to use, maybe we can also use this pattern here.
@typhoonzero  
Maybe environment variable approach is not friendly to users? 
What's more,  I think `xgboost generator` can share a lot of information (such as `filler`) with default `TF generator`.  So, I try to split codegen into two stages.
We need an explicit way to distinguish the generator, the env or the estimator prefix.
 
I think implement a common `Filler` struct is a wonderful idea, and maybe we need to think about it with  `AlpsFiller`, `TFFiller` and `XGBFiller`. 

And @sperlingxx can you separate this into two PRs:
1. Implement an independent `codegen_xgboost` like `codegen_alps`, and than
2. Refactoring the Filler struct.


other backends.
@Yancey1989 xgboost operator is good for distributed xgboost training and batch prediction. xgboost operator would help sqlflow-xgboost distributed xgboost training on k8s.  
@sperlingxx 
> Maybe environment variable approach is not friendly to users?

Seems so, should let user to choose the model to train, for ALPS it's another case. And, Agree with using independent `Filler`s.
This function is quite the same as `train()`, curious why we need to add this function now?
I filed 4 related PRs to implement the whole design. And this function used for a placeholder appears too early in this PR.
I'm taking it to the next PR.
Can remove this case, we don't support other drivers except for MaxCompute.

should remove this
delete or use log here.
maybe need a meaningful name, what's `cdr` stands for?
Maybe `AS` can also be used as standard sql aliases: https://www.w3schools.com/sql/sql_ref_as.asp, can add another case to test this case so that the parser will be a little more general.
done.
done.

Change to `Strings()`
Good practise.
I left a TODO comment, will implement it in the next PR, and maybe have some discussion with https://github.com/sql-machine-learning/sqlflow/pull/591
Is `supported` field necessary?

- If a database DOES support `namingTrainingDataset`, `supported` field is always true.
- If a database DOES NOT support `namingTrainingDataset`, the function should raise an error.
Minor suggestion: how about returning `(*trainingDataset, error)` with the pointer, so that we can use `return nil, e` on error.
maybe use the name `trainAndValDataset` ?
Also, this source file name `validation.go` seems is not what this file does.
> Also, this source file name `validation.go` seems is not what this file does.

Good point. How about `split.go` or `create_train_val.go`?
`supported` is a temporary variable for `codegen`. Here it used to avoid damage to `CI`

https://github.com/weiguoz/sqlflow/blob/5618433e2490ed50b72d48af06d77eef6d18ca72/sql/validation.go#L24-L27

Just feeling confusion: does `submit_experiment` equal to `run_expriment`?
just a bug in alps.
This only works for keras models, can set `tf.get_logger().setLevel(logging.INFO)` if `verbose>1`?
Good point, will do that in the next pr.

Good point! Should merge with https://github.com/sql-machine-learning/sqlflow/pull/609
Please remove the debug code.

Please delete the unused code.

Add a unit test for the infinite bug or merge https://github.com/sql-machine-learning/sqlflow/pull/611 firstly? 
Done.
Is there a way to drop the temp table after the training is finished?
PR([release resources](http://gitlab.alipay-inc.com/Arc/sqlflow/blob/develop/docker_alps/Dockerfile)) will take over it, but I would like to use [LIFECYCLE](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/training_and_validation.md#release-the-temporary-table) to handle it for Maxcompute at this time.
Make sure `odpscmd` a public available program.
standard?
Can reuse `ModelDir` ?
curious why not `PREDICT IDENT  WITH attrs` ?
Does this line mean we can write multiple `USING`?
I copied the link from Aliyun, I think it's a public program.

Fixed it.

done.
Yes, fixed it.

Done, and found some same syntax bug, such as `SELECT xx FROM a FROM b`, `SELECT xxx from table TRAIN model COLUMN a,b COLUMN c,d`, I issued a bug: https://github.com/sql-machine-learning/sqlflow/issues/616 , and will fix it in another pr.

Why predict should set `IsTraining:         true,`?
defer clean up this file?
done.
done.
Seems milestone 1 only support the local training, how about removing the unnecessary fields like `runLocal`, `WorkerNum` and etc...  And we can add these fields in the ms2 which supports distributed training.

Why do we want to serialize the filler to JSON?
SQL is case-sensitive, so maybe we can remove `ToUpper`?
Don't need to add quota for the string value.

Please remove the comment, this PR's author is not typhoonzero .
Can fuse `fillDatabaseInfo` in `codegen.go`?
https://github.com/sql-machine-learning/sqlflow/blob/a290673e54c3a128ad6a8dc4d551e632abe0b841/sql/codegen.go#L201
I saw there are too many attr keyword here, are these all necessary? I'm not good at XGBoost, for the experience 
 of TF codegen, the Go code only need to parse the common keyword such as `batch_size`, `verbose` and etc.. into Resolver:
https://github.com/sql-machine-learning/sqlflow/blob/a290673e54c3a128ad6a8dc4d551e632abe0b841/sql/expression_resolver.go#L50-L54

the others can fill into Python code as` train_args`:
https://github.com/sql-machine-learning/sqlflow/blob/a290673e54c3a128ad6a8dc4d551e632abe0b841/sql/codegen.go#L297
Not sure why the CI's linter check didn't report this style check that, comments should start with the function name, see: https://github.com/golang/go/wiki/CodeReviewComments#comment-sentences
Seems a simple way is to determine the attribute value type and set to an arbitrary map, then render the generated code. It's fine if the user setup the wrong attribute value type since it will throw errors at runtime.
I think make xgboost-related estimator keywords case-insensitive is more friendly to users, because they are very long.
Because `xgblauncher` accept nested python structure as configure,  I want to do more  work with golang, less work with template. Since long templates is harder to read and maintain than golang.
Yes, but it seems no harm to do some check during codegen?
Please merge develop, I believe `pr.attrs` has been changed to `pr.trainAttrs`.
@typhoonzero maybe linter only check exposed functions?
True. I personally like simpler codes, it's your choice, this do not block merging.
True. I personally like simpler codes, it's your choice, this do not block merging.
This workaround looks good to me. Do you want to make this a PR to TF? Or do you want us to add it?
This field is used for https://github.com/sql-machine-learning/sqlflow/blob/develop/sql/template_alps.go#L147
`gitLabModel` ?
Maybe define some URI schema could reduce the number of parameters, like `token@https://gitlab.yourhost.com/your/repo.git:sha:/path/to/dir:ModelClassName`
Is this a standard URL format for `gitlab`?
Ok, will fix it
Not a common standard, note we also use `maxcompute://xxx` to identify the database drivers. This is a method to define a pattern and reduce the number of paramters.
Add some unit test?
Since `NE` is supported, do we need to support `EQ`?
EQ is supported by line 269: `| expr '=' expr  { $$ = binary('=', $1, $2, $3) }`. We may add `EQ` when we need it?
How about
```go
if pr.train {
    return tfTrainTemplate.Execute(w, r)
}
return tfPredTemplate.Execute(w, r)
```
shall we move `get_dtype`and `_parse_sparse_feature` to `sql/python` so that they be shared between templates?
`get_dtype` & `_parse_sparse_feature` are specified to `tensorflow`. I'm not sure if other templates would use this.
`auth={{.Auth}}` => `auth="{{.Auth}}"`
Maybe add more tests to test connection string with out `?auth=NOSASL`?
Will add it in the next pr.

done.
Do we need to fix the `kubectl` version to adapt the k8s server version on GKE?
I haven't tested this command, does `--host=%` works well?
miminal => minimal

I'm not sure `miminal SQLFlow ` is exactly enough, how about **deploy SQLFlow gRPC server and Jupyter Notebook server** ?
`CloudSQL instance` or `MySQL instance`? I found 
> In this tutorial, the difference is that we are relying on an existing MySQL
instance (hosted on CloudSQL)

using the `MySQL instance`, how about unify the name to CloudSQL instance ?
introduces on running => introduces running
Updated the instruction to install how to install GKE compatible kubectl with "gcloud" command
Yes, host=% denotes unrestricted host name

https://cloud.google.com/sdk/gcloud/reference/sql/users/set-password#--host
SG. Done :)
Unified to be CloudSQL MySQL instance, since CloudSQL also support postgres, so just "CloudSQL instance" might cause confusion I feel.
Done
`SqlflowDSConfig ` can be capital to `SQLFlowDSConfig`.
Just confusion why the label column is None.

Because all column fields in use have already been included in feature_column_names.

https://github.com/sql-machine-learning/sqlflow/pull/647/files#diff-10bbf40d8866f298982cb34c597430d9R73
Done
@Yancey1989 why removing the random name? Shouldn't training and validation tables have a temporary name?
Also, this PR is failing on MaxCompute unit tests. https://travis-ci.com/sql-machine-learning/sqlflow/jobs/224573082#L4551
SqlFlowDSConfig => SQLFlowDSConfig
Remove the comment code.
`target("feature_columns:).` is not a complete schema?
Is https://github.com/wangkuiyi/elasticdl a public repo?
FYI, in the case of ALPS as backend, a user would write`train.num_epochs`.
SQLFlow can help with inferring data types and tensor shapes. :)
SQLFlow can help with inferring data types and tensor shapes. :)
Where should we store the RecordIO file? Why not reading from the ODPS table directly?
Maybe add the sample code for the high-level API.
For now we have to convert them to RecordIO files. They will be stored in Kubernetes persistent volumes.
Great! Is there an example for that?
Not yet. 
Isn’t that “train” redundant with the “TRAIN” clause? 
The goal is to differentiate with other model-specific parameters, similar to TF Estimator’s RunConfig. 
It is too complicated for SQL users to specify worker/master resources. Each predefined model can have an optimal resource config to be used directly.
For Keras functional API, input layers are required. If the Keras subclass is used, no need to define the input layer.
Yes, another approach is to pre-define some resource types like "small", "standard", "large". But from API side, we still provide a way for advanced users to config their tasks, right? Not sure how ALPS handles this.
@tonyyang-svail Support reading directly from ODPS will be added later, after we complete the entire SQLFlow->ElasticDL work.
Ending with a comma.
Just checked with ALPS folks. They handle this types of configurations in WITH clause as well.
> Great! Is there an example for that?

@terrytangyuan the data type inference logic is scattered around in the code. I apologize for that.

For example, to determine the label type, we have

https://github.com/sql-machine-learning/sqlflow/blob/d873bc994350493a599e58a7cc5dc519d09e58e5/sql/codegen.go#L190-L205

To determine the input tensor shape in the case of dense tensor like "1,2,3,4". We select one row and split the cell by delimiter, then count the number of elements to determine the shape.

https://github.com/sql-machine-learning/sqlflow/blob/d873bc994350493a599e58a7cc5dc519d09e58e5/sql/codegen_alps.go#L658-L661

Currently, the type and shape inference logic is not unified across different `codegen_*.go`. SQLFlow team is working on unifying them and put the inferred result into a struct like`featureMeta`.

https://github.com/sql-machine-learning/sqlflow/blob/d873bc994350493a599e58a7cc5dc519d09e58e5/sql/codegen.go#L47-L53

This effort may take several weeks.

What is the first use case of EDL on SQLFlow?
In one case, users need to **Inference on the whole validation data**, so the Inference Job need to know the validation table name, instead of a hidden random name. But I think we can name the table name to `<original_table_name>_tv_sqlflow, <original>_train_sqlflow, <orignal>_validatoin_sqlflow`.
Currently, the error is written directly to `wr`, for example,

https://github.com/sql-machine-learning/sqlflow/blob/5e7adc1ececc92995423097328eb3ca63c27f99b/sql/executor.go#L189-L193

So how about `wr.Write(fmt.Sprintf("%v", err))` => `wr.Write(err)`?
Done
indentation.
indentation.
Is it possible to avoid `append_columns`? A training job should memorize the field names later used for a prediction job.
What is the usage of the encoding column?
Encoding column stores leaf indices of this sample in each tree. We transform leaf indices in  a string which format like: "index_0,index_1,......,index_n" 
Does `prob_column `, `detail_column` is required? Can we add these columns by default, so the WITH statment can be shorter...

Prob_column, detail_column, leaf_column and append_columns are optional. Only result_column is required for prediction task, which has a default column field: "result".
Can keep consistent with the TF example, specific result column in `PREDICT iris.predict.result`?
We can get the odps configuration from `datasource` argument like: 
https://github.com/sql-machine-learning/sqlflow/blob/113606eb853d6cd3a4d683d5bb5703620a6365e7/sql/codegen_alps.go#L175
Add this case to hive e2e test also ?
Please be aware that not all selected columns are used as features for training, we can write `select * from some_table train MyModel column a label x ...` and the table may have columns `a,b,c,d...` but only a will be used as training input.

Get feature list from `COLUMN` clause or you can just write some comment here for later update.
File `data_conversion.py` is not included in this PR?
Typo: legal
I saw some cases also using `WITH BATCHSIZE=2` instead of `WITH train.batchsize` like: 
https://github.com/sql-machine-learning/sqlflow/blob/77cac234c571ec0af6ddd1d30a1d5c54e28f674e/cmd/sqlflowserver/main_test.go#L616-L620

maybe we need to make the syntax to be consistent and refine the example code?

You're right, will update `codegen.go` to use `expression_resolver.go` so that all attributes are of the same format.
Yes, this issue will be tracked in the separate TODO issue. 
Sorry did not see how it's generated.
why return? shouldn't be continue?
`[]int` is not of type `[]interface`.
Is the case `"mysql"` identical to the case `"hive"`, if so, how about using the shorthand `case "hive", "mysql":`?
function comments should be right above the function declaration and should be the format: `createDataset ....`
Note that we should not drop the validation table after training because we may still need to use that table to run a full evaluation. Can run this function before the training start yet. ( introduced in https://github.com/sql-machine-learning/sqlflow/pull/682/files#diff-d77fda4265f0434c48d4fe6252700e7dR284)
@typhoonzero Thanks for this syntax design.

Looks like the `*` in `select * from train_table` and the `*` in `COLUMN *` have different meanings. The first is the shorthand for all fields. And the later is rather complex, whose meaning depends on many other things.

1. Consider `select *, a from train_table`, the result columns are all fields in `train_table` plus a duplicated `a`. However, `COLUMN *, a` has the same columns as `COLUMN *`. The meaning of `*` is depending on `a`.
1. The `COLUMN *` in `COLUMN * LABEL label` doesn't include the label field. The meaning of `*` is depending on the label clause.

Do you think it is hard for the user to learn `*`?

How about introducing a function named `MATCH(regexp)` that will expand the regexp to match column names. So we can write `MATCH("[a-d]")` to represent columns `a`, `b`, `c` and `d`. So the train SQL would become
```SQL
SELECT * FROM training_table
TRAIN DNNClassifier
WITH someattr=somevalue
COLUMN MATCH("[a-d]"),EMBEDDING(e, 128, "sum"),EMBEDDING(SPARSE(f, [1000000]), 512, "sum")
LABEL label
INTO my_model_file;
```
In the case of [credit fraud](https://www.kaggle.com/mlg-ulb/creditcardfraud) dataset, we want to select `V1`, `V2`, ..., `V19`, we can write `MATCH("V\d+")`, which would exclude field `time` and `class`.



What if the column data type falls into this category (contents are "1", "2", "3", "4", ...), but a user write `SPARSE(column_name)`. Do we still categorize this column as dense tensor?

I believe the feature derivation logic should start with what feature column a user has written. 
As we discussed this morning, I am sure that what must be done by the SQL statements are:

1. Describe what columns to read from. It could be all columns in the table or several columns in some pattern.
1. Describe what are the columns used for training samples ( or input X ), and what is the columns used for the label (Y).
1. If there are a lot of X columns, we should have a fast way to match them all, e.g. credit card fraud dataset have time, v1~v18, amount features, we can match them by `time, MATCH(v[0-9][0-9]), amount`.
1. Describe how to parse the column data into tensors, e.g. parse a CSV string to a `tf.SparseTensor` or `tf.Tensor`, or preprocess the tensors like image random crop etc.
1. Describe how the feature column is assembled to the network, like whether to use embedding for the column, should the embedding column use shared weights etc.
> I believe the feature derivation logic should start with what feature column a user has written.

You are right.
which column is the label?
should convert to `[]interface{}` first
I see that only hive will do the `DROP TABLE`, this does not affect current running cases.
It will be fixed!
Remove `var origTableWithNoDBPrefix string` ?
Tiny suggestion: how about renaming `origTableWithNoDBPrefix` to `origTableWithoutDBPrefix `
I'm not sure if we can make this assertion. Is it possible the `len` equals to 1?
We must support user write sqls like `select * from myproject.mytabe train ...`
Will update the comment, thanks.
`?` ??
Should be called `BufferedDBWriter` since it buffers data. When you write `writer.write(row)` you'll know it's buffered.
Just copied from the current implement:
https://github.com/sql-machine-learning/sqlflow/blob/7a51332149a5943a0f3e331c90f5b173c042f88e/sql/python/sqlflow_submitter/db.py#L112-L119
Wrap this in a with block or finally block to make sure it’s executed even when the write() call fails 
You can also inherit from abc module and just add @ abstractmethod decorator to this function 
Do we need to wrap this in a finally block? Same for other similar places 
done.
Good suggestion! Updated PR based on your comment.


done.
done.
clean up?
Clever change !
install Hadoop to use as the client when writing CSV to hive tables.
What if command run fails?
seems this is to write rows in the buffer, is there a way to write all the rows before writing to hive?
can also add `stderr=subprocess.STDOUT` to output error message. Also need to print out the return output of the call `subprocess.check_output `
done.
The error message seems will throw to stderr. So this may not needed.
It looks this field renamed to `CheckpointFilenameForInit` in `resolvedPredictClause`.
Shall we do the same thing here?
Remove this line or use the `log.Infof(xxx)`   : )
I'd like to keep `Eval` here for now since currently training and evaluation is coupled and it would be good to keep `Eval` so that we know this is only used for evaluation. `resolvedPredictClause` is only related to prediction so it's unnecessary to name it `PredictCheckpointFilenameForInit `.
Thanks. Removed.
Some suggestions for elaborating the details:

The `codgen_shap.go` generates a SHAP Python program. The SHAP Python program prints the resulting image in HTML format to stdout. The stdout will be captured by the Go program using [`CombinedOutput`](https://golang.org/pkg/os/exec/#Cmd.CombinedOutput). The Go program then sends the HTML text to the client as a single message.
Does `elasticDLTrain` need the result of `newTrainAndValDataset`?
Nope not yet until ElasticDL supports reading from ODPS directly 
For the record, SQLFlow+EDL currently only supports training without evaluation.
Maybe add some comments about how to select the axis to plot like `shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])`
maybe `anal` -> `anlz`?
Will update this section in the next PR.

Maybe combine the following command to a bash script?
Good idea. Done. 
maybe leave this line unchanged?
Nice practice!
Move this to top of the file
@terrytangyuan Done
Without the support of the feature column, how does EDL infer the shape of the input?
Marking this as WIP for now. I'll reuse `verifier` to get this kind of information instead.
I am curious about the necessity of sorting.
It simply makes the testing easier. Otherwise, the generated feature information string varies.
How about using  `os.environ.get('MAXCOMPUTE_ENDPOINT', None)` to get the default value,  and also applying to other the MaxCompute env?
Thanks. Fixed. The other env vars are required for now so I am leaving them unchanged.
Dataset should be read from sqlflow.db just as training/prediction?
You are right. The data should be read from `sqlflow.db`. This PR is verifying the end to end pipeline as mentioned in https://github.com/sql-machine-learning/sqlflow/issues/707#issuecomment-525967005. :)

Sorry for causing the confusion.
Remove the commented code?

It is a sample code for how to use it.
Next PR will remove it.
A question here: this doesn't quite work yet. Somehow even though I specified `SQLFLOW_submitter=elasticdl` here the script `test_magic_elasticdl.py` still uses TensorFlow as the submitter. During my local testing, I had to hard-code executor to use elasticdl submitter to get this working.
One possible reason: the `sqlflowserver` is started on line 48, when `SQLFLOW_submitter` is still `""`
Why adding `--net=host -v /var/run/docker.sock:/var/run/docker.sock -v $HOME/.kube:/root/.kube -v /home/$USER/.minikube/:/home/$USER/.minikube/` to the `docker run` command of `test_maxcompute.sh`?
These additional set of args are needed in order to run minikube + docker inside the container correctly, which will be required by ElasticDL CLI.
I see. I’ll look into this later when I start uncommenting these lines after open source.
Please remove the commented code.
Can use the standar function [strings.TrimRight](https://golang.org/pkg/strings/#TrimRight)
Why changing to a pointer?
To improve reusability, `fillDatabaseInfo()` is renamed to `newConnectionConfig()` which returns a pointer.
Maybe rename `TrainingDataset` to `TrainingDatasetSQL` is more meaningful
Thanks for your reminder. `trimTailOf` is replaced by [strings.TrimSuffix](https://golang.org/pkg/strings/#TrimSuffix).
Good idea.
Add a section to introduce the `Cluster Model`?
How do you want to expose `ClusterModel`  to SQLFlow? For the current implement this should be a [Tensorflow premade Estimator](https://www.tensorflow.org/guide/premade_estimators) or [Custom Kerse Model](https://keras.io/models/about-keras-models/#model-subclassing), can we implement `ClusterModel` as a Custom Kerase Model?
Maybe we need a more general target for the keyword **EXTRACT**
`EXTRCT SQL ` => `EXTRACT SQL`
This keyword is just for illustration of the design. Next, maybe we can think about a better keywords together.
Do you mean EXTRACT?
yes~
"EXTRACT" a model does not read well, we can train a model, save a model, use a model to do prediction but not extract a model. Since the model name is "clusterModel", we can distinguish the model type just like we did in xgboost. Maybe we can use `TRAIN ClusterModel.myDeepClusteringModel` then the code generator can generate specific code for the training pipeline for clustering models.
How would an analyst use this table?
Analysts will compare the mean of each feature to analyze the behavioral characteristics and differences of each group of users, maybe by ploting the result_table.
I see. Thanks for the explanation. :)
Maybe paste the link here before this figure, so that readers can understand this figure well.
please remove the blank lines and use 4 spaces as indentation.
You mean “does not work”? Same in other places. Also did you mean to use double quotes instead?
OK~~thx~
The `USING` statement have a higher precedence than  pre_train=True in WITH statement. Since model.encode_units sets the pre_train part of the autoencoder network, the pre_train statement does not work when the using statement exists, so encode_units does not work.
I understand that. I was just asking you to revisit this part of the grammar. It should be “does” instead of “is”. And then switch to use double quotes.
Do we need to refine the USING syntax? Or just following the existing syntax `USING existed_pretran_model`.
It's not Python syntax, maybe using 
``` python
if hasattr(classifier, 'pre_train'):
    classifier.pre_train(...)
if hasattr(classifier, 'cluster_train_loop'):
    classifier.cluster_train_loop
```
Maybe to specify the result column by  `PREDICT output_table.group_id` is more accurate.
How about moving  the cluster model introduction section on the top of the document, the structure can be:
1. ClusterModel introcution
1. User interface in SQLFlow
1. How implement ClusterModel it in SQLFlow
  
How about split `Cluster` section into `Train` and `Predict` so that users can know what does `TRAIN SQL` and `PREDICT SQL` do.

> As one of the most powerful method  in  pattern recognition, clustering focus on finding the similarities between items per group and differences between groups. Hence, `Cluster Model` can help analysts to build such a model which can split data samples into different group according to their features automatically.   

@Echo9573 If it can help.
In my opinion, it can be divided into such two scenarios:

1. User has no pre-train model (auto-encoder). 
 In this scenario the user wants the full training process which consists of `auto-encoder` and `clustering`. Thus the user should  be forbidden to use the `USING` clause, because there is no pre-train model ready for using in training process. User should define relate parameters of `auto-encoder` model  in `WITH` clause clearly, like `model.encode_units`.

2. User has pre-train model (auto-encoder).
In this case, use has at least one pre-train `auto-encoder` model already and he/she want to use it without training this part again. `USING` clause should be used for defining the path/name of the pre-train `auto-encoder` model and  in `WITH` clause user should guarantee the correct structure of pre-train model to make sure that the model data can be loaded correctly. It requires some additional checks to be performed in the background.
I think the `decoder` should be include into the stage of `Pre-train`. Because the `auto-encoder` is used for building `encoder` for next training process. The `decoder` will be created at the same time. Even the `decoder` will be never be used in the future, it still should be treated as `Pre-train`(Just my opinion).
OK~~thx！
@sperlingxx Please: 

1. define the ultimate number 42 as a const value.
2. add comments why need to fix the random seed for better readability.
logginer.info ?
Use warning here because info level seems to be ignored by sqlflow streaming.
how about renaming it to genAntXG**B**oost?
You're right, that's a typo, thx.

Is this for debug? if not please use `log.Infof`
I found our [filler for tensorflow](https://github.com/sql-machine-learning/sqlflow/blob/develop/sql/codegen.go#L62) in `codegen.go`,
https://github.com/sql-machine-learning/sqlflow/blob/9a0dc86b160c4248732124e92ea64edcfc72a41f/sql/codegen.go#L67-L69
`Features` named to `X` and `Label` to `Y`.
I would suggest such consistent naming.
try put attribute extraction into the codegen for each submitter?
Remove this line.
It's used to resolve XGBoost parameters, the current `expression_resover` can only resolve the Tensorlfow parameters, maybe we can refactor the `expression_resolver` to extract `getBoolAttr`, `getIntAttr` as the common function.

done.

done.
Maybe a better way is reuse the filler in `codegen`, would optimize it in the next PR.

If we only have these two parameters currently, try all put it in `expression_resolver.go` and refine this later. We should let each codegen to deal with it's only attributes.
`TRAIN XGBoost.someModel`?
did not see the `XGBOOST` keyword?
Why need to write a file?
fixed it.

XGBoost use the `objective` paramter to specify the training objective such as:
`objective=binary:logistic `, ref https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters

Maybe we can use `Train XGBoost` in the train statement, and specify the objective in WITH statement: `model.objective=binary:logistic` ?
XGboost use DMatrix as the input dataset , and it seems the text file  format is popular in XGBoost:
 
> XGBoost currently supports two text formats for ingesting data: LibSVM and CSV

ref: https://xgboost.readthedocs.io/en/latest/tutorials/input_format.html

I still prefer to put the `objective` in the `TRAIN` clause, it seems quite similar to `tf.estimator.*`.
Update the doc, would use `TRAIN xgboost.multi.softmax` to fill the objective parameter.

should remove `train.objective` now?
**SELECT STATEMENT** => the SELECT statment
It tells the SQL engine to run the SELECT statement and retrieve the training/test data.  It saves the data into a text file, which could be loaded by XGBoost using the DMatrix interface.
PREDICT clause
done.

Thanks, done.

Done, and also polish the last sentence.

I think the parsing of the WITH clause is the parser's work, but not the submitter's work, am I right? 
The parser can parse the WITH clause to a general [attrs](https://github.com/sql-machine-learning/sqlflow/blob/develop/sql/parser.go#L106) struct which is a Go struct `map[string]*expr`, and each generator would resolve the`attrs` to program parameters, such as XGBoost generator would convert the attrs as follows:
- keys with `train.` prefix to `xgboost.train` arguments.
- keys without any prefix to XGBoost Parameters which is JSON format.

typo: targe
`resolveParamsCfg` must run after `resolveTrainCfg` to resolve all other attributes, maybe add some comment here as hints.
`resolveParamsCfg ` only resolve the keys without prefix, maybe the order is fine?
thx, done.

What are the group and weight columns?
Formatting: please start with `#`.
Is `SPARSE` currently supported?
Yes, but we need to add some tests for `SPARSE`.
Fixed!
Alipay.inc => Alipay Inc.
fork repo => fork
Since they are optional, we assume only users with background knowledge will use them.
Use active voice instead of passive voice. We can say: Ant-XGBoost extends `dmlc/xgboost` with the capability of running on Kubernetes and automatic hyper-parameter estimation.
`###` => `#`
`####` => `##`
`####` => `##`
`#####`=>`###`
`dmlc/xgboost` stops when no significant improvements in the recent n boosting rounds, where n is a configurable parameter.
Are the metrics the same of what XGBoost used as stopping criteria?
`#####`=>`###`
All above are about Ant-XGBoost and should be part of the documentation of Ant-XGBoost, other than SQLFlow. I would recommend moving the above content to github.com/alipay/ant-xgboost, and put a link in this document pointing to that repo.
This document is supposed to be about the design of `antxgboost_codegen.go`. But there is no discussion about this code generator?
Why `Quick Start` here? Is this a design doc or a tutorial?  If it is a tutorial, it should contain how to build and setup SQLFlow with the Ant-XGBoost codegen.
I think this document is not about the extended syntax by SQLFlow to SQL. Do you want to explain the part of SQLFlow syntax to be utilized by the Ant-XGBoost codegen?
Here mentioned `estimatorType`, but the concept estimator is not yet introduced here. I see it will be introduced in the next section. Do you think it could be more comprehensive if we move the next section before this one?
@wangkuiyi Yes, I want to inform users the overall sqlflow syntax related to ant-xgboost. So, we rename this section with `Overall SQL Syntax for AntXGBoost`. 
Maybe we can add links to reference `auto_train` and `convergence_criteria`, so that users can know the concept clearly.
sqlflow => SQLFlow
Does users need to set `objective=train.objective ` in WITH clause or not? If not, which of would be the value of `objective`?

two feature column schemas
=>
two kinds of feature columns?
what does `k` and `v` mean?
The title is too deep, do you want to use `*` to introuce how to use `append_columns` ?
Done.
Done
Done
Done
Done
Done
standard SQL parser => third-party parsers like tidb parser
More details about what workflow is? We would like to analyze the dependencies of the execution order of all the SQL statements and form an execution graph automatically, then parallelly execute the graph nodes.
Sure. Added.
Sure. Updated.
To support more accurate splitting, we need the lexer in package `github.com/sql-machine-learning/sqlflow/sql`. So we need to export the lexer? If so, I would prefer splitting on the client-side...
The cause is the `testErrorSQL` is appended with a `;`. So it won't go into the mockRun `case testErrorSQL`. Therefore no error is returned. 

https://github.com/sql-machine-learning/sqlflow/blob/229937ac9a6ed26101bff9552b269f8855abe2b7/server/sqlflowserver_test.go#L52-L53
I support to allow SQLFlow server to run a sequence of SQL statements to form a workflow. But I have a few questions:

1. I cannot find a design doc. However, I think we do need one, and it should explain the interactions between Jupyter Notebook server/magic command and the SQLFlow server.
   - What would happen if the user presses Ctrl-Enter in a Jupyter Notebook cell with one or more SQL statements? Will there be one or more gRPC call(s)?
   - What would happen if the user clicks the Run button (a triangle pointing to the right)? Will there be one or more gRPC call(s)?

- I am very worried that the splitting of SQL statements in a cell by `;` is too hacky and would lead to many bugs. I would do the right things in the right order -- get the general parser (connecting SQLFlow with various database systems) done before parsing multiple statements from a cell.
One possible solution described at https://github.com/sql-machine-learning/sqlflow/pull/779: expose this function as `SplitSQLStatements(s string) []string` for the `server` package.
Done
sqlflow_models.my_xgboost_model -> XGB.my_xgboost_model ?

https://github.com/Yancey1989/sqlflow/blob/497ca9691a006652a4a7b6b0e8e46267d69543c4/sql/codegen_analyze.go#L88-L90
`XGB.` is the prefix of Estimator, I think the model name can be any user-defined name.

Sorry, I misunderstood the concepts of estimator and model.
remove this tab?
The `xgboost-laucnher` included the `dmlc/xgboost` package, if we want to skip ant-xgboost unit test, maybe we also need to install `xgboost==0.90` to pass the `dmlc/xgboost` unit test.

Added. Thanks for the reminder!
Thanks for fixing the indent.

Please also add a unit test in `executor_test` to test the pred SQL.


Done.
We don't need an `ExtraConfig`, we can't judge what's "extra" and what's not. If it is some configuration, just put in attributes.
Same as above, if it's only used to store validation sql, just name it `ValidationSelect`.
`Feature` only have information about how to parse the column data, we still need information about how to construct a feature column on it.
I would suggest using a field name with clearer meaning, or people may be confused when they see it.
https://github.com/sql-machine-learning/sqlflow/issues/774 here's some of my thoughts about refactoring attribute resolution.
How about we define several `enmu` types? like [http/status.go](https://golang.org/src/net/http/status.go)
Attribute(s)?
Maybe we don't need to implement an IR for each job, how about simplifying like: 
``` golang
type FeatureMeta struct {
    DType string
    Delimiter string 
    ...
}
type DBConn struct {
    Driver string
    User string
    ....
}
type ClauseIR struct {
    Estimator string
    SelectClause string
    Attributes map[string]interface{}
    DBConn DBConn
    Features map[string]FeatureMeta
    ...
}
``` 

Each generator can extend the `ClauseIR` as needed.
 


Sure.
I put `ExtraConfig` here for possible extensibility. I don't have a clear idea of what to put at `ExtraConfig`. So I will remove this field.
Sure.
I think singular is fine. The `map` type already indicates there are multiple attributes. The same reasoning applies to `Feature`.
@Yancey1989 Thanks for the suggestion. Combining all three `IR`s to a single `ClauseIR` does save some code. However, I still advocate using separate IRs for different job types. Here is my reasoning.
- Avoid confusion. The developer of `xgboost.Predict` would be confused by the `ValidationSelect` field in `ClauseIR`. Also, as we adding more features to SQLFlow, more fields would be added to `CluaseIR`, and the confusion will increase.
- Less work. We either distinguish the job type in `sql` or in `codegen`. However, there are many `codegen`s and only one `sql`. Distinguishing the job type in `sql` saves works in all `codegen`s.
Thanks. I added `FeatureColumn` field in `FieldMeta`.
@typhoonzero Thanks for the link. I think `Attribute map[string]interface{}` here is fine.

I believe `AttrMeta` belong to the code generation package since different machine learning toolkits accept different attributes.
Sounds great. `enum` types are more informative than opaque string, so that the developers know what to expect.
> I still prefer to put the `objective` in the `TRAIN` clause, it seems quite similar to `tf.estimator.*`.

@Yancey1989 @typhoonzero `objective` corresponds to the loss of function of a model. So it shouldn't be in the model name. For different types of models, there are `gbtree`, `gblinear` and `dart` as listed [here](https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters).
> I believe AttrMeta belong to the code generation package since different machine learning toolkits accept different attributes

It is. Each submitter's code generation package define it's `AttrMeta` and call a function to get an `Attribute map[string]interface{}`.
@tonyyang-svail Thanks, you are right. I'll update to put`objective` in attributes.
indent
how to get the train parameters? Should we add `TrainIR` to `PredictIR`?
Maybe we can save the TrainClause in the model struct: 
https://github.com/sql-machine-learning/sqlflow/blob/5ae82c045024e632a9d5eb898225c631187d688f/sql/model.go#L27-L30

And the prediction job can resolve the TrainClause to the parameters. And I think `PredictIR` is a good idea, do you want to resolve the Predict SQL and saved model into `PredictIR`?

Thanks, will fix it in the next PR.

Should find a more accurate way to determine whether the model is a regression model.
Do not need `err == nil` because the above IF statement does that.
 
Done
maybe `\n` also need to be trimmed?
`strings.TrimSpace` can trim `\n` and space: https://golang.org/pkg/strings/#TrimSpace

suggestion: define IR struct like:

```go
type FieldMeta struct {
    FieldNasme string,
    DType FieldType,
    Delimiter string,
    Shape []int,
    IsSparse bool,
}

type FeatureColumn struct {
    FieldMetas []*FieldMeta
    Keys []string,
    // CATEGORY_ID(c1): key is c1,
    // EMBEDDING(CATEGORY_ID(c2)) key is c1,
    // CROSS(EMBEDDING(c1), c2): key is c1, c2
}

type TrainIR struct {
...
Feature map[string]map[string]FeatureColumn
}
```

this will much like the struct of column clause, which DENSE/SPARSE defines the `FieldMeta`, furthermore, the `FieldMeta` is derivated when feature derivation is enabled.

```sql
COLUMN EMBEDDING(CATEGORY_ID(SPARSE(c1, 1000, COMMA), 1000), 128, sum),
NUMERIC(DENSE(c2, 128, COMMA), [128])
```
Hi @typhoonzero, thanks for the suggestion. I agree that making `FeatureColumn` contain `FieldMeta` is more straight forward. I will update the struct and the design doc in this PR.
Add a function to guarantee feature column type.
```SQL
select c1, c2, c3, class
column embedding(c3)
label class

select c1, c2, c3, class
column c1, c2, embedding(c3)
label class

select c1, c2, c3, class
column numeric(c1), numeric(c2), embedding(c3)
label class
```

```go
type NumericColumn struct {
    FeatureColumn {
        FieldMeta
    }
}
```
```go
type Attribute struct {
    Key string
    Value interface{}
}
```
`Attributes []Attribute` can preserve the order.
Add `TrainIR` and `ModelTable`.
Remove `Feature`, `Estimator`, `Label`.
Change to `ModelTable`.
Add `TrainIR` and `Explainer`. Remove `Feature` and `Label`.
Instead of linking the design doc, linking the user guide might be more useful.
done
no need to mention design in a tutorial?
Train a XGBoost model to fit the boston housing dataset
"you will know how to" -> learn how to...
SQLFlow will auto split train/validation dataset, shall we mention this?
> no need to mention design in a tutorial?

Yep, already linked the user guide doc.

done.

done.
Good idea, fixed.

Missing documentation title. Maybe the following paragraphs would help.

# Analyzing model on SQLFlow Tutorial

In this tutorial, we will learn to
- Train an XgBoost tree model on [the Boston housing dataset](https://www.kaggle.com/c/boston-housing).
- Analyze the trained model using `ANALYZE` SQL statements.

You can find more SQLFlow usage from the [User Guide](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/user_guide.md).

Maybe move the syntax section to the user guide: https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/user_guide.md#syntax
When I am viewing this file on GitHub, the image is not showing up..

![Screen Shot 2019-09-16 at 11 58 02 AM](https://user-images.githubusercontent.com/29932814/64985235-49a98680-d879-11e9-8a7b-3b3a174f92e0.png)

Please avoid passive voice so that the tutorial is more engaging. For example, "trained model" => "we train a model"
we will learn to
=>
you will learn how to 
Add a link to XGBoost tutorial?
fixed. It caused by the invalid HTML tags.
The syntax here just briefly describes how to use and introduces the `ANALYZER`.
Of course, it's a good idea to add a section about `analyzer` in the user guide.
Good idea.
@weiguoz 👍 
~Seems I don't find the **exception** test?~
Shall we add test cases for all feature columns?
Shall we implement this TODO?
Where do we check the column selected actually exists? i.e. where is the `func verify`?
The `LabelColumn` might be redundant to the `Label` field. How about removing this field and use `NumericColumn` for numerical labels?
Are we supporting [`NUMERIC(field, n[, delimiter=comma])`](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/user_guide.md#numeric) as the equivalent for `DENSE`?
Where shall we put the logic of automatically training and validation splitting?
~~Also, shall we make lexer/parser aware of integer and floating-point?~~
Sure.
I intend to finish TODOs in next PR to keep this PR smaller for review.
Sure.
No, we'll only support below methods:

`NUMERIC(DENSE(field, shape, delimiter))` or

`NUMERIC(field)` and infer the field's shape and delimiter using feature derivation, or

`field` or nothing for full feature derivation.

For a CSV sparse tensor column, user must write: 

`NUMERIC(SPARSE(field, shape, delim))`
Added TODO comment, will add together with feature derivation.
Done.
Added TODO comment.
As we discussed, it can be inferred by parameter `feature_columns` and `n_clusters`. 
User will not be forced to input for `pretrain_dims` but `n_cluster` should be required.
Maybe we need to put this case into another test case, it's not DNN.

Done.
How about merging with L215. Like:
```go
if r.TableName, labelColumnName, e := parseTableColumn(pr.into); e != nil {
    // ...
}
```
I am worried that these two situations cannot be distinguished: 1) `row[label_idx] = -1`; 2) `else -1`
You're right, `-1` can not be used to distinguish `with label clause` and `without label clause`, the model implementation should deal with that.

Will polish it in the next PR.

Good catch. This is due the `attrs` type in the parser is a map.

https://github.com/sql-machine-learning/sqlflow/blob/01730675a6505d1384393a04f647f2dc380a211e/sql/sql.y#L87

During the parsing, the key-value pairs of `attrs` is assigned as

https://github.com/sql-machine-learning/sqlflow/blob/01730675a6505d1384393a04f647f2dc380a211e/sql/sql.y#L260-L267

I find it hard to switch from map to slice because multiple code generators are depending on the map struct. Also, there is a check on the duplicating map keys in our parser.

https://github.com/sql-machine-learning/sqlflow/blob/01730675a6505d1384393a04f647f2dc380a211e/sql/sql.y#L103-L111

@weiguoz @typhoonzero @Yancey1989 Sorry I didn't realize this issue. Shall we change the type of `TrainIR.Attribute` back to `map[string]interface{}`?
In the previous implementation, we intend to put all attributes without a prefix directly into `params` and then generate the configuration JSON string. Seems not quite the same here?
For the booster algorithms except `gbtree`, we need to specify it in parameters:
``` python
param = {'booster': 'dart',
         'max_depth': 5, 'learning_rate': 0.1,
```
ref: https://xgboost.readthedocs.io/en/latest/tutorials/dart.html#sample-script

Maybe we can only support the `gbtree` booster and support other booster algs with the unit tests in the future?

@Yancey1989 The current code does support `param = {'booster': 'dart'}` on line 128 `params["model."]["booster"] = booster`.
Hi @typhoonzero, which previous implementation are you referring to?
In here: https://github.com/sql-machine-learning/sqlflow/blob/develop/sql/codegen_xgboost.go#L48
I see. I will remove the `model.` prefix on the model parameters.
I see, thanks.

Done.
Also need to regex the tag branch name?
You are right. Added support for release tag like `v0.1.0-rc.1`.
Agree that we should use map for now.
`sqlflow_train_loop ` is used to run the custom train loop instead of **premade**
I think this condition can be the `label clause` is empty, no need to run the evaluation if there is no `label clause`:

``` golang
if "{{.Y.FeatureName}}" != "":
    eval_result = classifier.evaluate(validate_input_fn(BATCHSIZE), verbose=VERBOSE)
    print("Training set accuracy: {accuracy:0.5f}".format(**{"accuracy": eval_result[1]}))
```
Good idea.
It looks SQLFlow does not need to split the dataset into [train&val](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/design_training_and_validation.md) while `Y.FeatureName` is empty.
Please remove this out-dated TODO.
The parser already checks the attribute duplication at 

https://github.com/sql-machine-learning/sqlflow/blob/01730675a6505d1384393a04f647f2dc380a211e/sql/sql.y#L103-L111

It is safe to remove this check.
Done
Done
Maybe change to more concised statements
```go
if ret, err := strconv.Atoi(expr); err == nil {
    return ret
}
```
`NOTE` => `NOTE(typhoonzero)`. It is better to indicate the owner of the note.
I don't quite understand. How do we support FieldMeta configurations in column clause?
`golint` seems is not checking `// NOTE` comments, so I just removed `NOTE` here.
Updated comment to:

```
// TODO(typhoonzero): support FieldMeta configurations (DENSE/SPARSE) in column clause, e.g.
// CATEGORY_ID(DENSE(...))
```
How about converting the CSV file into sql file and put it on `/docker-entrypoint-initdb.d/` so that users don't need to run the Python script in the tutorial.


I prefer use csv to keep the same format as user downloaded. The file in the repo only contains several lines.
How about adding a unit test?
I agree to add one, preferably in a followup pull request.
If we use `isUnsupervisedLearning` to skip `newTrainAndValDataset` process, how can we make sure the logic of checking  existing table with same name will be run when invoke `createDataset` in `newTrainAndValDataset` ?
Maybe add some explanation that this is for test only, user can connect to a production hive server according to their own setup.
Can we remove `python3 -m http.server 8899`? I think the HTTP server is used only in our test script.

https://github.com/sql-machine-learning/sqlflow/blob/0efd29902a371ce7cc1fe9e6ce9f9c1de5395472/scripts/test_hive.sh#L15-L26
Have we supported KERBEROS, LDAP, ...? If we have supported them all, we should provide specific examples. 
Do we need to add `-p 8888:8888` so that the Jupyter server in the container can be accessed by the browser on the host?
How to connect Hive with SQLFlow
Sure, will do that.

The sqlflow Docker container shared the network stack of hive container by `--net=container:hive ` and the hive container exposed the port to host `-p  8888:8888`.
done.
Then we can => Then you can ...
done.

`sql-machine-learning/gohive` use [beltran/gohive](https://github.com/beltran/gohive#supported-connections) to connect hiveserver2 with SASLTransport, I think we need to add more test in `sql-machine-learning/gohive` to make sure it works well in SQLFlow, before that we can leave one example (PAM auth) here.

Missing dot: `session<cfg_keyN>=valueN]`=>`session.<cfg_keyN>=valueN]`
I will revert this change due to the comment "log doesn't work" by @wangkuiyi 

https://github.com/sql-machine-learning/sqlflow/blob/572b23a37ccfd9f4041ede14508c5c76aab62183/sql/db_test.go#L45-L47

I don't know why "log doesn't work" though. @wangkuiyi Would you mind adding an explanation?
`sqlflow/sqlflow:latest` already contains `shap` and `sqlflow` Python packages.
Maybe change the directory name from `test_sqlflow` to `titanic`?
OK~Thanks for your review!
train a DNNClassifier model.

using the trained model
I found `train.csv` and `test.csv` are in the downloaded zip package, how about using other filenames?
> Finally, we got the `train.csv` and `test.csv` files. The feature engineering file is `titanic_preprocessing.py` in the current directory.\n",


You can execute the Python script `[titanic_preprocessing.py](./titanic_preprocessing)`  to preprocess the raw data, and got `train.csv` and `test.csv` finally.

Seems there will be other examples, how about:
```
`-example
    `-didi
        |- README.md
        |-titanic
            |-tutorial_dnn_titanic.ipynb
            |-train.csv
            `-test.csv ...
        |- other exampels...
```
OK~got it！
Maybe we can remove the `test_sqlflow` folder?
I have not tried to build this Docker image, but maybe we need to add  the `ipynb` tutorials into this Docker image by adding the following context:
``` text
...
ADD example/didi/carprice/tutorial_xgboost_carprice.ipynb /workspace/
ADD example/didi/titanic/tutorial_dnn_titanic.ipynb /workspace/
CMD ["bash", "/start.sh"]
``` 


Because the Dockerfile in the didi folder, maybe we adding the following context instead?
ADD carprice/tutorial_xgboost_carprice.ipynb /workspace/
ADD titanic/tutorial_dnn_titanic.ipynb /workspace/
CMD ["bash", "/start.sh"]
Yes, you're right.

done~thanks
done~thanks!
done thanks
done, thanks~
done~, thanks!
~~I am not sure whether this would work. I think `sqlflow.org/sqlflow` will always point to the default develop branch, while CI should be tested on the PR branch.~~

Just found that TravisCI supports vanity imports via `go_import_path`. [ref](https://docs.travis-ci.com/user/languages/go/#go-import-path).

This would enable CI to test the package at `go/src/sqlflow.org/sqlflow` instead of `go/src/github.com/sql-machine-learning/sqlflow`.
I believe we need more comments here explaining why we don't need to build before tagging.

We also need comments explaining variable TRAVIS_ environment variables to make this configuration comprehensive.  So, I am good to merge this PR before a successive one that adds the comments.
Maybe service.cn-beijing.maxcompute.aliyun-inc.com/api => `service.cn-beijing.maxcompute.aliyun-inc.com/api`.
"actually the whole ..." => "please be aware that the whole ...".
`tutorial_dnn_iris.ipynb` => `iris-dnn.ipynb`
Maybe more consistent formatting?
```
maxcompute://accesskey_id:accesskey_secret@endpoint?current_project={workspace_name}&scheme={my_scheme}
```
=>
```
maxcompute://{accesskey_id}:{accesskey_secret}@{endpoint}?current_project={curr_project}&scheme={scheme}
```
Maxcompute => MaxCompute
Maxcompute => MaxCompute
Maxcompute => MaxCompute
Maxcompute => MaxCompute
Maxcompute => MaxCompute
Maxcompute => MaxCompute
It looks \[localhost:8888](localhost:8888) won't be rendered as a link. So, let's just write `localhost:8888` here
installed `mysql` => installed a `mysql` ?
Sure, thanks.
Sure, thanks.
Maybe add handling for unrecognized data types
```go
else {
    return nil, fmt.Errorf("bad FieldMeta data type ...")
}
```
Done
should also update https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/run/docker.md#mysql ?
Error string should not be capitalized: https://github.com/golang/go/wiki/CodeReviewComments#error-strings
Done.
I deleted odps package because it is duplicated with pyodps. Both of them are Python SDKs for ODPS. I choose pyodps because [its PyPI page](https://pypi.org/project/pyodps) appears to be more official than [odps's PyPI page](https://pypi.org/project/odps/).

The odps package is originally introduced in #553. However, I don't see the necessity of it. @Yancey1989 @typhoonzero as the contribute of that PR, could you please confirm with this deletion?
Note -> NOTE?
Why note me : )
I checked the git history. This line is introduced at https://github.com/sql-machine-learning/sqlflow/pull/319 by @weiguoz 
select_expr -> field_expr?
Predict and Using Clause

title capitalizing rules: https://wenku.baidu.com/view/07e52c69a98271fe910ef9f4.html
I prefer `select_expr` because it is used by MySQL syntax https://dev.mysql.com/doc/refman/8.0/en/select.html.
Should I update all section titles? For example, "Select clause" => "Select Clause", "Prediction syntax" => "Prediction Syntax".
I see.
We should, and seems that some of the documents also need update like `run_with_hive.md`
"has already loaded in MySQL" => "has been loaded to MySQL" ?
This tutorial describes how to train an XGBoost model using the Cars Dataset, then how to predict the car price using SQLFlow.
You can find more SQLFlow usage from the => Checkout the User Guide if you are new to SQLFlow.
Using => Use
that -> then
The Car Price Dataset
This tutorial would use -> we are using
eighty-two -> 82?
Here are some of the column descriptions of the dataset:
why not use sql?
why not use sql?
is used for features -> is used as features
So where to find the full statement when user want to run the SQL in notebook?
And using a standar SQL to fetch the prediction data:   standar-->standard; 
Than, we can specify the prediction result table by PREDICT clause:
 : than-->then
The toolkit `markdown-to-ipynb` would convert ` ```sql ` block to code-block in ipynb.

carprie_preprocessing --> carprice_preprocessing
Appending a white space between ``` and `sql` is a workaround way.
But I don't think it is a good enough solution.
done.

done.

done.

Done.

Done.

done.

done.

`convert_markdown_to_ipynb` tookit will convert the ` ```sql ` block into an executable code-block in ipynb.

done.

Can find it in the following code-block.

thanks, done.

titanic_preprocessing -> carprice_preprocessing
Hi @typhoonzero @Yancey1989 , I changed it to eighty-two since the number in English is more formal.
**check out** vs **checkout**

> Check out is a verb phrase that means to sign for something or to observe something. Checkout means a place to buy things or the process of leaving a hotel as a noun, and it describes qualities of these things as an adjective.

So in our documentation, we should use check out. :)
Move this file to `doc/tutorial/didi`?
We already have a Dockerfile at `doc/tutorial/didi/`, maybe combine them?
Done.
Done.
User Guide => Language Guide 

btw, what do you think of substituting `Syntax Guide` for `Language Guide`? 
> User Guide => Language Guide

Sure
> 
> btw, what do you think of substituting `Syntax Guide` for `Language Guide`?

I would suggest still using `Language Guide`, considering SQLFlow extends the SQL(Structured Query **Language**)

@typhoonzero I think we should change this behavior at `pysqlflow`. If `CompoundMessage` only contains one item with `TypeRows`, the display function should return the item itself, so that `Rows.__repr__` will display the data in table presentation in IPython Notebook.
Hi @tonyyang-svail , I would like to use `list` as the returned value type of `display` function in pysqlflow, it looks like the behavior is more consistent. How do you think to merge this PR and talk about this in the future, I want to release the didi Docker image ASAP.

Maybe remove the beginning space?
`COPY` the whole directory will cause the caching fails because the directory always changes in a Pull Request. Copy only the build script so that all environment builds are cached.
Only this part will be run every time the CI runs.
Do we need to move `# 6. Install latest sqlflow_models for testing custom models` to Dockerfile? Because the models repo also changes frequently.
why removing `src/`?
On line 47,

```
python -m unittest discover -v sql/python "db_test.py"
```
=>
```
python -m unittest discover -v python "db_test.py"
```
why removing `src/`?
why removing `src/`?
why removing `src/`?
Thx, done.

fixed.

fixed.

@Yancey1989 @typhoonzero If the return type of `display` is a list, what would a user after typing the following in the Jupyter Notebook?
```
%%sqlflow
SELECT 1;
```
Sorry, I meant to delete the check at `ir_generator.go` and keeps the check at `sql.y`.
The presentation looks quite different.

![Screen Shot 2019-09-27 at 3 50 39 PM](https://user-images.githubusercontent.com/29932814/65806497-a725b900-e13e-11e9-9ec9-4bde95a5b80d.png)

See https://github.com/golang/go/wiki/CodeReviewComments#dont-panic, do not panic, maybe just log the error and overwrite the attribute?
I prefer using panic. We need to return the error of duplicated attributes to the user. Logging the error only shows up on the SQLFlow server.
Well, `panic` will cause the server process exit, which we do not prefer because the server is a long-running process, we can not assume that user always input valid SQL statements. When the server exits, we need to manually restart it or auto restart it by Kubernetes, even it's restarted by Kubernetes, it will cause:

- temporary service down-grade
- broke currently handling incoming requests in other goroutines
- give more load to the Kubernetes master

and this kind of error better to return to the client, so maybe just put this in `ir_generator.go`?
> Well, panic will cause the server process exit, which we do not prefer because the server is a long-running process, we can not assume that user always input valid SQL statements. 

There is a `recover` function for the parsing. So the server will not exit.

https://github.com/sql-machine-learning/sqlflow/blob/1cc07f0e3d611adec889c59773236873ee04898b/pkg/sql/parser.go#L316-L324

> this kind of error better to return to the client, so maybe just put this in ir_generator.go

Is there a way other than panic that can get the duplication error?
I see, approving.
inputs and outputs can be pvolume, or other file storage place. 
confused here, branching point to the job to control this ? or the workflow or pipeline control? 
do we need to define the pipeline or dag at first ? then follow the jobs, and control logic. 
using `t.Fatalf` if no `GITLAB_TOKEN` in the env to avoid raising the nil point exception.

`os.Getenv` will return an empty string if the environment variable is not defined, in that case, the test should fail due to some gitlab error.
How about moving these to `deploy.sh`?
Done
please remove the unnecessary blank line.

Do we need to install this? I think `cover` is part of the gotools.
This is following https://docs.coveralls.io/go, I think it's better to keep it here.
Hi @typhoonzero, thanks for this PR. I am afraid `GetFieldMeta() *FieldMeta` may not cover all the cases. For example, some feature columns, like `cross`, may have multiple `FieldMeta`s.
Should it be like `GetFieldMeta() []*FieldMeta` ?
Sounds good.
Done
`nil` point is likely to cause panic.

Instead of returning `nil`, why not
- return an empty slice? 
- return `[]*FieldMeta, error`
Maybe add a comment explaining what is a `Vocabulary`?
Why `fmt.Println`? Shouldn't we send the logs to the user via `cw`?
Thanks. Fixed.
Thanks, I was considering exactly the same thing, will do in next PR.
Will do in the next PR.
Maybe use a more meaningful name than `Dictionary`?
I think we should clarify the terminology first.

"Asynchronous" means the caller moves on without waiting for the callee. For example, the client may have two calls to the server: `client.execute("SQL1")` and `client.execute("SQL2")`. If we say the client submits the job asynchronously, we mean the submission of "SQL2" shouldn't wait for "SQL1" to finish on the server end. However, this is not what the design doc is proposing. The client waits for "SQL1" by pulling the result periodically.

It took me a while to realize the solution is not actually asynchronous... I would suggest changing the title to "Handle long-running SQLFlow jobs via polling".
wording: "long links" usually means the length of the URL is long. Maybe change it to "long live connection".
General suggestion. We should also mention:

How should a server handle a request that contains multiple SQLs?
What does the URL contain? Should the user see the URL?

From the protocol definition, the URL looks like a token to retrieve the most recent logs. So the user shouldn't be aware of the URL. In this case, please change wording "URL" => "token".

However, the following sentence says the user should click on the URL. I am confused.
Maybe mentioning the rationale of choosing the solution. For example

-----

## Possible solution
 
1. Increase the default timeout of RPC calls.
1. Communicate via multiple RPC calls. And we maintain the state:
    1. On the client-side: the client starts a service after submitting a SQL, and the server pushes the logs to the client's service.
    1. On the server-side: the client submits a SQL and receives a token. The client poll the server periodically using the token. (Described in this design)
    1. On a third party service: the client submits a SQL and receives a token. The server pushes the logs to a third-party service like etcd or Kafka. The client fetches the result from the third party service using the token.

Each solution has its pros and cons. We choose ... because ...
Abstract => Motivations or Background
long links => HTTP connections
hung => blocks
finish => complete

finish 完蛋
complete 完满
cost => take

Sometimes, the SQL job takes too much time and the gRPC calls timeout.
proposal => design

In this design, we propose ...
What is the "each request"? Is it for a SQL statement, SQL statements in a Jupyter Notebook cell, or all SQL statements in a notebook?
What is currently in `Session`? Should we make `url` a new field of `session`?
The service of SQLFlow doesn't query anything. Instead, it converts a SQL program into a submitter program and runs it. So, it doesn't make sense to name the method `Query`. A long name could be `TranslateAndRun`, or a shorter one as `Run`.
To make the SQLFlow server to be a [stateless server](https://www.quora.com/What-is-a-stateless-server#targetText=Stateless%20means%20it%20has%20no,user%20over%20multiple%20subsequent%20requests.), maybe we can not maintain the state on the server-side. In fact, the distributed AI Job can run on the cluster e.g. EDL on k8s, ALPS on YARN/k8s, XGBoost distributed job on Spark, and the cluster can maintain the job state, so we can only maintain an endpoint which can check the job state on the client-side.
I think it really a URL, if the job is running on YARN, the URL is Job tracker address, if the job is running on k8s, the URL is Kubernetes API URL, SQLFlow server can parse job state from the URL response context.
It's one gRPC call, there would be one or multiple SQL statements in one gRPC call. For the Jupyter Notebook, executing one cell would send a gRPC call to the SQLFlow server.

`Session` contains the  user credential information for the current definition:

https://github.com/sql-machine-learning/sqlflow/blob/0023fc2007d6ec9f62436431e390984e2e5266a1/pkg/server/proto/sqlflow.proto#L22-L27

Agree with making `url` to be a new field in `Session`.
Thanks, I have updated this design doc and introduce a concept `Cluster Job Runner` in the design doc, please review again.

Done.

Done.

Changed to long live connection because it's a gRPC connection instead of an HTTP one.

Done.

Done.

Done, thanks.

`IsFinished` should fetch the rows and logs from the server, since `sqlflow.Run()` can run multiple SQLs at once.
Can `Session` represent information of multiple SQLs?
So if once this proposal has been implemented, does ElasticDL still need to provide a blocking/sync API? Or maybe ElasticDL just needs to provide an API that can be called to check the job status? See https://github.com/sql-machine-learning/elasticdl/issues/1285 for related issue. cc @tonyyang-svail 
The PR title does not mean the same thing as the markdown title
I believe "an API that can be called to check the job status" is better since a training job could last weeks while the long connection can timeout.
After putting more thoughts into this problem, I realize the problem boils down to the `job_tracker_url` only corresponding to a training job, while a `client.Run()` can create multiple jobs. So I don't think we can avoid maintaining states on the server end.
I still think the client's behavior shouldn't base on the deployment type of the server..
Thanks and updated.

For the local job runner, the SQL job is managed by the server-side, and maintain the states on the server.
For the cluster job runner, the SQL job is running in a Kubernetes Pod, the client checks the job by check the k8s Pod stats, so the server does not need to maintain the states.

And I think `job_tracker_url` or `token` is corresponding a SQL job, the SQL job may contain one or more SQL statements.

Maybe implement a blocking API that checks the EDL job in a polling manner is better.
server -> Server
The SQLFlow client
blocking -> wait
When the SQLFlow server receives one training SQL statement, it will generate a python training program that runs on the host or submit the training job to some distributed training service cluster (Kubernetes/Yarn). This will cause:
If one of the SQLFlow server instance fails, the SQL job also fails.
pooling -> polling
communicate -> Communicate
implement -> Implement
Why not directly use ElasitcDL?
generates a token mapping to the SQL job -> generates a token identifies the SQL job
I prefer to call EDL API in the Kubernetes Pod because:
1.  SQLFlow server doesn't need to consider about the dependency for different submitter program, for example: the server can launch k8s Pod with `sqlflow:edl` Docker image to run EDL submitter program and `sqlflow:alps` Docker image to run ALPS submitter program.
1. We can deploy **ONE** SQLFlow server cluster and serve all the submitter type, just launch the SQLFlow Docker image with different submitter dependency installed.



SQLFlow server ...
That's a bit complex, like we are going to do:

SQLFlow server -> call k8s API to start a submitter pod -> submitter call k8s api to start EDL master -> EDL master call k8s API to start workers -> submitter pod wait the EDL master to return -> SQLFlow server return.
Is the `T` specified in the request of `pb`?
the -> The
and wait -> and waits
Suppose a client sends an unexpected `fetchResut` after the job completed, which code would be returned, the `UNKNOWN`?

Do we need a [FSM](https://en.wikipedia.org/wiki/Finite-state_machine) to describe the transition of the state?
@Yancey1989 This proposal handles the polling manner already though. ElasticDL only needs to provide the API that can be called each time to check the status.
Highly Available
finish -> complete
one -> a
When -> Once
will generate -> generates
Python -> Python
Just say submit a job, not to mention running on the host, which means submit jobs to run on the host. No need to mention Kubernetes and YARN either.
Who is going to communicate with the SQLFlow server? No object in this sentence.
Job -> job

I don't see why we need local and server jobs. I understand we need local and Kubernetes job lunchers, which could be a convenient utility to be called by some submitters.
This doesn't look like a token, but a job ID.
Token -> JobID

ClusterJobRunner -> KubernetesJobLauncher
Is there a tight relationship between job ID and storing trained models? I am not sure if we should have this section in this document about job ID.
I don't have a preference for "Kubernetes job submitter" and "local/server job runner".

@Yancey1989 Since we don't have a clear idea of the "Kubernetes job submitter" at the moment, shall we avoid the `LocalJobRunner/ServerJobRunner` interface? I believe we will discuss this issue thoroughly once we move on to implement workflow. :)
You are right. @Yancey1989 shall we change it to `job_id`?
Maybe `results` => `responses`? Sorry that I wrote `results` at the first place...
@weiguoz Good question. I believe the return Code depends on the server implementation. For example, if the server cleans up the `token`/`jobId` after the job completion, the client will receive an error.
Hi @wangkuiyi, you are right. This section is a leftover between @Yancey1989 and me. We were discussing how the Kubernetes jobs should save the trained model.

@Yancey1989 Shall we save this section for future discussions?
In my opinion, `Submitter` and `JobRunner` are two latitude concepts
1. The `Submitter` is a Python program that runs a machine learning job.
1. The `JobRunner` determinates the SQL job would be run on host or cluster(k8s/Yarn).

Yes, you're right, the k8s pod cmd can be:

``` bash
sqlflowcmd -e "sql...."
```
I was struggling with the naming as well. Any suggestions? :)
Add some indents?
Thought the model is saved by `executor.go` by tar all the working directory, so this model save directory can be hard coded maybe?
Good idea
How about refining the interface `xgb.Train(ir)` to `xgb.Train(&program, ir)`,  that don't need to write String to the `bytes.Buffer` twice.

I am still planning to use string because it is easier for people to understand. And we don't think too much about the performance here.
I'm not sure which style of the SQL string is better. How about following the former one? 
In fact, I think this style is pretty good.
Sure. Maybe add a check in `Train` to make sure `ValidationSelect` in `TrainIR` is always empty.
I think either way is fine, as long as it is consistent across all IR codegen. :)
Will be done in #988 
Like `HyperParamsDefDict` ?
`model.hidden_units = [10, 10]` or `hidden_units = [10, 10]`? Shall we make the model parameters consistent with XGBoost?
Should be `model.hidden_units`, to be consistent with all current docs: https://github.com/sql-machine-learning/sqlflow/blob/develop/README.md#quick-overview

I see. Let's keep the current way and discuss this in an issue.
3 -> three
Use English than numbers in formal documents should be better.
Done.
Done.
Should we remove this print?
New line at the end of file.
Done.
Done.
There are so many changes in this file. This reminds us to refactoeize this file somehow to remove duplications.
I am not sure if returning the address of a parameter is to *new* a float value. Maybe 

```go
return &new(float32)
```
Go supports returning address of stack variables: https://stackoverflow.com/questions/52996452/returning-pointer-from-a-local-variable-in-function
1. A model definition may include: model/loss/optimizer/metric,this could be a python file

2.  Besides a model, we also have to define the data pipeline which transforms original data to model input

3. Training logic related code, it loads data and sets up a model to run training

The first is not hard to standardize, we could provide some templates or examples to tell users how to provide.

The second is a little hard to define, there are different kinds of data sources. And it will also lead to different data preprocessing logic. The only determinant thing is to define the model input format. Users' data processing logic must generate the right format.

We could provide some helpful tools for users to construct data pipelines.

The third one is hard to define, we could provide some examples, while users could define its own. Users could also add various logics, such as data random cropping/data batching/data shuffle/etc
Another common case could be creating a new variant model based on the standard model(maybe just adjusting some layers), and training with a new dataset.

For example, we could use `DeepFM`  model to do recommendation. But the model structure may be a little different, in other data sources and scenarios.

Or such high-level users could provide this new variant model back to model zoo.


Maybe use  `requirements.txt` to describe the dependency is better, SQLFlow can `pip install -r requirements.txt` before running the train/pred job.

Does the model zoo have the credential? If not, the pre-trained model can be replaced by anyone.


This is just a single file though. If we want to reuse components such as loss/evaluation_metrics/optimizer/etc., we should allow a Python module instead and then within this Python module users can reuse and re-import from other existing modules.
+1 to use requirements.txt. This should be specific to each individual model.
How do we specify what engine to be used? Should this be part of the model name or is there a better way to explicitly specify this?
Sounds good. Still, if the model is implemented using multiple python source files, these files still need to store in this directory.
Write access is only permitted by administrators. Yet, if we want to implement a "model market", more features like sharing and charging is needed.
We can not permit one model to import stuff from other models because not all models are publicly available, some models is shared to part of the users for access.

Each model should be independent to other models in the model zoo, so, if the model want to reuse some code, you can:

- for public accessible deps, put it in `requirements.txt`
- for local deps, put it in some other `.py` files under this directory.
You are right, engine type, as well as engine version, is needed as the model's metadata. I'll add a file `engine.meta` in the model directory.
defination --> definition
On the one hand, the model trained by ElasticDL can also be published in SQLFlow model zoo. A `model_meta.json` file will be generated when training ElasticDL. 

On the other hand, If you want to train/fine-tune a model from the model zoo with ElasticDL, SQLFlow can use the "columns" information in `model_meta.json` to form a `dataset_fn` which ElasticDL needed.
requirments.txt -> requirements.txt
Tensorflow -> TensorFlow (other places too)
So there cannot be any commonly shared utility modules used for different directories? If the model zoo gets larger and larger, there will be a lot of duplicate code and when it comes to migration/upgrade, it would be difficult.
Done
Thanks, Done
If there are modules or utilities that common, it should be in Keras or TensorFlow, since it's common among all model implementations, or it is just the model specific. Contribute to Keras or TensorFlow if these utilities are really common among models.
TRAIN sqlflow.org/modelzoo/iris_dnn_128x32
   USING sqlflow.org/modelzoo/iris_dnn_128x32
These two models are the same. Will we overwrite the model "sqlflow.org/modelzoo/iris_dnn_128x32" after executing this SQL?
Our model zoo has some something in common with https://www.tensorflow.org/hub, maybe we can take it for reference.
weights is only stored under => weights are only stored under
model is saved to local, which is identified by the `INTO` clause. `TRAIN ...` will not write the model.
Thanks, will take a look~
Github repo might not be a suitable place to store the actual artifacts of models since the models can get really large and Github is not suitable for large files. We need to consider a third-party storage for this.
This typo is still here
In the design of sqlflow, how do we express the feature engineering logic(such as the preprocess logic using TF-Transform) ? Should we put it in the select section such as SELECT SUM(X), MEAN(Y) FROM some_table, or in model definition?
We do data pre-processing using SQL statements currently, the pre-process SQL statements will generate some temporary tables for train/validation. Then the training SQL statement will use the temp table directly.

We did not consider cases using TF-Transform for now, maybe we will add this part of the design in the future.
The model zoo doesn't train anything.
I think the model zoo contains not only the "model", but also the process that converts data into model inputs. Only if we have both parts in the model zoo, we could make sure that the prediction and the training are using the same conversion from data to model inputs.
The model definitions are Python programs. We cannot make a file service that provides program downloading. This violates most security rules.

I see a viable solution to publishing a version of a model zoo is to package model definitions into a Docker image, together with the SQLFlow server.
The publication of a trained model needs to upload the parameters of the model to a storage service, labeled with the version, or Git commit ID, of the model zoo.
Input conversion information is included at: https://github.com/sql-machine-learning/sqlflow/pull/949/files#diff-4979133b9186419f2057f96cafe9b0c1R63
Why not? SQLFlow users can choose to use the model to train from scratch or fine-tune a model, either is possible. We can not limit the usage only to fine-tuning or transfer learning.
I added subdirectories in the file service for versioning. In fact, the versioning of Docker images are also saving different images for each version.
Done.
I would suggest using the `.ymal` file, which carries comments so as to more readable.
Sounds good, will update in next PR
I don't think we need to `Close()` the `os.Stdin`.
Done.
FYI, Go's default "flag" package doesn't differentiate between `-` and `--`, so `-execute` is the same as `--execute`.
~~I am not sure if we need `terminal.IsTerminal()`. If the user doesn't type in `-e/-f`, we should start the program as a REPL.~~ Never mind, I see the code also supports reading from stdin.
I am not sure why we need to print `sqlflow>` in a non-terminal mode such as `go run repl.go -e "select 1;"`. 
I propose to separate `sqlRun` out from `main` to be a function definition as the following

```go
func runStmt(stmt string, isTerminal bool)
```

so to make `main` shorter and more comprehensive.
I propose to extract this `for` loop out from `main` to be a function definition

```go
def repl(inputScanner bufio.Scanner, isTerminal bool)
```
Yep. The reason of introducing `-execute` and `-file` is to be consistent with `-model_dir` and `-datasource`, while `-e` and `-f` is to be compatible with hive.
In my own experience, user may use redirection to save information in the training process,  such as `go run repl.go -f 'train_and_evaluate.sql' **> train.log 2>&1**`, `sqlflow> ` can be used as an indicator for different output blocks.
Done.
Done.
Maybe group these to a message called `HiveConfig`?
hdfs_namenode_addr is actually an HDFS config not for only hive.
`PredicrIR ` => `AnalyzeIR`?
This comment is likely to be out of date. Please change to "Explainer types. For example TreeExplainer.".

The list of supported explainers should be documented elsewhere. :)
Not sure why we need to change these files. Have you used a code formatter?
Is there a linter complaining we need to explicitly name the field name? If so, please file the change in a separate PR.
The go vet complains: `[govet] xxx(struct) composite literal uses unkeyed fields [E]` while I'm editing in another file.
I found that there was not much code to be changed, so I changed them conveniently.
My understanding is that "zoo" is a little different from "market" in the mechanism. In the "zoo" the only requirement is model repo sub-folders are read-only for non-authors; but "market" requires a whole new world of transaction mechanism from authorization to payment (such as pay-as-you-go mode).
Do we need to check the arbitrary select statement using third-party parsers like calcite, or directly send the statement to the DB engine? It's easy to implement if we can directly send the SQL statement to the DB engine, and if grammar error occurs, the DB engine should return some error message before the SQL is executed.
Is it vital to use APIs like `describe table` to retrieve column names and types? Running the arbitrary select statement maybe resource consuming.
A little confused about when to use the alias. If we write `SELECT c1,c2,c3 FROM table TRAIN model COLUMN c1,c2,c3`, this seems clear enough for the column clause. If we write `SELECT *`, the user may already know the column names, or just let SQLFlow to use them all.
fetch the training data -> fetch the training log?
If WITH is optional?
Maybe add some examples to show how SQLFlow should use lexer to split the train clause?
I prefer directly sending the SQL statement to the DB engine.

The parser can check the syntax error, while the DB engine already does that.
Just to clarify, you are referring to create a temporary table using `CREATE TABLE {.TempTable} AS ({.SelectClause});`, then use `describe table` to retrieve column names and types. By doing so we can avoid running the arbitrary select in the later feature derivation stage and training stage.

If the user has the write permission to the DB, I do believe this method can have performance improvement. However, I would like to save these details until we find performance is the major issue.
Thanks for pointing it out. For example:

```
mysql> select class + class from iris.train limit 1;
+---------------+
| class + class |
+---------------+
|             4 |
+---------------+
```

The name `class + class` is system-generated, and the user may not know in advance.

I will add this example to the design doc.
Sorry for the confusion. I was thinking the submitter is running the training job locally, and the training job is fetching the training data, so the submitter is fetching the training data. However, the submitter is likely to run the training job remotely.

I will remove ~~"to fetch the training data"~~.
> Maybe add some examples to show how SQLFlow should use lexer to split the train clause?

Thanks for the suggestion. I will add an example.

> If WITH is optional?

Currently, our parser still requires the `WITH` clause. The design doc illustrates the main idea. And we should reference the code for the specific implementation. I am changing 

If SQLFlow finds the following consecutive tokens ...

=>

If SQLFlow finds the consecutive tokens like ...
I see, that's cool.
> However, I would like to save these details until we find performance is the major issue.

Sounds good.
I agree with @xieliaing. This document is only about zoo.
Should also include model parameters ( weights ).
We should make clear what the identifier is used for follows `TRAIN`, `USING`, `INTO`:

`TRAIN [IDENT]`: IDENT is a model def.
`USING [IDENT]`: IDENT is the location stores a model parameter set.
`INTO [IDENT]`: IDENT is the location stores a model parameter set
How can `MyDNNRegressor` distinguish it's a model in the model zoo or a pre-made estimator or some self-defined model in `PYTHONPATH`? And how to convert the name `MyDNNRegressor ` to docker image `a_data_scientist/regressors`? We can not assume all the model name is in the model zoo, we need to run the model before it's published to some docker repository.
For distributed cases, the command should be calling ElasticDL. Also how to put generated `my_first_model.py` to the runtime containers.

Use a database to store the saved model is:

1. hard to publish or share the weights to other users.
1. users are using different databases, it can not be commonly used for all open source users.
1. for some database engines it's not suitable to store model parameters in the database like hive. Most of the saved models are of "small size" for HDFS
I think we don't need to enable the use of pre-made Estimators or self-defined models in PYTHONPATH. How about disabling these possibilities?
I propose the solution as described in https://github.com/sql-machine-learning/sqlflow/pull/1042/files#diff-0e016e244fea1579c23458c190308b87R82 for Docker images to list the model definitions it contains.
In my mind, in order to submit an ElasticDL training job, we need the following actions.

1. The SQLFlow server invokes codegen_elasticdl.go to generates the submitter program `my_first_model.py`.
1. `my_first_model.py` calls the ElasticDL client API to submit a job.
1. The SQLFlow server then runs `my_first_model.py` in a Docker container (if SQLFlow service is not running in a Kubernetes cluster), or a Pod, which has ElasticDL client library installed.
1. As this container needs to contain ElasticDL and the model definition, it must be derived from `a_data_scientist/regressor`, like from the following Dockerfile:

   ```dockerfile
   FROM a_data_scientist/regressors
   RUN pip install -y elasticdl_api
   ```

Please correct me or improve the above idea.
Thanks, I see. Another question, we can release one or more docker images, where can we find all docker images built for SQLFlow models? Maybe we can use a [docker registry](https://docs.docker.com/registry/deploying/)
I see, that's clear enough. One question, maybe we can just build all model zoo Docker images with ElasticDL API ( model Dockerfile should depend on our base image like `sqlflow/sqlflow_model_base`), then the submitted job can directly use the model's Docker image, or else it may require to build an image and push to the registry before submitting the job.
Can we also use the syntax like `SQLFLOW LIST` to list all models available and `SQLFLOW DESCRIBE my_first_model` to show the model's document?
I see. It is like requiring all model definition repositories have their Dockefile's all derived from a common base image. I think it is a viable solution.
I think the model zoo database is part of the SQLFlow server. It could be embedding DBs like SQLite.
Good idea! I might not have sufficient time today to follow your suggestion in this PR. Please feel free to merge this PR and submit successive PRs to complete these ideas.
`tools and Git` -> `tools like Git`?
Do we need a `docker pull` or `git pull` like command here, to pull the model in the model zoo to local? 
Training might be mixed with evaluation sometimes too. We should probably also store evaluation hyperparameters. They can affect the resulting trained model (in case techniques like early-stopping is used).
Also need the docker repository location where this particular docker image resides
predict some data -> make some predictions on new data
I would suggest separating the `an_analyst/my_first_model` into 2 fields(`an_analyst ` and `my_first_model`) to support  SQL like `SQLFLOW LIST an_analyst` easier.
I think using dot rather than slash  is more nature in SQL, such as `an_analyst.my_first_model`.
If `an_analyst/my_first_model` is a path, maybe a quoted string is more preferable, a quoted string implies that the slash is not an operator, i.e. `an_analyst/    my_first_model` is different to `an_analyst  /my_first_model`, but `an_analyst.    my_first_model` and `an_analyst  .my_first_model` has the same meaning.
It seems we should save the extended SQL itself instead of the two above fields, for example: if the user trained two different datasets at different time (daily analysis e. g.), the model zoo should know which model comes from which dataset. 
As a supplement, the SQLFlow version and training date/time can be present too, just like the build number in software versioning.
At last, there should be a description field that records training result (test accuracy etc.) by default, or users cannot distingish different models if they have too many.
Is it possible to avoid `feature_column_code` and `estimator_code`? So that we don't need to call `eval`.
Is this table the same as the model zoo table mentioned above in line #86? It seems they have different schemas.
The model zoo is a collection of Docker images. When the SQLFlow server runs `docker run`, the Docker client would pull if needed.
Yes. For simplicity, I just mentioned all hyperparameters related to training by "training hyperparameters".
Please be clear `/var/sqlflow/submitters/an_analyst/my_first_model.py` is generated by SQLFlow. I was wondering what is `my_first_model.py` until I read the conversation at 

> The SQLFlow server invokes codegen_elasticdl.go to generates the submitter program my_first_model.py.


I also had the same question as @typhoonzero while I am reading the design. Please add "the following actions" to the design doc.
~~SQLFlow passes the argument to `docker run` and starts the training. And the `docker run` is supported by the model repo, so the model repo is responsible for the distributed training?~~
I see. Yes. Just like the full name of a trained model like `model.sqlflow.com/an_analyst/my_first_model`, we need `dockerhub.com/a_data_scientist/regressors` here to name a Docker image.
Do you mean making `SQLFLOW LIST a_data_scientist` to list all model definitions in all Docker images built from code repositories owned by `a_data_scientist`?
No, SQLFlow will generate a submitter program according to
1. the model.py provided by the model repo
1. the `input_fn` generated according to `COLUMN` clause.
Both the full name of Docker images and trained models like the following are inspired by the convention used by Docker to name images.

- `dockerhub.com/a_data_scientist/regressors` or `a_data_scientist/regressors` names the Docker image hosted on `dockerhub.com`. This convention is from the Docker community.

- `models.sqlflow.com/an_analyst/my_first_model` or `an_analyst/my_first_model` names a model trained by `an_analyst` and hosted on `models.sqlflow.com`. I prefer to use the same convention of Docker image names, rather than inventing a new one like `an_analyst.my_first_model`.
I agree that we might need more fields here. Each exists for some reason. We could add these fields together with the reasons later.
I don't see relation to #86.
I agree that the identifier after `TRAIN` is the name of a model definition. However, the identifiers after `USING` and `INTO` are not the local of model parameters; instead, it is the value in the `model ID` field of the model zoo table, as described later in this document.
We should use `sqlflow.org`?
I am afraid that the model service would be a commercialized one; as we need fundings for storage and computation resource.
Sounds good, will try to refine this in next PR.
s/catch/cache
data conversion or "feature transformation"?
> In my mind, in order to submit an ElasticDL training job, we need the following actions.
> 
> 1. The SQLFlow server invokes codegen_elasticdl.go to generates the submitter program `my_first_model.py`.
> 2. `my_first_model.py` calls the ElasticDL client API to submit a job.
> 3. The SQLFlow server then runs `my_first_model.py` in a Docker container (if SQLFlow service is not running in a Kubernetes cluster), or a Pod, which has ElasticDL client library installed.
> 4. As this container needs to contain ElasticDL and the model definition, it must be derived from `a_data_scientist/regressor`, like from the following Dockerfile:
>    ```dockerfile
>    FROM a_data_scientist/regressors
>    RUN pip install -y elasticdl_api
>    ```
> 
> Please correct me or improve the above idea.

Are you talking about submitting a model to the zoo, or submitting a training job? A little bit lost in the discussion.
Is `my_first_model.py` written by the developer or generated by the system? Does it contain just the model definition, or also include the data pipeline?
Can we support the tag similar with docker images?
We should probably save both the training SQL statement as well as the "data converter", because we are doing "feature derivation" when training, the "data converter" is generated based on the training data. If the data used for predict is of different format of training data, go through "feature derivation" again might cause some error.
@tonyyang-svail does that mean we still need to generate some python source code and run it in the docker container?
We will delete this line because we all need to run `codegen` to generate a python program containing all hyperparameters to submit the job.
=> `fmt.Errorf("unsupported explainer %s", ir.Explainer)`
`model:%s` => `model: %s`
Please switch to `attribute.Dictionary` in the upcoming PRs. Example:

https://github.com/sql-machine-learning/sqlflow/blob/eb19db58b36640b58cca0e6b979be0dff7101e4a/pkg/sql/codegen/xgboost/codegen.go#L37-L47
GenAnalysis => Analyze. This function should be called as `xgboost.Analyze`.
resolveParames -> resolveParams
from sqlflow_submitter.db import connect_with_data_source
`return os.Getenv("SQLFLOW_codegen") == "ir"`
Remove `fmt.Printf...`
I'm curious the value of `len(resultTableParts)` would be 3, 2 and 1...
Would you plz add some comments? Thanks.
How about making the condition more clearly?
``` go
    resultTableParts := strings.Split(intoStatement, ".")
    if len(resultTableParts) > 3 {
        return "", fmt.Errorf("bla")
    } else if len (resultTableParts) == 3 {
        return strings.Join(resultTableParts[0:2], "."), nill
    } else {
        return intoStatement, nil
    }
```

Never mind, just for your reference.
FYI, package `tensorflow` has the same code snippet. If we were to change them, change both.
https://github.com/sql-machine-learning/sqlflow/blob/0b716a3b1bdcd038ddb401fe292a9169c6560e41/pkg/sql/codegen/tensorflow/codegen.go#L241-L249
```
"sqlflow.org/sqlflow/pkg/sql/codegen/xgboost"
xgb "sqlflow.org/sqlflow/pkg/sql/codegen/xgboost"
```
Looks like the package has been imported twice. Not sure if there is any side effect.
Nice refactor!
What is a "Model Document"? The title is very confusing. I can understand a file named `pkg/sql/codegen/xgboost/README.md` is a about the XGBoost codegen; however, I have no idea what will a `model.md` file is supposed to present.
If the executable is supposed to update `doc/model.md`, why don't name it `docgen/model.go`?
How about renaming it to "Model Parameter Document"? As mentioned in the first paragraph of this document, the document lists all model parameters supported by SQLFlow
You are right, the name `model.md` is confusing. I will change it to `model_parameter.md`.
Sure. I have renamed `docgen/main.go` to `docgen/model_parameter.go`.
Add xgboost case?
Seems no test can ensure that these fields are filled?
Using `regex` to ensure the `HDFS...` field.

`sqlflow.org` will generate indexes using document titles. Should have meaningful titles so the document for tensorflow, xgboost, alps wouldn't be the same.
shapSummaryAttrPrefix
Please note that go test may run test cases unordered, the model may be not generated when running this test, it's better to generate this model first before running `ANALYZE`.
The [ref](https://github.com/golang/go/blob/a813d3c788b4ec58032616e8d269ee65d1b10085/src/testing/testing.go#L791-L792) introduces a `go test` run parallel with other tests if and only if the `t.Parallel()` was called.

This is not about parallelism, it's about the order, see https://stackoverflow.com/questions/31201858/how-to-run-golang-tests-sequentially, it says:

> You can't / shouldn't rely on test execution order. The order in which tests are executed is not defined, and with the use of testing flags it is possible to exclude tests from running, so you have no guarantee that they will run at all.
In our e2e test, the [subtests](https://blog.golang.org/subtests) are ordered by group
https://github.com/sql-machine-learning/sqlflow/blob/672d4ef75fcaa955ddab1fc5f03278d51c77a4b4/cmd/sqlflowserver/main_test.go#L308-L310
But we would run `go test -run CaseTrainAndAnalyzeXGBoostModel`  independently some times, it needs an existed model, so I add the several codes for that.
Sorry about the confusion. I want this file contains all the document for for tensorflow, xgboost, alps.

I have updated the description in https://github.com/sql-machine-learning/sqlflow/issues/1028 to the following.

> A command-line `docgen` in `cmd/docgen` that will call `func DocGenInMarkdown() string` for each package and combine them to `doc/model_parameters.md` 
Was this a bug? Why was the label column in `trainIR.Features`?
I see
The previous implementation includes the label in `trainIR.Features`. Removed now.
`job string ` => `job pb.Job` ?
Great job! Do you want to set up Argo on the Minikube in a bash script?
In practice, we do NOT need the `argo` command, so we don't need to edit the Dockerfile.  Instead, it is the submitter program running in the SQLFlow server container who submits Argo workflows.  It does so by calling the Kubernetes Restful API, but not the `argo` command.

Therefore, I would suggest canceling the edits to Dockefile in this PR.

Another note is that the SQLFlow server container is likely running on the same Kubernetes cluster, on which, we run Argo workflows as well.  Calling Kubernetes APIs from a container running on the Kubernetes cluster is known as *Kubernetes-native*.  For how to implement Kubernetes-native calls, please refer to the ElasticDL master program. 
clluster -> cluster
Hi @wangkuiyi, could you please provide the link to the code snippet in the EDL master program that invokes Kubernetes-native calls? It is hard for me to find it by going through the source code.
https://github.com/sql-machine-learning/elasticdl/blob/develop/elasticdl/python/master/k8s_worker_manager.py#L61
Removed Argo in Docker image.
Could you remove `db *sf.DB` as well?
"defination" => "definition"
Potential bug: should be `continue`?
Unknown type do not need to check the actual value's type, just added checker call here.
`Validate` should validate all attributes. One attribute being `Unknown` doesn't mean we don't need to check the rest attributes. So we should change `return nil` to `continue`.
I see, sorry my brain wa ta le.
message in stdout may not be error message, just print "program output"?
"Error Message" => "Program Output". +1
I think lower and upper should be a pointer, we can use `nil` to represent no-bounds: `(1, nil, true, false)` => `[1, ~)`
This change uses LowerBoundChecker and UpperboundChecker to represent infinity bounds. The two functions behave similarly to the builtin operators `>=`, `<` etc. As a result, we don't need `nil` anymore.
As explained in https://bitbashing.io/comparing-floats.html, it doesn't make much sense to compare the equality of two float values. We should rewrite the conditional something like

```go
if (!includeUpper && f < upper) || (includeUpper && f <= upper) {
    return nil
}
```
Done.
The comment is not inconsistent with the following code, BoolIntChecker **do** check the input.
IntChoiceChecker returns an error message like `fmt.Errorf("attribute value out of range(%v), actual: %d", choices, i)`, but it's not clear for the user to find out the relative attribute name.
> IntChoiceChecker returns an error message like `fmt.Errorf("attribute value out of range(%v), actual: %d", choices, i)`, but it's not clear for the user to find out the relative attribute name.

This is an existing problem in other checkers, maybe I can fix this later in another commit
@weiguoz I'll try polish the error message in the next PR.
I don't get the logical connection around this "so". There are two bullets before "so" and three after it. Which one of the first two is the reason for which one in the last three?
pre-existing => existing
You skip over the logical progression here and enumerates some concepts. This is confusing -- why do you list these concepts.

1. We want SQLFlow to work with existing SQL engines, while extends them to support AI.
2. We want the extension is in the form of appending SQLFlow extension clauses to a SQL SELECT statement.
3. Each SQL engine might have its own SQL dialect of the SELECT statement.
4. We need the **SQLFlow parser** to call **dialect parser** to handle the SELECT statement and calls the **SQLFlow syntax extension parser** to process the appended clauses.

The logical progression reveals the concepts naturally in a logical order, which helps comprehension.
`TO TRAIN/PREDICT` -> `TO TRAIN/TO PREDICT` is more clear?
What about `ANALYZE`?
What to do if parsing failed before `p`?  Does it mean SQL statement is an invalid stander SQL?
Just a mention, for the future `VALIDATE` future: `SELECT ... TRAIN ... VALIDATE (SELECT ...)` , we also need to parse the validate SELECT statement.

Do the TPP API also need an API to return the AST or just columns to verify the SELECT columns and COLUMN statement 
 in extended SQL? 
> Does it mean SQL statement is an invalid stander SQL?

Yes. Thanks for mentioning this. I will replace this paragraph with a concrete algorithm.
Hi @wangkuiyi, thanks for the suggestion. I have rewrote the whole section to make the logical progression more smoothly.
You are right. I will rewrite this paragraph.
I believe TPP only does the syntax checking. Take `select * from some_table to train ... column c1, c2` for example, the parse doesn't and shouldn't check whether `select *` has `c1`, `c2`.
> TO TRAIN/PREDICT -> TO TRAIN/TO PREDICT is more clear?

Sure.

> What about ANALYZE?

Added.
typo: `enouph`?
It seems the old `filedClause` is  useless.
Yes, I keep it just in case. Maybe we need another commit to clean such stale syntax rules.
Naming: `validation.dataset.table` or `validation.table`?
~~Is it possible to keep this feature? A user may enable it by `validation.split_ratio = 0.2`.~~

This feature requires SQLFlow to modify the database by creating temporary tables during the execution of the Go code, while the Go code should only be responsible for parsing and code generation. The execution is left for the workflow engine.
I am not sure if we need to check the existence of the "dataset" key.
Naming: Does `DS` refer to `Dataset`? If so, maybe change to `validationDataset` or `validationSelect`.
Naming:

- `validation.dataset` or `validation.select`?

- `validate` or `validation`?

    - verb: train, predict, validate

    - noun: training, prediction/predicting, validation
+1 for `validation.table`
Is there any mechanism of go mod that could handle such indirect modules automatically?
Please check out the document link above. `go.mod` and `go.sum` are generated automatically.
Add `ENV GO111MODULE on` in Dockerfile also? You can refer to the changes on Dockerfile in https://github.com/sql-machine-learning/sqlflow/pull/1097
@typhoonzero How come such `//indirect` dependency entries? Did you manually add them? If so, why did you do that, instead of leaving these indirect dependencies using their default versions?
@typhoonzero @tonyyang-svail Can we remove the settings of `GO111MODULE=on`  if we install Go 1.13 into our Docker image by editing the following code snippet?

https://github.com/sql-machine-learning/sqlflow/blob/2dc6657bc4095852c3cc666aadfbf0b6efca175f/scripts/build_docker_image.sh#L47-L51

I ask because it seems from https://blog.golang.org/using-go-modules that since 1.13, the module mode is by default on.
The validation data is usually not the same as the training data. So maybe rename `boston.train` to `boston.val`?
Using a verb or a moving phrase for a function name should be better.
will this work if a standard SQL follows the `TRAIN` SQL, like: `select * from iris.train to train a_model; select * from some_table;`?
It will work.

Line 61: `psr.Parse("select * from iris.train to train a_model; select * from some_table;")` will raise error at `to`.

Line 69: `psr.Parse("select * from iris.train")` will pass.

Line 86: `{"select * from iris.train ", pos, nil}` will be returned.

Then SQLFlow's extended syntax parser will parse the `to train a_model;`. Then SQLFlow will call `ParseAndSPlit` again to sparse `select * from some_table;`.

Please be aware that `split` function in `pkg/sql/parser/split.go` is recursive.
Changed to `extendedSyntaxParse`.
maybe add some message: `print("Validation result: %s" % re)`?
`go.mod` and `go.sum` is generated automatically by running `go test`.
This will be fixed in the next `polish code` pr.
sure
Should we fix the version of TiDB as something like [`v3.0.5`](https://github.com/pingcap/tidb/tree/v3.0.5)?
driver => sql_engine or dbms
split => parse
parse(dbms, sql_program string)
split.go => parse.go
split_test.go => parse_test.go
Do we need to dump the ParseResult into a JSON?
Where is the implementation of this `Parse` function in the Go source files?
tpp => third_party_parser or native_parser
Done.
Done.
Done.
Done.
Sorry for the confusion. I have updated the documentation. Basically, `sql_engine.Parse` will invoke a Java command-line which takes a SQL string and outputs the parsing result in JSON format. Then SQLFlow can parse the output into the following Go struct.
`pkg/sql/parse.go`.
go lint forbids using an underscore in the package name. And the package name is better to be consistent with the directory name. So I am keeping the `tpp`.

```
hookid: go-lint

pkg/sql/third_party_parser/third_party_parser.go:14:1: don't use an underscore in package name
Found 1 lint suggestions; failing.
pkg/sql/third_party_parser/tidb_parser.go:14:1: don't use an underscore in package name
Found 1 lint suggestions; failing.
pkg/sql/third_party_parser/tidb_parser_test.go:14:1: don't use an underscore in package name
Found 1 lint suggestions; failing.
```
This line is generated by running `go get github.com/pingcap/tidb@v3.0.0`. I am not sure why it appears to be `v.0.0.0-2019....` in the `go.mod`.
Invalid
Go is installed in the Docker image, so we may not need to install Go.
I was thinking about the same thing. Are you using git on your host? If so, you have to install Go and Java. Because `git commit` will trigger `pre-commit`,  and `pre-commit` will run Go command and Java command.
if we moved -> once we move
I see.
HiveQL
Calcite
Remove debug logs.
Remove debug logs.
We need a comment explaining the use of this class.
It looks to me that the test for Calcite parser and the one for HiveQL should be in different test source files.
Done.
Done.
I've added the comments.
You are right. I have put two tests into two source files.
Done.
Done.
These two tests have some code in common, maybe construct a base class to store the test case, and result testing functions and the sub-classes call the corresponding parser.
Are you going to delete this Dockerfile once the parser development is done? We can use the SQLFlow Docker image to run these tests.
Xgboost => XGBoost
Will refine in next PR.
Let's follow the usage: `Copy(src, dst)`
This is inspired by https://golang.org/pkg/io/#Copy
Next time, please file a separate PR for moving run standard SQLs functionality our of `executor.go`, since it isn't related to the title of this PR.
I don't think we need to create a temporary directory for the whole SQL program.  Different SQL statements should have different working directories.
This function is the entrance, move it to the beginning of the file. It shouldn't be sitting next to `getDefaultSession` and `errorPipe`.
Remove `cwd` parameter. Steps shouldn't be sharing the same directory.
Why does the server need to consume all messages? `sf.Pipe` supports closing on both ends.

The server side goroutine writes a message to `func (w *PipeWriter) Write(item interface{}) error`. If an error has returned, the goroutine should exit.

Please refer to this [design doc](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/close_producer_from_consumer.md) for details.
Can we change `runStandardSQL(statement, db)` to `runStandardSQL(wr, statement, db)` so that we can avoid the`Copy`?
What is "all" in "all moved to IR"?  Does it mean `ALPS` and `EDL`?

`executor_ir.go: 146` also uses `OriginalSQL` during the model saving.
Move this test to `executor_ir_test.go`.
Shall we avoid implementing this function following https://github.com/sql-machine-learning/sqlflow/pull/1133#discussion_r343859836 ?
Remove commented code.
May need to remove `cwd` parameter from `generatePredictIR` and `generateAnalyzeIR` so that we can separate generating IRs and run them.
Add `defer rd.Close()` solved this, thanks!
`LogChanWriter` is at `executor_standard_sql.go` so I'll keep it here.
Sorry. I'll keep this PR updating since you already reviewed most of the part. Will try doing separate PR next time.
A PAI program is a python program that uses TensorFlow or other frameworks like XGBoost. PAI requires the python program to expose several command-line options to communicate with ...

Typically, you can submit the PAI program by:
the command above -> the above command
Why and how the program communicate with MaxCompute?
Maybe can just paste the link to the details of how to use these command, not describe it in here.
Better to add a blank line after titles.
the specified engine -> PAI?
k8s is always needed?
Currently, each deployment have been configured to use one submitter. The user can not specify which submitter to use.
You can not directly submit a model python file, you should submit several files including:

- python program generated by SQLFlow which uses the model file as model implementation.
- the model implementation file.
- dependencies python files.
Is this the format of the saved model? How this format of the saved model can be published to the model zoo, and how can a user submit a PAI training job using a published model from `model.sqlflow.org` which is of different format?
Add a `TO`
I'm confusing about the relationship between PAI, PAI Tensorflow, and PAI task ... Maybe we can explain these concepts first?
we train a model => we train/predict/analyze a model ...
submitter file => submitter program
> the submmiter program is mapped into a Docker image

Do you mean `mount` into a Docker container ?
> Maybe can just paste the link to the details of how to use these command, not describe it in here.

I can't find any detailed description on the Web about how to submit a PAI task with `odpscmd` or `pyodps`, i. e., the most viable way for users to check out how to submit a PAI task is through `odpscmd -h`. Anyway, I'll paste the links to their official documentation here.
The command line here is only for demonstration. In practice, all the python files will be packed into a `.tar.gz` file. And there's a command-line option to specify which python file is the entry.
Got it.
Done.
Done.
Yes and Done.
Done.
> the command above -> the above command

Done.
> A PAI program is a python program that uses TensorFlow or other frameworks like XGBoost. PAI requires the python program to expose several command-line options to communicate with ...
> 
> Typically, you can submit the PAI program by:

Done.
> Why and how the program communicates with MaxCompute?

The program needs to get training data from MaxCompute.
This is only for the PAI model zoo. The first several fields are consistent with models from model.sqlflow.org, so we can simply omit the extra fields 
 when publishing a model to `model.sqlflow.org`, because they are only useful for users of PAI model zoo. Similarly, we can keep the extra fields unfilled when submitting a PAI job using a published model from `model.sqlflow.org`.
I remember we talked about using minikube for single machine users in the near future, so shouldn't we only consider k8s here?
Done.

> Currently, each deployment have been configured to use one submitter. The user can not specify which submitter to use.


`The specified engine` here -> the engine specified by the deployment configuration.
Need to rewrite to make it clear.
> The program needs to get training data from MaxCompute.

what command line options are needed? example of how to write a PAI training python program or a link to the example should make this description more clear.
The PAI Tensorflow training job runs on the cluster resource provided by PAI. Maybe `sqlflowserver` is deployed on k8s, the argo workflow runs on k8s, but the training job runs on PAI.
the SQLFlow server -> The SQLFlow server
> I'm confusing about the relationship between PAI, PAI Tensorflow, and PAI task ... Maybe we can explain these concepts first?

Done.
> Need to rewrite to make it clear.

Done.
> we can pack all the python scripts/dependencies of the PAI program into a tarball that can be passed to the `-Dscript` option.

The dependencies of a model in the model zoo is specified by a Docker image, how can we pack the dependencies?
I think this section has been explained in the model zoo design doc, can we delete this section?
Maybe put the "Concepts" section ahead of "Submit a Task to PAI".
couler or workflow uses python API to submit a workflow, better to use PAI python API here?
You can add a requirements.txt that describes the requirements  to the tarball
Done.
Let me try.
Does this means we must have a `requirements.txt` in the Docker image of every model?
Should be couler will have a module like `couler.pai` to use `pyodps` to submit jobs to PAI?
I think so, submitting a PAI program is sort of complicated. 
> A [PAI program](#Concepts) of PAI model zoo may have multiple python source files and will be executed as a [PAI task](#Concepts) on PAI rather than a process in a Docker container.

maybe just say: PAI do not support run the model in a Docker container.
> the Docker image should specify the directory where the model source files reside

A Docker image can not specify anything, the model developer (data scientists) can. Or we can say: "The source files of the model must be put into the directory `/workspace` in the Docker image"
> `SQLFLOW_MODEL_ZOO_MODEL_SOURCE=/model_zoo/`

the directory where to put model source files is not the "model zoo" I think. It may contain several models, but not **the** "model zoo".
SQLFlow will generate the python program. And it will call couler to submit the job to PAI.
Couler is not ready at the moment, we may revise this statement after it's ready.
> > `SQLFLOW_MODEL_ZOO_MODEL_SOURCE=/model_zoo/`
> 
> the directory where to put model source files is not the "model zoo" I think. It may contain several models, but not **the** "model zoo".

`model_zoo` is only an example here, it's the root of all the models in that Docker image.
> model_zoo is only an example here, it's the root of all the models in that Docker image.

Try to make the design specific, the implementation should look exactly like the descriptions in the design.
Yep. I will do so in the next PR. :)
Sure. I will refactorize it in the next PR.
Sounds good.
Not a problem.
I see. `LogChanWriter` is not used in the `executor_standard_sql.go` tho.
Couler and SQLFlow
This design is about the migration from SQLFlow submitters to use Couler.

Couler is a compiler that translates a workflow represented by a Python program into an Argo YAML file, which can run on Argo, the Kubernetes-native workflow execution engine. Couler is also a framework that directs users to define steps and workflows as Python functions.

SQLFlow is a compiler that translates a SQL program into a Python program known as a *submitter*. Currently, SQLFlow has several compiler backends known as *codegen*s.  For example, `codegen_xgboost.go` generates a submitter that calls ODPS for the execution of usual SQL queries and XGBoost for training and prediction models.  The Python code that calls ODPS and XGBoost deposits in the `python/` directory of the SQLFlow source code repository.

The migration includes the following parts:

1. Converts Python source code called by submitters into Couler definitions.  For example, 
   - `couler.{odps,mysql,hive}.query(sql)` run a SQL program/statement on ODPS/MySQL/Hive
   - `couler.{odps,mysql,hive}.export(table, filename)` exports a table from ODPS/MySQL/Hive to RecordIO files
   - `couler.{xgboost,tensorflow,elasticdl}.train(model_def, data)` trains an XGBoost/TensorFlow/ElasticDL model
   - `couler.{xgboost,tensorflow,elasticdl}.predict(trained_model, data)` predicts using an XGBoost/TensorFlow/ElasticDL model

1. Deposits some frequently reusable workflows into Couler functions.  For example
   - `sqlflow.couler.query(db_info, sql)` calls `couler.{odps,mysql,hive}.query(sql).
   - `sqlflow.couler.train(db_info, sql, ai_info, ...)` calls `sqlflow.couler.query`, `sqlflow.couler.export`, and then `couler.{xgboost,tensorflow,elasticdl}.train(...)`.

1. Instead of having multiple codegens, let us have only one, `codegen_couler.go`, which, translates the intermediate representation of a SQL program into a Couler program. Then, SQLFlow can run the Couler compiler to further convert and execute the workflow.  

   For example, `codegen_couler.go` converts a `SELECT ... TO TRAIN` statement into the call to `sqlflow.couler.train(db_info, sql, ai_info, ...)`.
Only the codegen_couler.go has the chance to take an IR (intermediate representation). A Couler function doesn't have the chance.
After reading through the source code of Couler, I feel we can simply write the Couler template as

```
def myfuc():
    # SQLFlow generated code, like pkg/sql/codegen/tensorflow/template_train.go

couler.run_script(image="sqlflow/sqlflow:latest", command="python", source=myfunc)
```

Hi @tonyyang-svail , I updated this design doc, and the pipline is: `sqlflow.couler.{tensorflow,xgboost}.train -> couler.{tensorflow.xgboost}.train -> couler.run_container(...)`
Can use [createTempFile](https://docs.oracle.com/javase/7/docs/api/java/io/File.html#createTempFile%28java.lang.String,%20java.lang.String,%20java.io.File%29) to create the temporary file.
Maybe we can follow #1146 , keep the second way.

LGTM. In this design, SQLFlow is only responsible for the parsing, verifying, feature derivation, and serializing the result into the following Python struct.
And we need to think about who is responsible for generating the user documentation. In my opinion, who is translating `train.epoch` to `epoch` should be responsible for docgen, which is Couler in this design. Do you think it is reasonable?
This is indeed a great advantage. A data scientist is usually more familiar with Python than Go.
Thanks, I will try it out in future PRs.
@tonyyang-svail can't agree more. By the way, if couler is generating the documentation, we should put couler repo under github.com/sql-machine-learning so that we can generate documentation under sqlflow.org.
Maybe we can refine this later using the Linux pipe to avoid writing temporary files on the disk.
unused import?
- What SQLFlow provides?
- How an existing SQLFlow sql looks like? Users need to specify model, hyper-parameters, input data, etc.
- This doc is to further reduce users' inputs by introducing hpo, to remove `with`.
Apache MXNet
Trail -> Trial
vizier -> Vizier
Note that if a saved model is large we may have multiple rows, each row stores part of the saved model.
How about saving the whole model to storage media like OSS?
Maybe for cases like training with PAI Tensorflow, we can store the URI of the saved model file on OSS in the "trained model table"?
@typhoonzero I don't think we need to test multiple SQL in the unit test since we are using `mockRun`.
Why installing from a fork? Shall we merge the change to `models` repo first? I can help with the code review on `models` repo. :)
This is for testing the code, will move to develop
UI related YAMLs can be removed, as we don't need the UI for CI.
This file is not needed, right?
This file is already not needed, if we don't need kustomization.yaml
Not needed?
File not needed?
Need to double-check whether `kubeflow` namespace is needed, or we can just skip it and use default one.
Use a smaller value here.
These are already installed. No need to copy the same script here and run again.
This only applies the yaml but no result is being validated. 
ElasticDL -> katib 
Intuitively, considering the polling manner, I would suggest renaming `Fetch` to `Peek`.
Is it lack of  `Code  status  = 1; // (or 2)` ?
On parsing
```
SELECT *
FROM some_table
TO TRIAN ...
```

The Hive Parser gives error position as `line: 3, column: 0`. To make the error position at the character `T` of `TO`, we should add 1 to the column number.
Also update the comment above?
Posix seems to guarantee that writes with O_APPEND are atomic. The APUE book also describes the behavior in detail.  So we don't need a file lock here.
Sure, will do.
SQLFlow generates a workflow program. The workflow program will save the model. So the `TrainIR` should contain `Into`.
Also, need to update `runPredictIR` or do this in another PR?
`parse` and below `newParser().Parse(sql)` seems confusing, and the filename `parse.go` and `parser.go` also confusing, a better name is needed.
Thanks for your suggestion. I have renamed `newParser().Parse(sql)` to `newExtendedSyntaxParser().Parse(sql)`.
For the record, SQL syntax usually doesn't accept `/` or `:` being part of the identifier. Take MySQL for example, we can create table named `temp1`, but not `tem/p1` or `tem:p1`.

```SQL
mysql> create table temp1 (a integer);
Query OK, 0 rows affected (0.02 sec)

mysql> create table tem/p1 (a integer);
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '/p1 (a integer)' at line 1
mysql> create table tem:p1 (a integer);
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ':p1 (a integer)' at line 1
```

However, `repo/image:tag` is the native syntax in Docker, so I think it is worthwhile to make the naming consistent by using `repo/image:tag`.

https://github.com/sql-machine-learning/sqlflow/pull/1042/files#r337120122 also mentioned this issue.
Agree with keep the same naming with Docker image.
I don't think we need to expose the port 50051, since it is only needed **inside** the container.

```
  Host                                   Container

                       +-----------------------------------------------+
                       |                                               |
                       |                                               |
             Port 8888 |               localhost:50051                 |
Browser <---------------->  Jupyter <-----------------> SQLFlow server |
                       |                                               |
                       |                                               |
                       +-----------------------------------------------+
```


Also `SQLFLOW_DATASOURCE=...` should be the same line with `jupyter`, otherwise, the `jupyter` process can't read the value of `SQLFLOW_DATASOURCE`.
Note that the SQL statement may contain a single quote too, using `'echo "..."' may contain too many levels of quotes.
image="regressors:v0.2"
How to get the image name from t `sqllflow -parse`?
Where can we specify configurations like datasource and session?
I think SQLFlow server should calls the parser module to parse the input SQL program first:

`sqlflowserver->parser->IR(without verify/feature derivation)-> couler_codegen.go->couler program`
We can pass them as the environment variable of `couler.sqlflow.run("", env={"SQLFLOW_DATASOURCE":"mysql://(127.0.0.1:3306)..."})`, and these env would be passed into the Argo step.
 
Do you mean `sqllflow -parse` should output the JSON with a field `model_image`?
I am not sure if the JSON needs to be like SQLFlow TrainIR. Why not just a list of SQL statements?
I think IR structure contains `Estimator` field instead of `model_image`, we can parse the `model_image` in `codegen_couler.go`
I'm sure the JSON is `TrainID` which is the input of `sqlflow_submitter.xgboost.train`.
SQLFLow command-line compiles the SQL into IR, the submitter program submit the estimator. We don't need to export Feature derivation/verify to Python code.
As the discussion, `sqlflow -parse` outputs a protobuf text file.

Why changed to not using pipe?
`FeatureColumn` should be a map.
`message IR {`
`FeatureColumn` is different from `FieldMeta`. Should follow the struct in `intermediate_representation.go`.
```go
sqlProgram := sqlProgram[:i]
extendedSQLProgram = sqlProgram[i:]
```

If use `pyodps` but not `odpscmd` can we have a submitter program under `python/sqlflow_submitters` to make this template simpler?
Do we need the python2 ? If so, maybe we need to add some testcase on Python2.

Also update the testcase to fit this fix?
Shall we install the cmd line: `pai`?
I'm afraid we can't. `pyodps` cannot submit xflow tasks to our cluster. The reason is still under investigation.
`pai` don't have a standalone CLI tool.
Naming: This function is not submitting any job.
@shendiaomo @typhoonzero I am planning to add `pr.save` to `TrainIR` as `INTO` field in #1187. So `pr.save` can be removed from the function signature. [ref](https://github.com/sql-machine-learning/sqlflow/pull/1187#discussion_r346058473)
`cwd` is not used.
I see.
Great, that's where it should be.
Done.
Done.
This code duplication is temporary. An optimistic estimate is that we don't need to support python2 after several weeks.
Done.
@shendiaomo `test_maxcompute.sh` won't run if the PR is filed from a fork. Could you please file this PR from a branch of this repo?
Will this change affect the performance of `pkg/sql/codegen/tensorflow`?
Need to check the return code in case that the command fails.
Can this also be a function under `sqlflow_submitter`? Seems it's most python code.
maybe re write like: 

```go
type SubmitterType int
const (
    SubmitterPAI = iota
    SubmitterElasticDL
    SubmitterALPS
)
func submitter() SubmitterType {
    if envSubmitter == "pai" {
        return SubmitterPAI
    } else if ...
}
```
Maybe `inferByModel`  -> `getTrainIRFromModel`?
Can we check the TF version and determine the cache call? Cache to memory only works on very small datasets.
Argument `name` may need a better name.
Maybe add TODO comment that the prediction should also run on PAI?
Done.
Done.
Done. See https://travis-ci.com/sql-machine-learning/sqlflow/jobs/259314068
> Will this change affect the performance of `pkg/sql/codegen/tensorflow`?

No, as @typhoonzero  said, if a filename is not provided, the dataset will be cached in memory.
> Can we check the TF version and determine the cache call? Cache to memory only works on very small datasets.

Done.
Done.
The prediction does run on PAI. See `tfPredictTmplText`.
Reasonable idea! I'll refactor this later in subsequent development.
Done.
Hi @typhoonzero, I am assuming you are suggesting a better naming, which I don't agree.

Please be aware that the `sqlProgram` may contain multiple statements. For example, let's consider the following scenario.

```go
sqlProgram := "select ... to train ...; select ... to train ...;"

sqlProgram := sqlProgram[:i]         // "select ...", which is not a SQL program
extendedSQLProgram = sqlProgram[i:]  // "to train ...; select ... to train", which is not a extendedSQLProgram
```
Hmm but this is Maxcompute related though. What if ElasticDL supports MySQL and others in the future? Why would separating it better than it is now?
I am not sure why we need to `MarshalTextString/UnmarshText`, because we shouldn't test these two functions.

Can we have an exhaustive `a.Equal` between fields of `sampleTrainIR` and `pbIR`(not `pbIRToTest`)?
Can we make attribute type aware? Maybe add a message like
```proto
message Attribute {
  oneof attribute {
    int32 i =1;
    ...
  }
}
I am not sure how to do the direct import. Do we need to include `pkg/server/proto` during `protoc`? If so, is it more convenient to organize all the proto files in one directory?
Naming: `Pb` or `PB`? I feel `PB` is better since it is the acronym of Protocol Buffers.
The proto file needs more comments like `TrainIR` since it will be read by many developers.
I see. I'm approving this.
We are going to use the IR at the python side by deserializing the message, so maybe it's better to test the fields after deserializing it.
Sounds good, will update in next pull request.
You are probably right, I still need to check the details at https://developers.google.com/protocol-buffers/docs/proto#importing-definitions
I'll merge this first and do these polishments in another PR.
Default install Couler in the Docker image?
Good idea  and I will do that in the next PR.

In the case of `SELECT ...; SELECT * FROM my_table TO TRAIN ...`, `sqlProgram[:i]` is `SELECT ...; SELECT * FROM my_table`, while it should be `SELECT * FROM my_table`.
Lesson learned: always handle error value.
maybe also need to configure the k8s API endpoint address in the future?
will the "local mode" move to couler "docker mode"?
If you also update the pysqlflow, please refer to this PR in the pysqlflow PR.
Good point and I will add it when implementing the `Fetch` interface.

The `local mode` here is the current implementation. Will move to `docker mode` if the `docker mode` is ready in Couler.

Sure, there is a task in the TODO list #1066 
We can keep the name `TrainIR` because `TrainClause` do not have enough message that it is an `ir.TrainClause` struct.
redundant `r` at the beginning?
inconsistent indent
Thanks for finding this, I'll fix it in the next commit.
@typhoonzero What is the difference between TrainIR and TrainClause?

Do you mean here TrainIR means the parsing result of the SQL statement consisting of the SELECT statement and the TRAIN clause?
You can use https://www.tldp.org/LDP/abs/html/subshells.html and shorten this new line into 

```bash
(cd python/couler && python setup.py install)
```
Thanks. I've followed the comment.
`Session` is imported on line 5.
> @typhoonzero What is the difference between TrainIR and TrainClause?
> 
> Do you mean here TrainIR means the parsing result of the SQL statement consisting of the SELECT statement and the TRAIN clause?

I mean the object name `TrainClause` we actually don't know it's a struct or a `TO TRAIN ...` string, when we use the object name `TrainClause`, the type `ir.TrainClause` can tell it's an IR struct. But the name `TrainIR` can tell it's an IR struct.

We can compare the below two lines of code, and pick up a better naming though:

```go
trainIR := &ir.TrainClause{...}
trainClause := &ir.TrainClause{...}
irTrainClause := &ir.TrainClause{...}
```


Seems using subqueries here will cause error: https://travis-ci.com/sql-machine-learning/sqlflow/jobs/260837168, I'll change it back to the regex way for a fast fix. Remove the `LIMIT 10` from train SQL, it works well.

Running the subquery SQL using hive command line also works. Need to find out a solution.
> > @typhoonzero What is the difference between TrainIR and TrainClause?
> > Do you mean here TrainIR means the parsing result of the SQL statement consisting of the SELECT statement and the TRAIN clause?
> 
> I mean the object name `TrainClause` we actually don't know it's a struct or a `TO TRAIN ...` string, when we use the object name `TrainClause`, the type `ir.TrainClause` can tell it's an IR struct. But the name `TrainIR` can tell it's an IR struct.
> 
> We can compare the below two lines of code, and pick up a better naming though:
> 
> ```go
> trainIR := &ir.TrainClause{...}
> trainClause := &ir.TrainClause{...}
> irTrainClause := &ir.TrainClause{...}
> ```

The naming convention that prefix/suffix a variable name with its type such as `irTrainClause` is known as Systems Hungarian, which is not recommended nowadays because the type prefix/suffix doesn't provide more information. See https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/ for details and https://stackoverflow.com/questions/111933/why-shouldnt-i-use-hungarian-notation for short. In this perspective, `TrainIR` is not better than `TrainClause`.
Maybe `ModelBuildingContext` is more informative because the member is actually representing the original model building code.
Also cc @Yancey1989 @weiguoz @tonyyang-svail 
Agree that not using "Systems Hungarian". Yet comparing `TrainIR` and `TrainClause`, as mentioned by @wangkuiyi  above, we call the `ir.TrainClause` an "Intermediate Representation" for now, and it consists of `Datasource`, `Select` and `ValidationSelect` etc, which apparently not the part of `TrainClause`, so I'd prefer `TrainIR`.

Yet if we change the naming `IR` to some other names like `TrainContext`, then the name should be `trainCxt` as an example.

By the way, the naming `ir.TrainClause` seems not describing what it is since it contains `Datasource` and so on, it really should be changed to `ir.TrainContext` or `ir.TrainSpec`, @shendiaomo what's your suggestion? 

I prefer `ir.TrainContext` in these two names because `TrainSpec` reminds people of `tf.estimator.TrainSpec` while they are very different.
We can execute a program, execute(interpret) the intermediate representation, but not execute a submitter.
> We can execute a program, execute(interpret) the intermediate representation, but not execute a submitter.

Execute is an intransitive and transitive verb.
Transitive verb example:
> A system that executes a program is called an interpreter of the program. ✅

Intransitive verb example:
> Very few programs execute on a bare machine.✅

Both the examples are quoted from https://en.wikipedia.org/wiki/Execution_(computing)
So we can say _The intermediate representation executes **on** a submitter_.
Style guide: "Try to keep the normal code path at a minimal indentation, and indent the error handling, dealing with it first. This improves the readability of the code by permitting visually scanning the normal path quickly." https://github.com/golang/go/wiki/CodeReviewComments#indent-error-flow

So maybe rewrite this function to following in the next PR. This comment also applies to other places in this PR.
```go
func (s *defaultSubmitter) ExecuteTrain(cl *ir.TrainClause) (e error) {
	var code string
	if isXGBoostModel(cl.Estimator) {
		if code, e = xgboost.Train(cl); e != nil {
			return e
		}
	} else {
		if code, e = tensorflow.Train(cl); e != nil {
			return e
		}
	}
	
	if e = s.runCommand(code); e != nil {
		return e
	}
	
	return s.SaveModel(cl)
}
```

I haven't seen `if e == nil` much in Go project, so please avoid it as much as possible.
> So we can say The intermediate representation executes on a submitter.

@typhoonzero @shendiaomo How about changing `sqlIR.Execute(submitter())` to `sqlIR.ExecuteOn(submitter())`.
I agree that we need to change the `TrainClause` since it contains more information than a clause. This struct is originally named `TrainIR`, and since it belongs to `package ir`, so why not simply named it `Train`, so we have `trainIR := & ir.Train{...}`.
I vote for `trainIR := & ir.Train{...}`.
I'll fix this later in another commit.
Please rename `sqlProgram` to `sql` since IR generation doesn't work on multiple statements due to 

https://github.com/sql-machine-learning/sqlflow/blob/91d94030ffe9f62d8f9af8648d39d25a9737c4d1/pkg/sql/executor_ir.go#L142-L149
If we have renamed `sqlProgram` to `sql`, maybe change calling `parse` to calling `parseOneStatemeent`.
can use k8s API here?
Sure, will import k8s package when implement `Fetch` gRPC interface, and I will rewrite here to use k8s API.

Maybe we need to update this implement to #1272.
Maybe add env as the session at here.
You're right, will add it in the next PR.

Can we use the messages from `proto/intermediate_representation.proto` to replace the original structs in the `sql/ir/ir.go`? In that case, we don't need to maintain these conversion functions.
Can we make this `bufSize` configurable? If my memory serves me right, the `string` type in MaxCompute has a much bigger size than 64KB.
Is it possible to unify `sqlfs` with `modelURI`? For example, can we make `sqlfs://database_name/table_name` behave the same as `table_name`? This seems to improve consistency.
Better to keep it constant for better saved model migrations.
`oss://` and `file://` are well know URI prefixes. We do not intend to invent a new one.
Protobuf IR struct is harder to use because the `oneof` type will construct many layers to call, but Go's `interface{}` is simpler to use in codegens.
LGTM. Let's keep the status quo until we find a better way.
`attribute.go` is not engine specific and these attributes seems only used in Tensorflow.
What's "copyint"?
`estimator` is Tensorflow specific, and we should not add engine specific code in `attribute.go`
I think this is kind of temporary. The `optimizer` argument in Tensorflow Estimators can be a string as well as an `Optimizer` object, we need also pass things like `learning_rate`, `learning_rate_decay` etc. to construct the optimizer object.

Seems it's better to use a struct:

```
type Optimizer struct {
    Name string
    params map[string]interface{}
}
```
To store the construction details of the optimizer object. If `params` is empty, then pass the optimizer name as string to the Estimator, else construct an object and pass it to Estimator.

And, it's useful to update `python/sqlflow_submitters/tensorflow/train.py` to have an argument `optimizer` to accept it.
For reference: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers
Done.
`estimator` is not TensorFlow specific, sklearn proposed the original concept and it is widely accepted by the AI community, XGBoost implemented the `estimator` interface too.
For another example, we also have `ir.TrainClause.Estimator` with the same meaning as the `estimator` here.
> I think this is kind of temporary. The `optimizer` argument in Tensorflow Estimators can be a string as well as an `Optimizer` object, we need also pass things like `learning_rate`, `learning_rate_decay` etc. to construct the optimizer object.
> 
> Seems it's better to use a struct:
> 
> ```
> type Optimizer struct {
>     Name string
>     params map[string]interface{}
> }
> ```
> 
> To store the construction details of the optimizer object. If `params` is empty, then pass the optimizer name as string to the Estimator, else construct an object and pass it to Estimator.
> 
> And, it's useful to update `python/sqlflow_submitters/tensorflow/train.py` to have an argument `optimizer` to accept it.

Yes, this is a transitional plan. To allow constructing an `Optimizer` in SQL statement requires a more comprehensive design on which I'm still working.
They are used both in TensorFlow and PAI TensorFlow, that's why I put them here. Though `codegen/pai` shares part of `codegen/tensorflow` at the moment, they may diverge someday.
> To allow constructing an Optimizer in SQL statement requires a more comprehensive design on which I'm still working.

Maybe something like the following?

```
WITH
    optimizer.name = "adam"
    optimizer.param.lr = 0.1
```
Let's refine this pull request to only restrict the TensorFlow model attributes. Another pull request about optimizer will be issued later.
Did you ran `go get ./...` before commiting? we are using gomod now, and `go get` will try to update all dependencies.
I ran `go test ./...` which I thought is the reason for this.
This section is empty
It's a level 2 heading that contains a couple of level 3 headings.
I fixed the comment by git push directly.
`file://` or `file:///`?
~~`fmt.Println`~~
Maybe add a test examing the `isInsert` logic.
Do we need timestamp fields, like `createdAt`, `updatedAt`?
By timestamp, we can eliminate the overdue data.
The prefix is `file://` and the path is `/path/to/model/dir` started by `/`.
`CaseTrainFeatureDerevation` has two train SQL which have the same `INTO` clause, this is testing this if branch. Adding comments in that test case.
Sounds good, will add in next commit.
What's the '\n' for?
Can we put this code snippet as a separate function `func LogFeatureDerivationResult(wr *PipeWriter, trainIR *ir.TrainClause) error` and call this function at 

https://github.com/sql-machine-learning/sqlflow/blob/a5986ba188feea1081627f32d17383b499f66d35/pkg/sql/submitter.go#L131-L142

so that
1. We can avoid changing `InferFeatureColumns(trainIR)` to `InferFeatureColumns(wr, trainIR)`.
1. We can reuse this function for our debugging due to `w := io.MultiWriter(cw, &output)`.
To separate feature derivation logs and training logs.
Good point, yet it's better to put it in runSingleSQLIR, where trainIR can be easily got.
We'd better keep this check somewhere to avoid printing error message twice when logging to stderr.
How about `defer`ing with the new `Close` code in a lambda?
Maybe we can use `log.Fatalf` to exit if some errors.

I believe should check the error of `hiveWriter.Close`, I updated this PR follow https://www.joeshaw.org/dont-defer-close-on-writable-files/ that uses a safe way to close sqlfs.
 
`log.Fatalf` will terminate the program, that's no good for the interactive mode of REPL.
Is it safe if we call `hiveWriter.Close` twice?
Int => in
~~`// if wr is not nil, then write`~~
ds -> `datasource`?
Good idea, will polish it in the next PR.

maybe don't need to create a bucket every time.
It's ok because what `create_bucket` do is indeed `create_if_not_exist`
I would suggest not to name source dirs or files by 'util'; a more precise name is often preferred.  How about renaming this file to be `oss_temporary.py`?
Use `%[1]s` instead of `%s`?  So we need only pass  `caseDB` once in `main_test.go`
I meant to provide some other functions in this file, anyway, I'll come up with a better name.
The meaning of `createByType` is not clear.
3x for pointing out this, I'll come up with a better name later.
Thank you for pointing this out!

I tried to understand the change by reading https://godoc.org/github.com/golang/protobuf/ptypes/timestamp#Timestamp.GetSeconds and saw the example code:

```
Timestamp timestamp;
timestamp.set_seconds(time(NULL));
timestamp.set_nanos(0);
```

Where the POSIX call `time` returns the UNIX seconds.
Not sure when using `katib` or `auto` here..
Need to tell detailed difference between container and job here
Need to add a para to tell what a Katib job, the inputs, the outputs, and what the job can do.
Also we need a story for the default range, and users may not be required to add a range for each parameter.
So `run_katib` is a function defined in couler?
One way could be:
```xgboost.py

def train(....):
    # Submit a XGBoost training job based on the input parameters

def auto(...):
    # Submit a Katib job which tune the XGBoost models
```

In such a way, users can use `xgboost.train()` or `xgboost.auto()`...
Please be aware that according to the [model zoo design](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/model_zoo.md#background), the model names a class in a Docker image and is in the form of `a_data_scientist/regressors:v0.2/MyDNNRegressor`.
Also, it is `TO TRAIN` instead of `TRAIN`.
What does the prefix `multi:` mean?
What does `validate_select` mean? Do you mean `validation_dataset`?
couler => Couler

In quite many other places, we need the same renaming.
I am confused about this part, since SQLflow query -> couler.run_container will not able to generate a couler.run_katib. However, the code gen logic of Sqlflow would able to generate a step like couler.run_katib on the run time. it means that pod of Argo would generate other workflow with couler.run_katib.  
creating Katib job for XGBoost training in SQLFlow 
Maybe auto is better than katib.
`multi:softmax` is a value for the objective, which sets XGBoost to do multiclass classification using the softmax objective. 
We can use `run_container` to run a container and within this container to create a katib job. However, in this case, the katib job is not a step of Argo and not managed by Argo. 

Sorry, but what is CaseTrainSQL?
1. Use a raw string to get rid of escaping?
1. Use `\s*` in case there is more than one whitespace, and I think we may need a multiline setting to make the following work on this.
    ```sql
    select * from 
        iris.trainable ...
    ```
3. May the table name capitalized? If so, we'd better use `[\w\.]` instead of `[a-z0-9_\\.]`
updated the comment to:

```
// caseInto is used by function CaseTrainSQL in this file. When
// testing with MaxCompute, the project is pre-created, we only need to
// specify the table name in that case.
```
Can't we utilize the third party SQL parser to support complex SQL queries here?
No. Queries with subqueries will not write the result to a table, the result is produced in memory.
`s/Tigger/Trigger` and `s/Tunning/Tuning`? 
It seems this `temp` is unnecessary.
Oh. I mean to export the table temp to be a file on HDFS named temp. So, I think we need both "temp", am I right?
Could we export the table `c` to the HDFS file？It seems `temp` is identical to `c`?
I'm not sure, but if my memory serves me, the golang `regexp` requires a `(?m)` prefix to enable the multiline mode, in that case, `\s` will match `\n` automatically. Can we add a test case for the multiline case?
Already tested on http://regex-golang.appspot.com/
Sorry this is cause by previous commit: https://github.com/sql-machine-learning/sqlflow/pull/1281/files#diff-f1bebf56ba6d498c6b1d0a104ead3e62R117
`a.NoError(err)`?
If `ModelImage` in IR is not empty string, then use `ModelImage` else use `defaultDockerImage`
Sometimes, if `datasource` is an empty string, this error message is not showing the actual datasource, a little confusing.
Can write `fmt.Errorf(...)` then the client will raise the error.
Testing MySQL requires starting a MySQL server inside a Pod. Maybe we should use MaxCompute as data source instead.
using MySQL can check each PR that comes from forked PR, maybe it can cover more test case.


maybe printing  the logs is helpful to debug
maybe `SQLFLOW_TEST=workflow` use the same pattern as above tests?
We can not use the `ModelImage` field directly. For example:

``` sql
SELECT ... TO TRAIN ... INTO mymodel;
SELECT ... TO PREDICT ... USING mymodel;
```

the PREDICT SQL image field is empty because the training job has not started.  A better way is to analyze the dependency graph between TRAIN statements and PREDICT statements in a SQL program. I will create a design doc to introduce that in the future and then we can make some discussion.
  
Can you show more details about the khatib train step, such as:
1. where does the model_def come from in SQLFlow?
1. In this example, `hyperparameters ` is empty, what and how does this argument to use in SQLFlow?
1. Do we need `couler.katib.predict` ?
I realize there are potential problems to allow programmers to use their own image in katib tuning job.
1. The collector in Katib requires the job container's output to follow a certain format, like `accuracy = 0.97`. And users need to tell Katib to collect data for `accuracy` in katib job yaml.
2. Katib does not obtain the tuned model. When one pod finishes tuning, it needs to write the tuned model to a store, e.g., odps, then the following pred can make use of it.

I think it requires too much on programmers in their own image. Maybe sqlflow invokes submitters to train model when programmers specify the image; otherwise, sqlflow uses katib. 
Sure.

1.1 As @wangkuiyi suggested, programmers need not specify to use katib explicitly. Instead, sqlflow will check if programmers have input all necessary model parameters. If it is, sqlflow invokes submitter to train model (e.g., xgboost submiitter); otherwise, sqlflow uses katib via couler.
1.2  As the xgboost example above, the model_def can be something like `xgboost:gbtree`.
2. `hyperparameters={"booster": "gbtree",  "objective": "multi:softmax", "eta": 1.0, "max_round": [20, 100], "max_depth: []" }`.
3. No. Katib is only used for model tuning.
For less probability of name conflicting, I assume we'd change `FLAG` to a longer and more precise name like `SQLFLOW_TEST_FAST_FAIL_INTERACTIVE_OR_NOT`.
> Issue #1338 is about SQLFlow doesn't present a friendly error message when DB connection fails. I don't understand why we could fix this issue by adding a unit test?

The bug in #1338 occurs since the original `repl.go` doesn't check the connectability of DB before entering the interactive mode. The fix is actually the new  function `assertConnectable` in `repl.go`. and the call to it in the function `main` 
> For less probability of name conflicting, I assume we'd change `FLAG` to a longer and more precise name like `SQLFLOW_TEST_FAST_FAIL_INTERACTIVE_OR_NOT`.

Done.
"INTO temp" means saving the output from the SELECT operation into a new table named temp.
Can use `t.Skip()` instead of `return` so that other developers can know to skip this test case clearly.

Do you want to rewrite the `Create` function in `writer.go` using `SQLWriter` and `HiveWriter`? If so, may be we can move `dropTable` and `createTable` in the `Create` function.

``` golang
func Create(db *sql.DB, driver, table string, session *pb.Session) (io.WriteCloser, error) {
    if e := dropTable(db, table); e != nil {...}
    if e := createTable(db, driver, table);  e != nil {...}
    if driver == "hive" {
        return newHiveWriter(...)
    }
    return newSQLWriter(...)
}
```
`kubectl logs` would fetch all the logs, please add a TODO comment here to implement fetch logs by an incremental way.

Duplicated with `workflow.go`#getWorkflowID ?
can we use https://github.com/kubernetes/client-go instead of calling the command line?
What is the advantage of using the `client-go`? I am not sure if the `client-go` supports parsing the Argo workflow descriptions, so I may need to spend some time to test it out.
Yes, I will move workflow related code to `package workflow` in the next PR.
Sure, I will add this in the next PR.
I created an issue: https://github.com/sql-machine-learning/sqlflow/issues/1362 to discuss go-client or kubectl, maybe we can move to make some disccusion.

What does the `-q` option mean?
I agree. I think we will need to rewrite Create, maybe after we merge HiveWriter.
Thanks for the remind! Will update in successive PRs.
Can we directly use struct `Workflow` in https://github.com/argoproj/argo/blob/master/pkg/apis/workflow/v1alpha1/workflow_types.go ?
Absolutely! Thanks for pointing it out.
Just a mention, the `argo` package  is ** incompatible** since there is no `go.mod` file in it, we should fill the dependency such as `k8s.io/go-client` in manual. 
Good catch. I am doing that right now. Also, I've filed an issue in the Argo repo to see if they are planning to move to `go.mod`.
Why 900s?
Add a TODO comment here?
Maybe we need to enhancement the user guide also.

`docgen` currently only generate XGBoost documents, will do that in a single PR.
The Argo team is planning on migrating to `go.mod`, but it won't happen in the short term. So for now, I would suggest using `kubectl` to fetch logs directly. [ref](https://github.com/argoproj/argo/issues/1826)
It seems that we can not specify `namespace` here, it's not the workflow namespace but Pod template namespace. 

We can add the `namespace` field in the `kubectl` configuration file as the default namespace.

Please take a look at: https://github.com/sql-machine-learning/sqlflow/pull/1385? we can have more levels to show more detailed logs.
I am afraid that SQLFlow will not accept `xgboost:gbtree`. The current plan is to go with the model zoo design doc, which says what's following `TO TRAIN` is a Docker image name, a `/`, and a model name.

If we need to redefine the syntax, please justify the reason to make it accept `xgboost:gbtree`.
Could you please explain why we would not export data?
I am not sure if we need a `couler_katib_codegen.go`. What do you think? Can you add more details?  Should we have just a `couler_codegen.go`?  Or, what would be the difference between `couler_katib_codegen.go` and `couler_codegen.go` in your mind? The team would love to listen more about the connection between SQLFlow and Katib.
I got your point. Thanks. But I think it should be `PYTHONPATH=/sqlflow/python` in the Docker container. Am I correct?
Also, it should be `-p 1` instead of `-q 1`.
> Also, it should be `-p 1` instead of `-q 1`.

3x && Updated
This PR only intends to change a Markdown file. I am wondering why `go.sum` is also changing.
Should be `PYTHONPATH=$GOPATH/src/sqlflow.org/sqlflow/python`, see `test_units.sh`
Good idea! I'll issue another pull request to improve.
I think in the model zoo design, we plan to make `TO TRAIN` followed by a Docker image name + '/' + model name.  I don't remember that we could have `.` in the name.  Is there something we should update the format of the name? If so, let's update the model zoo design.
Need to drop and create a table here:
https://github.com/sql-machine-learning/sqlflow/blob/5bf232b52f02f8bfc72862044dc699a51ad6a94c/pkg/sqlfs/table.go#L24-L32
I have re-thought this part and it should be better to follow model zoo design. I will update the example in the next commit.
The problem is how to pass the data to pods in Kubernetes. Initially, my design is to put data into a local file and put this file into the storage of Kubernetes, e.g., NFS. Then each pod can read data from this storage. However, I realize we can not simply assume Kubernetes cluster definitely provides those storage facilities. The safe way is to make each pod read data from data source directly. This way may introduce potential performance problems, but I am thinking to improve it later.  
When to fill katib manifest in Argo workflow, we need some information from the input sql statements, for example, tuning hyperparameters. @Yancey1989 suggested having a separate codegen for katib.
We can have `.` already now, because https://github.com/sql-machine-learning/sqlflow/blob/develop/pkg/sql/lexer.go#L103 the `IsNumber` can accept `.`
just `return getWorkflowID(string(output))`
Maybe can use the env `SQLFLOW_WORKFLOW_STEP_IMAGE` here which been configurated in 
https://github.com/sql-machine-learning/sqlflow/blob/9d64323bef36fc3bc87c5f51f94917f5c2322ce0/.travis.yml#L67
This is not work in the current PR? Maybe we need to add `SQLFLOW_submitter=pai` in the `travis.yaml`
`SQLFLOW_submitter=pai` tests now can only run in the internal environment
Good point.
Do we really need the `SKIPPED` phase, I don't know what does the client do for the skipped phase.

According to the Argo source code, the client should consider SKIPPED as the completion phase. I suspect skip is only used for nodes (for example the skipped if branch), never for the workflow. But I feel it is safer to follow the Argo source.

https://github.com/argoproj/argo/blob/99db30d67b42cbd9c7fa35bbdd35a57040c2f222/pkg/apis/workflow/v1alpha1/workflow_types.go#L841-L846
To make debugging easier later on, please return an error on parsing failure.
Maybe change to `bash -c 'for i in {0..100}; do   echo $i;   sleep 0.0$((RANDOM % 100)); done'` for more intensive testing.
Good point, I have tested it on my laptop and it passed, will do that in the next PR.

Please switch order: `a.Equal(expected, actual)`
Can we use generated names so that this YAML can be used by multiple tests in parallel?
Do we need to wait 1 second here?
Maybe we can set the default docker image by: `${SQLFLOW_WORKFLOW_STEP_IMAGE:-sqlflow/sqlflow}` .
Let us don't mix shortened words, like `opt`, with non-shortened words, like semicolon, in naming.

Also, by the purpose, it seems that `opt_semicolon` should have the name `end_of_statement`, or `eos`?
Oops! Go doesn't allow me to do this shortening. 

```
pkg/sql/column_type.go:73:10: invalid indirect of v (type interface {})
```
Add `defer removeHDFSDir(w.hdfsPath(), hdfsEnv)` at L67 to fix #1345 , maybe we can mrege this PR and I can do that in the next PR.

else return some optimizer format error?
may be use piece[1] as the key, e.g. `model.optimizer.learning_rate` -> `optimizer`, but not `model.optimizer`?
That's my original idea that's attractive. I hesitated for a long time before I choose the current naming. Let's discuss it with the others. @tonyyang-svail @Yancey1989 


That's not necessary. If the attribute is not an optimizer, it will stay untouched thus raise an error in `initializeAttributes`.
remove debug code?
Seems this PR only keeps one label column that specified in the predict SQL?
Yes, always using `predict result column` as the prediction result column name.

Cool!
`TrainStmt. ExtendedSQL` seems confusing. Can direct implement `GetOriginalSQL` and `IsExtended` for each `TrainStmt`, `PredictStmt` and `AnalyzeStmt`
> `TrainStmt. ExtendedSQL` seems confusing. 

Structure embedding in Go has similar semantics as private inheritance in C++: they both disguise composition as inheritance. So we never need to write `TrainStmt.ExtendedSQL` or `TrainStmt::ExtendedSQL` explicitly. Struct embedding is good for extracting common fields/methods of several similar structs into a single struct.


> Can direct implement `GetOriginalSQL` and `IsExtended` for each `TrainStmt`, `PredictStmt` and `AnalyzeStmt`

I don't think code duplication is a good idea, maybe it's the naming of `ExtendedSQL` that causes the discomfort, how about renaming it as `ExtendedSQLBase`?  i.e. We have one `StandardSQL` and three `ExtendedSQL`s, the latter share implementation from `ExtendedSQLBase`.
The `ExtendedSQL` represent IR, do you want to rename `ExtendedSQL ` to `ExtendedStatment`
Get the latest pod status can fix the random failed.

This quick fix is off the topic of this PR. I have to add it because I need it to fix the failure of the unit test. Without this fix, when I run `go test -v ./...`, the call to `getEnv` returns "hive" as the default value, which then triggers the run of `TestNewHiveWriter` even if there is no Hive Server setup, and the unit test fails.
Hi @wangkuiyi , the Katib Couler step needs hyperparameter searching range as the argument, for an example XGBoost training SQL:

``` sql
SELECT ... TO TRAIN ... WITH max_depth=[2, 10]...
```

`couler_codegen.go` convert this SQL statement into couler step function code as: 

``` python
couler.katib.train(hyperparameters={"max_depth":[2, 10]}, ...)
```

`codegen/couler/codegen.go` can call `codegen/couler/katib.go` to generate the Katib Couler step function code.

Hi @samplise , I think fetching training data in each Katib step is a more general way, and it can resue [db_generator](https://github.com/sql-machine-learning/sqlflow/blob/develop/python/sqlflow_submitter/db.py#L133) to generate `(features, label)` and feed the XGBoost training.

A viable approach is:
1. refine the `katib.train` arguments to
    ``` python
    couler.katib.train(
        hyperparameters={"max_depth":[2, 10]} // Katib hyperparameters searching range
        extended_sql="SELECT ... TO TRAIN ..."
    ```
1. Each Katib step accpets the extended SQLFlow SQL and convert to IR to feed `sqlflow_submitter.xgboost` to launch training job, ref: https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/couler_sqlflow.md#couler-step-function
    ```
    entrypoing='''
        echo "SELECT ... TO TRAIN xgboost.booster" |
        sqlflow -parse |
        python -m sqlflow_submitter.xgboost.train
   '''
   ```


Good catch.
Here are some indentation issues. I am wondering why the `go fmt` in CI doesn't catch it.
Good catch!  This is not a .go file, but a .y file. I will re-indent manually after I fix the CI failure.
The same with `Meta +Del` ?
Yes, `Meta + Del` and `Ctrl + w` has the same behavior.
Maybe we need a strict check to make sure the `trainSelect` should be `SELECT * FROM tmp_table TO TRAIN...`, the standard sql statement should not contain any `WHERE/LIMIT/...`.
Is this a TODO comment?
How about renaming these variables with an `odps` prefix or without any prefix? After all, we are in the `pai` package,a `pai` prefix is redundant.
ditto. 
IMO `database = parseMaxComputeDSN(dsn)[-1]` is more pythonic.
Will fix this in next PR
removed.
Is it a token or an ID?
How to define "most recent logs"?

Suppose there are two successive calls to  `Fetch`.  The first call returns logs generated during the period from the starting of the workflow to moment A. How could we implement `Fetch` to make sure that the second call to it returns logs generated after moment A?  Does the SQLFlow server need to keep track of moment A for each workflow ID?  If so, the SQLFlow server keeps workflow status, which is exactly what we DON'T want and is the reason we introduce Argo, an execution engine to run workflows.
How about link to https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/high_available_sqlflow_server.md or restruct these two design docs?
The `Token` contains `ID` and fetch status such as `logOffset` and `stepId`:

https://github.com/sql-machine-learning/sqlflow/blob/36066f128f99acc23e47f6fb93e9d5a6081fad5e/pkg/proto/sqlflow.proto#L52-L58
Move `usage` content to Motivation.

Add some details about `updateToken`

> The `Token` contains `ID` and fetch status such as `logOffset` and `stepId`:
> 
> https://github.com/sql-machine-learning/sqlflow/blob/36066f128f99acc23e47f6fb93e9d5a6081fad5e/pkg/proto/sqlflow.proto#L52-L58

Avoiding too many logs in the response, do we need an `expect_length` to restrict the log size?
Indent error?
indentation.
indentation.
Maybe add more tests on statements like
1. Missing WITH clause `select ... to train dnn label class ...`
1. Missing semicolon in the with clause `select ... to train dnn with a = b c = d...`.
1. Addition semicolon in the with clause `select ... to train dnn with a = b, c=d, column ...`

Users often make these mistakes. And the error message from the parser can be really helpful.

Yes. Go fmt doesn't handle .y files. I will fire another PR with tools that can auto-indent .y files.
[Kubernetes Logs API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#read-log) supports the `sinceTime` parameter to fetch logs from the specified timestamp,  the client side keeps`FetchToken` object which uses this `timestamp` as `logOffset` to fetch logs in an incremental way, https://github.com/sql-machine-learning/sqlflow/issues/1382 is the more detailed survey. 
I will do that after polish this design doc.

It's a good point, [Kubernetes Logs API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#read-log) supports `limit-bytes` parameter to limit each request logs bytes, we can do this enhancement in the `Fetch` implement.
Should we add type check for these two new attributes?
Otherwise, a `num_ps="ten"` may break the program here.
It seems we can call `pickle.dump` instead of `pickle.dumps` here, such as 
```python
pickle.dump(list(meta), gfile.GFile(oss_path, mode='w'))
```
Also,  calling `pickle.load` instead of `pickle.loads` may simplify code here:
```python
return pickle.load(gfile.GFile(oss_path, mode='r'))
```

Add a comment to this function to explain why we need it?
It seems PAI will fill these flags automatically, how about adding a comment for this behavior?
Can call `sql.SplitDataSource`: 

https://github.com/sql-machine-learning/sqlflow/blob/6344075f4edc0bfb9f413e6c87f67483c47274cb/pkg/sql/database.go#L67-L76
I saw `codegen.go#122` to make the default value of `NumPS`  is `0`, do we need the `NumPS` here?
How about move the PAI code to `pai.py`? The current `tensorflow/train.py` includes `Kerase`, `Estimator` and `PAI` code, it's too hard to read ...

`# ----------------- For PAI distributed training -----------------` is just it.
`# ----------------- For PAI distributed training -----------------` is just it.
`numWorkers > 1` is what we need to determine whether this is a distributed job
Will try to polish later
importing `pkg/sql` will cause:
```
import cycle not allowed
package sqlflow.org/sqlflow/cmd/sqlflowserver
	imports sqlflow.org/sqlflow/pkg/server
	imports sqlflow.org/sqlflow/pkg/sql
	imports sqlflow.org/sqlflow/pkg/sql/codegen/pai
	imports sqlflow.org/sqlflow/pkg/sql
```

so just keep it here.
We are not using `namenode_addr` currently because, in some deployment, the HDFS client needs to be configured to connected to multiple namenodes so that this deployment is Highly Available.
Maybe if namenode_addr is set (not empty string), then add `-fs` else, the command keeps `"hdfs dfs -mkdir -p %s/%s/"` to support both multi namenode setup and single namenode setup.
The above training statement usually takes a few minutes to run, and the outputs look like the following:

```python
{'accuracy': 0.4, 'average_loss': 1.0920922, 'loss': 1.0920922, 'global_step': 1100}
```
The average loss doesn't look very good; an idea value should about .....  Let us see what we can do to improve model quality.
_performance improvement plan_ => trial
Tuning usually takes a large fraction of the working hours of data scientists.  The SQLFlow team has a plan to introduce auto hyperparameter tuning in the near future.
Done.
Done.
Done.
why call it `new_request`
I prefer the word EOF here
`finish_fetching` should be under `FetchResponse` but not in `Request`? We do not need to send `finish_fetching` to the server I think
You're right, move `finish_fetching` to `FetchResponse`.

The client-side should keep the `FetchRequest` which contains the fetch status and refresh it after each `Fetch` gRPC request.

I see @typhoonzero 's point. How about we rename FetchRequest into FetchSince, and rename FetchResponse.new_request into FetchResponse.updated_fetch_since? @Yancey1989 
From https://github.com/sql-machine-learning/sqlflow/pull/1488/files#diff-b03e31960a96575596cdfc09b491fefaR25, it seems that function `newFetchRequest` has 3 parameters.  However, in the pseudo-code here, it has only one.  How to set the rest two?


The rest two would be the empty string, maybe the following code is clearer:

``` go
req := &FetchRequest {
  Job: &pb.Job{
    Id: wfJob,
   },
}
```
@typhoonzero I don't understand why we need to use `self.next_feature` to access features. Please be aware that TF launches `_create_generator` in a separate thread, while `self.next_feature` introduces a sharing state, which is error-prone.
@typhoonzero I don't understand why we need the `while loop`. I guess is that `len(feature_batch) == 2` BUG below led the implementer add it.
@typhoonzero BUG: the name `feature_batch` is misleading. It actually is a `(feature, label)` tuple with the batch size is always 1. However, `len(feature_batch) == 2`, and we shouldn't assign it to `self.batch_size`.
How about

```go
case string:
    if isBased64EncodedImage(s) {
        if isTerminal {
            imageCat(s)
        } else {
            renderImage(s)
        }
    }
```

I am not quite sure what content could a string-typed rsp could ever hold. It seems from your code that it could be a URL to an image, the image itself, or logs and other string-typed raw data.  Anyway, my above example was to illusrate that we could decomose the logic in imageCat so to make the code more comprehensive.
I noticed that the function `imageCat` actually does `catIfItIsImage`.  It would easier to understand if we decompose it into multiple functions:

```go
func isBase64EncodedImage(s string) bool
```

and

```go
func imageCat(image string) error // imageCat to iTerm2
```

and

```go
func renderImage(image string) error // render image in HTML
```
Ignoring `err` would cause an inefficient assignment warning and is not a good idea. 

Go function often returns an error-typed value.  A boolean value could be derived from the error value, like https://golang.org/pkg/os/#IsExist.

An alternative is to return an error in addition to the boolean value.
Just FYI, Go has a type `sync.Once`.  If `it2Check` is optionally needed, `sync.Once` is a better choice. But here, we need `it2Check` anyway, so I agree with your choice here.
It seems that we can call https://godoc.org/github.com/mattn/go-sixel#Decoder instead of running a sub-process. Otherwise, we'd have to require our users to install gosr.

I tried the following program works. If we build it into `./imgcat`, we can run `cat a.png | ./imgcat` in iTerm2 to display the image a.png.

```go
package main

import (
	"image"
	_ "image/gif"
	_ "image/jpeg"
	_ "image/png"
	"log"
	"os"

	"github.com/mattn/go-sixel"
)

func main() {
	img, _, err := image.Decode(os.Stdin)
	if err != nil {
		log.Fatalf("Cannot decode image from stdin: %v", err)
	}

	err = sixel.NewEncoder(os.Stdout).Encode(img)
	if err != nil {
		log.Fatalf("Cannot encode image into sixel format: %v", err)
	}
}
```
May I know what format image is? Is it PNG or sixel? Who is supposed to encode the image? SQLFlow server?
I am afraid that users cannot run iTerm2 from without a Docker container? If I am correct, iTerm2 users would have to download the it2check script on their mac computers manually?  If so, how about we include the script it2check as a string constant of repl, and call `os/exec.Cmd` to run the script?
Roger that.  `rsp` can be other things than an image, e.g.  an "OK" or "%d rows affected". 
That's a reasonable idea. 👍👍

The original logic of REPL is writing the string to stdout no matter what it is. In fact, the string is written to the [`pipe.wrCh`](https://github.com/sql-machine-learning/sqlflow/blob/e770a5ebbaaa45d346537abe4a75bab3b553e96e/pkg/sql/pipe.go#L26):
```golang
type pipe struct {
	wrCh chan interface{}
	done chan struct{}
}
```
by [`defaultSubmitter.ExecuteAnalye`](https://github.com/sql-machine-learning/sqlflow/blob/c1dce61cf97611abc63d8ca0687c744b20ae2fa8/pkg/sql/submitter.go#L200). The string is an HTML code snippet to be shown in the jupyter notebook. This pull request add a prefix `data:text/html` to make the HTML code a legal [data URL](https://en.wikipedia.org/wiki/Data_URI_scheme) to be able to be opened in a web browser to cover  non-iTerm2 terminals.

So IMO `renderImage` is not a good name because the function doesn't render anything.  How about naming it as `printDataUrl` if we supported other HTML in the future?

Later we can refactor submitters to return a specific type for images.
Rodge that.
It's a `png` to be shown on a  jupyter notebook.
1. A user can use iTerm2 to start the Docker container and run REPL in the container, so she doesn't need to download the it2check script manually. 
1. REPL can only run in a Docker container at the moment because it depends on SQLFlow core. Later we may try to extract REPL to a standalone repo and make it communicate to SQLFlow server via GRPC rather than call SQLFLow core directly, thus decoupling it from Docker. We don't need to include `it2check` in the binary until then.
Rodge that.
A user can only run REPL in a Docker container at the moment, so she doesn't have to install gosr. Anyway, it's great not to have to depend on another CLI tool, I'll fix this asap.
It seems `UnparseURL` is a private function of `database` pkg, can be `unparseURL`?
Good catch! I will file a PR to fix this.
seems `getEnv` is not used?
`getEnv` is still in use by code in this branch, so, while I am removing `log.go`, where `getEnv` is defined, I had to move `getEnv` to this new file `testing.go`. But we will likely be able to remove this `testing.go` after the merge of https://github.com/sql-machine-learning/sqlflow/pull/1494
Is there a way to add test to cover wokflow/pod pending branches?
I see, thanks~
May we have a comment explaining what "fast" means?
So? So this submitter depends on TF 2.0?
I don't see where this class is used in this PR. Is it used somewhere else?
It's used in this PR at: https://github.com/sql-machine-learning/sqlflow/pull/1505/files#diff-f445d670a7b7e5c8fa3d0e501acbecb1R122
In https://github.com/sql-machine-learning/sqlflow/pull/1505/files#diff-f445d670a7b7e5c8fa3d0e501acbecb1R122, the hook is only used if current installed Tensorflow version >= 2
Please add the facts to the comment, so others could know about it. Thanks.
Good point, will do that in the next PR.

`trainning/tunning` to `training/tuning`. GitHub doesn't show diff rightly on my browser.
`buliding` to `building`
Why need a `MockURL` function, when using it, we may not know what database type we are connecting to.
When I go through the codebase, I noticed some unit tests that just need a mockup URL. So I simply added the function database.MockURL().  You are right - we should check if we can remove it later after some code changes.
Maybe it's meanful to rename to `TestGetPodLogsStress` .
clean up.
After #1512 merged, please use `Fetch` API to check the workflow works well and not only check the workflowID.
How about featurederivation => feature?
Sounds good, will do that in next PR.
Do you want to replace `;` with `|`?
How comes the file `katib_xgb_submitter.py`?
This is a design issue that I hope to have a discussion here.  I am trying to find a way to pass the `IR` of the input sql query to each Katib pod. 

One is to use sqlflow generate the submitter in the Katib pod when it is started, which is something like `katib_xgb_submitter.py`. Then we execute this python program in the pod and train the model.  So the command to generate submitter program should be something like `sqlflow "select * from ..."` ? 

The second way is to ` repl -m "select * from ..." | python sqlflow_submitter/couler/katib/train.py  `. However, we should be careful here since Katib will append tuning hyperparameters to the command line. The final command will be `repl -m "select * from ..." | python sqlflow_submitter/couler/katib/train.py --num_round 60 --max_depth 3`. We need to make sure `num_round` and `max_depth` are passed to the train.py correctly.


What does `repl -m` mean? If you want to generate the IR proto message in text format, I believe it's `repl -parse`.

`python sqlflow_submitter/couler/katib/xgboost_train.py`
=>
`python -m sqlflow_submitter.katib.xgboost.train`
I think there is only one file `pkg/sql/codegen/couler/codegen.go` to generate the Couler Program. Why there are two files that can generate the Couler Program?
I prefer to keep the name to `couler.katib.train`
Maybe we can add attribute `range.max_depth=[2, 10]` in the demo so that users can know it's an auto hyperparameter search job.

For katib in couler, it may also serve other applications. So we design a unique API for each application since their parameters may be quite different. 
It may be a way to label it is a katib training job. However, the concept of auto model training is that users need not specify the range for any parameter, we need to fill default value instead.

I still do not find a good way to label it is a katib training job in sql statement. Any suggestions?
`couler.sqlflow.train` seems a general module to train all sqlflow models, maybe `couler.sqlflow.katib.train` ?
Which one does this design doc choice?
I prefer the second one,  consider the following SQL program:
``` 
create table tmp_t as (...)
select * from tmp_t to train ...
```

The `features` field depends on the [Feature Derivation](https://github.com/sql-machine-learning/sqlflow/blob/develop/doc/design/feature_derivation.md ) which read some table data from `tmp_t`, so we should generate the IR at the step container running instead of generating the Coulr program.


> In the SQLFlow submitter, it invokes `couler.sqlflow.train`:

I'm confused about this, `SQLFlow submitter` should like tensorflow/xgboost training/prediction program, why invokes a Couler step function ?
Maybe we can use env to label it, like `SQLFLOW_XGBOOST_SUBMITTER=katib`
Now I am following the first approach. I am fine with the other one.
Fine with me.
The TODO list can be an issue like: https://github.com/sql-machine-learning/sqlflow/issues/1066 
`couler.sqlflow.katib.train` ?
To avoid type asserting twice.
```go
if ss, ok := e.Value.(string); ok {
    s = append(s, ss)
}
```
The bug here is never triggered because the control flow never passes the condition check.
I think the fix should be: do not add default validation select, and if validation select is empty, do not run the validation.
The aim of the commit is to remove useless(and buggy) code, which does not change any logic. What you suggest is another topic that slightly changes users' experience. How about addressing these two requirements separately? The latter can be provided in another pull request after some discussion.
If we agree with "do not add default validation select", then some changes made in this PR need to be reverted once we merged this PR. I recommend close this PR and file another PR to directly enhance this feature.
1. Feature field **doesn't** exist
2. Error strings should not be capitalized https://github.com/golang/go/wiki/CodeReviewComments#error-strings
ditto
Why updating this line?
Why we are not verifying the label field of the trainSQL using prediction?
Removing, it's for debug.
Predict SQL may not select the label column in the SELECT statement, we need only verify the feature columns only in that case.
It seems we need to define a named variable here.
Do all the statements in a SQL program share the same temporary dir?
Do we need LoadModel anymore? How about deleting it?
Yes.
Done
If there are more than one `train` statements in the program, may the first one interfere with the second one? Will the checkpoints of the 1st `train` remains in the `model_save` directory?
I agree with @shendiaomo. Each train/pred SQL should have exactly one working directory, and it is separate from other SQL's working directory.
Thanks for this information, @shendiaomo @tonyyang-svail, done updating.
It seems that we have to manually remove the temp dir in every return site in the loop 😓
It's more easy to get the `repl` and parse jar file to use the following command instead of checkout `Dockerfile`:

```bash
> docker run --rm -it -v $PWD:/opt/output` sqlflow/sqlflow cp -r /usr/local/bin/repl /opt/sqlflow-parser/parser-1.0-SNAPSHOT-jar-with-dependencies.jar /opt/output
```
TODO comment needs to be followed by an explanation of what there is to do: http://google.github.io/styleguide/pyguide.html#312-todo-comments
Done.
@typhoonzero  I am curious why the original Python code is written in this way.
We don't need `LABEL` here because it can only appear in a training clause.
Maybe I just kept the testing code when I trying to get the feature sample as well as predict results, anyway this is a cool fix.
It seems these are not for test, is it?
Great catch!
@terrytangyuan Should I revert these changes in `template_elasticdl.go`?
Yes, revert them for now. We also need to change the namings in ElasticDL accordingly in order to make this codegen work.
What does `a.txt` and `b.txt` used for? Please remove them if only for debugging.
Sorry I should have deleted them.  They were for debugging.
Is this sqlflow pip package actually built from pysqlflow repo?
Yes, push a new tag of pysqlflow by [make release](https://github.com/sql-machine-learning/pysqlflow#release), so that PyPI would build a pip package with the new tag.

In https://github.com/sql-machine-learning/sqlflow/pull/1587, I am renaming Analyze into Explain. How about we rename this function `explain`?
How about renaming analyzeFiller into explainFiller?
I'll fix it in the next PR.
I'll fix it in the next PR.
update the comment in this line too?
Rename this file to `template_explain.go`?
explainr -> explainer?
Maybe this comment is suitable for the current implementation.
It seems that each step of this loop waits for 3 seconds. So, 1800 steps take 90 mins, not 30 mins. Should we further reduce the number of steps here down to 120/3 = 40?
Maybe add some comments to ensure we won't change it back?
The "old" go files will be removed later? And will these tests be removed then?
Yes, after verifying that the new one works, I plan to remove the tests.
bzip2 is in Ubuntu 18.04 by default.
Since this interface implements `ir.Executor`, it seems its name should be `SubmitterExecutor`, or, simply `Executor`? Also, a *submitter* is a Python program converted from a SQL statement; it doesn't make sense for a Go interface being named *submitter*.
Should we move `ir.Executor` out from the package `ir` into `executor`? An IR is not executable, only the submitter is executable.  Because only submitters are executable, we don't need the long name `SubmitterExecutor`, but `Executor` is good enough.

Also, should we not to create package `submitter` and close this PR, but open another PR to create an `executor` package? In that way, we could put this `SubmitterExecutor` (or `Executor`) and `ir.Executor` into the same pacakge.
I am not sure why would we need to build a registry here? If we want to map the name of a submitter type into a SubmitterExecutor, or, simply Executor, implementation, we could use a map.

```go
func NewExecutor(submitter_type string) *Executor {
    m := map[string]func()*Executor {
        "tensorflow": newTensorFlowExecutor,
        "xgboost": newXGBoostExecutor
    }
    if ex, ok := m[submitter_type]; ok {
        return ex
    }
    log.Fatalf("NewExecutor: unknown submitter type %s", submitter_type)
}
```
Still, I have a question in my mind -- do we need multiple types of executors? After all, whatever AI APIs a submitter calls, it is a normal Python program. Does that mean we don't need to distinguish the `submitter_type`?
> RunKatib generates Couler Katib program

RunKatib generates Couler Katib Step

What to do for `PredictStmt` and `ExplainStmt`?
Also check `fullAttrValidator` ?
Use a static map and remove `SubmitterRegister`, `pai_submitter.go:init()` should be simpler I think.
It just used to be consistent with the current implementation suck as `pai_submitter.go`, it used `init()` to register the submitter.   I would clean up the submitters in #1610 .
I agree with rename to `Executor` and we can move them to `pkg/step` package.

In another, the current implementation, `Submitter` interface embedded with`ir.Executor`, `pai_submitter` implement `Submitter` interface, I think we can move `Executor` from `ir` to `step` package, and add `PAIExecutor`, `AlisaExecutor` to implement the `Executor` interface.

Good idea, maybe we can move to `step` package, and using `step.Context` to setup an `Executor`:

``` golang
package step
type Executor interface {
    setup(ctx *Context)
    ExecuteTrain(ts *ir.TrainStmt)
    ExecutePredict(ts *ir.PredictStmt)
    ExecuteExplain(es *ir.ExplainStmt)
    GetTrainStmtFromModel() bool
}
```
> I am not sure why would we need to build a registry here?

All the submitters don't need to edit the `submitter.go` and only add one `init()` function to register itself, such as:

``` golang
# pai_submitter.go
func init() { Register("pai", &paiSubmitter{}) }
```

> Still, I have a question in my mind -- do we need multiple types of executors? After all, whatever AI APIs a submitter calls, it is a normal Python program. Does that mean we don't need to distinguish the submitter_type?

For my opinion, we need the different `submitter_type`, `codegen` can generate a Python program, but we need different  submitter to run the AI task, for example, TensorFlow codegen would generate Tensorflow Estimator Program, we can run it by `python train.py` simply, but in the production environment, we also need to  
- submite it as a PAI-Tensorflow task by `pai --name tensorflow1120 -Djobname=sqlflow-train`
- submite it as a PAI-Tensorflow task by Alisa Server: `alisa.createTask(...)`
- submite it as a EDL task by `elasticdl`

So we need different submitter implementation, to execute the program.
Yes. I agree.
Yes. BTW, an interface doesn't contain unexported methods like `setup`. We either remove it or rename it into `Setup`.
Or, maybe `paiExecutor`, `alisaExecutor`, and `NewExecutor(submitter_type string)`.
would rename it to `Setup`.
I see. The model_fn of the Estimator program can come from the model zoo. The Estimator program, or the submitter, is from a codegen. And we need a tool (in order to differentiate from the existing concept submitter, let us use the name runner) to start the Estimator program.

How about we do this -- the submitter program contains the Estimator and its runner.  For example, `pkg/step/codegen/pai.go` generates a Python submitter program which includes an Estimator class whose model_fn is from a model zoo and runs the Estimator class using PAI Python API or the `pai` command-line tool.
How about this -- let's have pacakge `pkg/step/codegen`, which contains several implementations of the `CodeGen` interface:

```go
type CodeGen interface {
    Train(*ir.TrainStmt) io.Reader
    Predict(*ir.PredictStmt) io.Reader
    Explain(*ir.ExplainStmt) io.Reader
    Evaluate(*ir.EvaluateStmt) io.Reader
}
```

Each method in the interface returns a Python program, known as the *submitter program*, as a string, which can be read out from the `io.Reader`.

Each implementation, for example, `elasticDLCodeGen`, should have corresponding function `newElasticDLCodeGen`, which can do setup/initialization work.  This is why the `Executor.setup` in https://github.com/sql-machine-learning/sqlflow/pull/1610#discussion_r362692562 is not needed.

To execute a submitter program, we just need to call `os/exec.Cmd`.

We could also have a `step.NewCodeGen(submitter_type string)` that instantiate an implementation.  So, the `cmd/step` could simply call

```go
cg := step.NewCodeGen(os.Getenv("SQLFLOW_SUBMITTER_TYPE"))
cmd := exec.Cmd("python")
cmd.Stdin = cg.Train(train_stmt_ir)
cmd.Run()
```

It is the responsibility of the submitter program to call ElasticDL API, or PAI, or Alps API to submit distributed computing jobs.
The original name `targetFeatureColumnMap` refers to Tensorflow feature column, maybe it's better than `ColumnMap`?
I see. I will follow your suggestion and change it back
clean up?
Is there a way to avoid passing `hdfs_` in all subsequent calls? Is it a good idea to wrap `hive/hdfs*` in a single struct?
Will try to refactor this in incoming PRs, also need to be done in `predict.py`
Should we tag this commit and refer to it by the tag name?
We'll move on to use the model Docker image instead of installing it, so just keep it when model zoo is done.
Please polish the `Switch` code:

``` golang
case *ir.StandardSQL, *ir.PredictStmt, *ir.ExplainStmt:
    ....
case *ir.TrainStmt:
    ...
```
Can using [testingMySQLURL](https://github.com/sql-machine-learning/sqlflow/blob/develop/pkg/database/testing.go#L85) instead of a hardcode `mysql.Config`
How about using  the existing code to reduce the code: https://github.com/sql-machine-learning/sqlflow/blob/0d60f92538c896e61ef869b98773540a9e019c1f/pkg/sql/codegen/xgboost/codegen.go#L47-L56
I am afraid we might not want to create a new file to host this function.  Also, I am not sure if we need this function; it's used only twice.  Adding this function creates more lines of code than not to have it.
Can we don't skip over the parser and call the lexer directly?  In my previous PRs, I made the `parseSQLStatement` in extended_syntax.y able to return index as the external parsers. I think we can use the ability to get rid of the necessity to call the lexer directly.
I was trying to use the return index from extended_syntax.y but failed at the first attempt.

Consider we parsing `to train with ... label l into some_table; select * from some_other_table`. The extended syntax parser will return an error indexed at the character `s` of `select`. So we should try to parse the string before the error index (i.e. `to train with ... label l into some_table; `), and this time the parsing is successful. To put this logic into code, we have

```go
pr, idx, err := parseSQLFlowStmt(statements)

if err != nil {
    pr, _, err := parseSQLFlowStmt(statements[:idx])
    if err != nil {
        return nil, err
    }
    return pr, err
}

return pr, err
```

However, this logic fails on cases like `to train a with a = b label c into d select * from e`. Our parser won't be raising error while it should be.
Update:

One solution I can think of is to make the extended syntax parser incapable of recognizing `;`, meaning parsing `to train a with a = b label c into d;` will return an error at `;` (this behavior is consistent with Hive parser and Calcite parser).

So when parsing `to train a with a = b label c into d; select * from e;`, the extended syntax parser will return an error indexed at the character `;`. So we check if the index is pointed at `;`, if so, we should try to parse the string before the error-index (i.e. `to train a with a = b label c into d`), and this time the parsing is successful. To put this logic into code, we have

```go
pr, idx, err := parseSQLFlowStmt(statements)

if statements[idx] == ';' {
    pr, _, err := parseSQLFlowStmt(statements[:idx])
    if err != nil {
        return nil, err
    }
    return pr, err
}

return pr, err
``` 

And this logic will also capture incorrect statements like `to train a with a = b label c into d select * from e`.
If we expect our parser errors with `to train a with a = b label c into d select * from e` as we want a `;` between `into d` and `select`, we can simply change the rule `end_of_stmt` to must have a `;` from that `;` is optional.
MYSQL => MySQL
All-in-one => all-in-one
SQLFLOW => SQLFlow
Please remove this line as the comment: https://github.com/sql-machine-learning/sqlflow/pull/1632#issuecomment-571648841
Thanks @Yancey1989 .  I am doing this quick change and merge.
A comment starts with a single # please.
Similar to the above comment. `# Install configurable-http-proxy`.
Can use one `RUN` line to install `npm` and `configurable-http-proxy`:

``` bash
RUN apt-get -y install npm && \
    npm install -g configurable-http-proxy
```

Ref [Dockerfile Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices) :
> Split long or complex RUN statements on multiple lines separated with backslashes to make your Dockerfile more readable, understandable, and maintainable.

Prefer auto since katib may have a different name in the future.
This function already exists, named URL()
Duplicated definition as in ir_generator_test.go
This function duplicates with function `ParseOneStatement` in `parser.go`.
Thanks for reminding me.
Thanks for pointing it out!
Removed.
@wangkuiyi originally mentioned the following, I am the one writing it down.

"
The design flaw of https://github.com/sql-machine-learning/sqlflow/pull/1626#discussion_r363575099 is it assumes upper-level logic knows the implementation details of the lower-level.

For a parser, there are four levels of logic:
1. syntax - parser
1. lexical - lexer
1. rune - Unicode
1. bytes/characters

While https://github.com/sql-machine-learning/sqlflow/pull/1626#discussion_r363575099 is suggesting code on level 1 access the logic of level 4.
"
I believe the default Docker image tag is `latest`, can you mention why using a specified Docker tag?
If it's the same as `defaultSubmitter` can just remove it?
maybe replace with https://golang.org/pkg/archive/tar/ later.
`CFJSONString` seems not telling it's configuring the cluster information.
Good point, I would not use the `achive` package here just because the example code is too long: https://golang.org/pkg/archive/tar/#example__minimal
I will implement some helper function of `achive` in the future so that the `alisaSubmitter` code can be more clearly.

`return cli.Bucket(bucketName)`
`defer f.Close()`
Use field `Project` in cfg.
Could you add a comment on this change? For example,

```
# NOTE(typhoonzero): `sudo: required` fixes "maven build fails with ACCESS DENIED".
# ref: https://github.com/travis-ci/travis-ci/issues/6593#issuecomment-417752102
```
Should call it `is_premade_estimator`.  A model is Keras model if it's not an `Estimator` does not make sense, even though we only support Keras and Estimators
`is_estimator` is better, there may be some models in `sqlflow_models` that implement the estimator interface
Maybe we can add these in `travis.yaml` so that we can avoid `docker build`

https://github.com/sql-machine-learning/sqlflow/blob/7170c6f2702085961311ce1fb1fcf66bc0363a3a/.travis.yml#L36-L40
> Maybe we can add these in `travis.yaml` so that we can avoid `docker build`
> 
> https://github.com/sql-machine-learning/sqlflow/blob/7170c6f2702085961311ce1fb1fcf66bc0363a3a/.travis.yml#L36-L40

I've tried a bit and it seems that travis lacks some `skip commits` mechanism. Any suggestion for how to do this?
They are different. My function returns 3 values.
Can resue `defaultDockerImage` ?
https://github.com/sql-machine-learning/sqlflow/blob/4646803832cac20b303774eea989182a623520cf/pkg/sql/codegen/couler/codegen.go#L26-L28

And I didn't found where to use it in this PR.

why remove `model.n_classes=2`?
Do we need to return a struct like:

https://github.com/sql-machine-learning/sqlflow/blob/129be40d6e2627a30e7f06aaa8604d872542b6c4/pkg/parser/sqlflow_parser.go#L28-32
Yes, the API should be consistent with 
https://github.com/sql-machine-learning/sqlflow/blob/129be40d6e2627a30e7f06aaa8604d872542b6c4/pkg/parser/sqlflow_parser.go#L113

That is superfluous because the `BoostedTreesClassifier` is only capable of binary classification.
Of course, removing this has nothing to do with performance stability:-)
Maybe we can rename this file to `plotter.py`
I plan to add some common explanation code in this file, `explainer.py` would be more appropriate.
Maybe we need to `assert model.n_cleasses == 2` instead of moving this argument.

I think it's ok without an assertion, all `classifier`s in `tf.estimator` defaults to binary classification.
Is this line duplicated with the newly added line to test/java.sh?
If so, it seems that we only need the line here, but not test/java.sh?
> Is this line duplicated with the newly added line to test/java.sh?

They are not duplicated. The line here is used for building the .jar file in the release image. The line in test/java.sh is used for testing.

This logic is consistent with having two `go generate ./...`s. One in Dockerfile, one in `scripts/test/units.sh`.
Is there an assertion `len(parts) >= 2` ?
can delete this blank line?
Thanks for the fix!
Do you think it is a good idea to define an optional rule 
```
opt_using
: /* empty */  { $$ = ""}
| USING IDENT  { $$ = $2 }
;
```
So that the explain clause is cleaner?
Yes and done.
`explainStmt.Explainer` is actually not used now, maybe add an issue about use the actual value.
Why use `defer` here, the "submit" action should be logged right after the action?
Using `defer` to calculate the duration time.
I think a method should be named with a verb phrase.  `SQLProgram` is a noun. What is the purpose of this method?
This method seems running the IR. This doesn't make sense, because the name of the concept is CodeGen, but not IRRun.  I suggest removing this method.  Instead, we could have another interface `step.Runner`.


All thee methods `Train`, `Explain`, and `Predict` are expecting the same `pb.Session`. It would be a better idea to embed the session as a data member inside the implementation of interface Codegen.  So, users can write

```go
ir, e := parser.ParseUnitProgam(a_sql_stmt) // <- Let's rename ParseSingleStatement to ParseUnitProgram
if e != nil {
    return e
}

cg := NewCodegen(os.Getenv("SQLFLOW_CODEGEN"), session) // <- pass session to New
pg, e := cg.Train(ir) // <- instead of Train
if e != nil {
    return e
}

rn := NewRunner(os.Getenv("SQLFLOW_CODEGEN"), session)
rn.Run(pg)
```

The function `step.Runner.Run` could be

```go
func (rn *Runner) Run(program string) error {
    if rn.codegen != "couler" {
        cmd := exec.Cmd("python")
        cmd.Stdin = strings.NewReader(pg)
        return cmd.Run()
    } 
    return couler.Run(couler.Compile(program))
}
```
I am worrying that the concept of submitter is confusing. In our design doc, submitter means the Python program generated by a codegen.  Here, it seems a kind of mechanism to execute the IR.

Let us follow https://github.com/sql-machine-learning/sqlflow/pull/1703#pullrequestreview-342630202 ASAP to make the followings concepts clear.

1. codegen -- the converter from IR to Python/Couler/etc. programs
1. submitter -- the programs generated from codegen
1. runner -- the mechanism to execute Python/Couler/etc. programs.
Maybe `CoulerCodegen` should be put under `pkg/workflow/codegen.go`. If we need a base interface, current `Codegen` interface should be under `pkg`, and implementations under `pkg/step` and `pkg/workflow` should follow this interface definition.

See: https://github.com/sql-machine-learning/sqlflow/issues/1585
This method generates program from an SQLProgram IR which contains multiple SQL Statment IR, e.g. `couler_codegen.go`,
 
The `ir.SQLProgram` definition: 

https://github.com/sql-machine-learning/sqlflow/blob/f96b5cbd27f728293c3e1159241edb4c305829fb/pkg/sql/ir/ir.go#L64-L66


Thanks for reminding, will do refactor recently.
Will this overwrite the above test's result?
No. They are saved to different files and DNN doesn't support explaining to table now.
Maybe set `result_table=""` to avoid confusing?
Should we make a local call here to print the docstring, other than start a process?
That's somewhat hard to implement because we have to import the classes to get the docstrings. I have investigated several python bindings of golang but they are either too primitive ([go-python](https://github.com/sbinet/go-python)) or not as reliable.
Maybe add a comment that unmarshal can append entries rather than overwrite it: https://golang.org/pkg/encoding/json/#Unmarshal
The package `filepath` is used to deal with different operating system paths, for OSS path, it's always `/`.
Same issue
And maybe add a comment for why use `/` rather than `filepath`.
Hi @MATRIX4284, I am curious why do we need this latest tag? I'd thought the latest is a tag used by default when there is no tag specified. In other words, `sqlflow/sqlflow` equals to `sqlflow/sqlflow:latest`. Am I wrong?
Maybe we need to using the `digest` ID  to make sure the YAML always uses the same version on Kubernetes.
> Note: To make sure the container always uses the same version of the image, you can specify its digest, for example sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2. The digest uniquely identifies a specific version of the image, so it is never updated by Kubernetes unless you change the digest value.

> Note: You should avoid using the :latest tag when deploying containers in production as it is harder to track which version of the image is running and more difficult to roll back properly.

Ref: https://kubernetes.io/docs/concepts/configuration/overview/#container-images

@MATRIX4284 how about using a fixed digest ID to pin the Docker images version?
Is it possible to change this sleep to a while loop that pings the SQLFlow server?
Go's map act like pointer by default, no need to `*`.
Why the warning message is not `cannot found it2check toolkit`?
> Why the warning message is not `cannot found it2check toolkit`?

I believe that code was somewhat temporary that is committed accidentally.
https://github.com/sql-machine-learning/sqlflow/pull/1507/commits/c9388694ef22363f16659fb0d7456d2de8514f92
maybe change `cleanUpModel` to `deleteOSSObject(path)` and call it here too?
There are two OSS bucket configurations here: **Checkpoint Dir** which used in PAI-TF and **Alisa Resource Bucket** which used to store Alisa resource.

Maybe a clearer way is to initialize two `OSSClient` fields in `AlisaSubmitter` to operate OSS objects? 
Maybe use `deleteOSSObject(bucket, path)` should work? 
This function still returns filename if env `workflow_name` does not exist, so the function name `workflow_name` may not telling this detail?
Env variables should be all capitalized, or try not use env to pass parameter?
The same action with `cluster_config`, can refactor here in the future.

We need a comment to explain what the function does.
We need a comment to explain the purpose of applying the regex here.
I don't get the point here. The parameter stmt seems a SQL statement. Why do we need to split it into multiple statements?

Even if we need to, `strings.Split(stmt, ";")` doesn't work, as the character `;` might appear in a string constant. For example,

```sql
SELECT * FROM tbl WHERE a==";";
```
> I don't get the point here. The parameter stmt seems a SQL statement. Why do we need to split it into multiple statements?
> 
> Even if we need to, `strings.Split(stmt, ";")` doesn't work, as the character `;` might appear in a string constant. For example,
> 
> ```sql
> SELECT * FROM tbl WHERE a==";";
> ```

This is an existing problem because `readStmt`  assumes SQL statements are separated by substrings semicolon :
https://github.com/sql-machine-learning/sqlflow/blob/develop/cmd/repl/repl.go#L53-L55

After this change, if the user inputs 
```sql
USE iris; SELECT * FROM table;
```
The statements will work as expected.

I'll find a way to recognize quoted strings
Done.
Done.
I think we need unit test for function execute.
We need unit test for readStmt.
Done.
Does SQL syntax state that `--` plus whitespace indicate the beginning of a comment?
Looks like the parser is depending on the `.err` field on the lexer to determine when to stop. I will go through related documentation on this subject.
The standard syntax only requires double hyphen as the beginning of a comment.

It's a MySQL extension that requires a whitespace after the `--`. Because it also works on standard syntax as well as most SQL dialects, it may be reasonable for SQLFlow to accept this extension, thus making SQLFlow programs with comments portable to all other SQL dialects.
Should we remove these commented lines?
This test case is named `TrainXGBoostOnPAI`.  How is the line related to PAI? Is that `connectAndRunSQL` runs SQL statement by default on PAI?  If so, we need a comment at the end of this line like

```go
// connectAndRunSQL runs statements on PAI by default.
```

Otherwise, we might need other explanatory comments.
How about use a verb phrase as the function name here? `genSubmitter`?
Should we encapsulate L227 ~ L236 into a function named `XGBoostTrainAndSave`, like that on L239, there is `TFTrainAndSave` (better named TensorFlowTrainAndSave`?)
Done and added todo comments
`CaseTrainXGBoostOnPAI` is a sub-test for `TestEnd2EndMaxComputePAI`. Added comments for `TestEnd2EndMaxComputePAI`.
Does this change fix https://github.com/sql-machine-learning/sqlflow/issues/1759 ?
I am a little confused -- why is the label called CSV label? CSV is a file format, right? Should we say `concat_label`?
I see. How about moving the comment `// NOTE: clustering model doesn't have label` to the end of this line?
Here I don't understand -- how comes shape? And why do we need to set the field Shape?
I am not sure what does the phrase *set back* mean?
What is the relationship between label and JSON? Is that XGBoost requires JSON-encoded inputs?
Not really, this is only a feature requested from @Echo9573 to support some time series model training, please refer to: #1715
CSV stands for "Comma Separated Values", since it's some values, I think it's OK to represent the data in the database cell.
It's just used to pass `ir.FieldDesc` to a Python dict object using JSON as the serialization method.
Indeed "set back" is not easy to understand. I was thinking, this function is setting derived column information back to the original IR structure, so it's a "set back", maybe we need a better name. I am updating this to the comment though.
I don't know why Tensorflow only accept shape `[]` for the label, pass `[1]` will cause an error. I'm wondering if we should pass `[None, 1]` because Tensorflow uses `None` to indicate the batch size dimension. I still need to do more tests to confirm this.
Done.
I see. Then `CSVLabel` means `comma-separated value label`, which is ambiguous -- is it a value or a label.  Should we use the name `CaseTrainWithCommaSeparatedLabel`?

If there could be column-separated label and semi-column-separated labels in the future, we might want `ConcatenatedLabel` or `ConcatLabel` instead.
Do you mean `updateLabel` or `deriveLabel` like `deriveColumn`?
Sounds good, will update the naming in next PR.
I prefer `deriveLabel` will update this in the next PR.
Skipping tests that not using mysql
rename to `prepareTestDataOrSkip` ?
`sql.RunSQLProgram` is testing the `sql` package, since below case is already testing `runStmt` maybe we can just remove this test case.
I think it means ''We are skipping mysql tests", the same as https://github.com/sql-machine-learning/sqlflow/blob/b4a186551ff0877c534e9a84d3a51673389e0860/cmd/sqlflowserver/main_test.go#L260-L262
Done.
Done.
Is this line printing a log message? Should we call `log.Print` or just remove it?
`alisaCmd` does uploading code resource and run the submit. How about splitting these two operations to two functions?
Change to `log.Print` or remove this
Why rename `pai_submitter` to `maxcompute_submitter`? I think we should keep the name `maxcompute` always stands for a database driver. And, PAI as one of the execution platform.
It's just because of submitting a PAI job using `odpscmd` instead of the PAI command.
I revert the renaming, can renaming it in the future if we want to submit PAI job in varients ways as as PAI command line.

I renamed it to `uploadResourceAndSubmitAlisaTask`, maybe it's a common function can be used in `ExecuteTrain` , `ExecutePredict` and `ExecuteExplain`
Just used for debugging, I removed it.

Add markdown links to avoid copy-n-paste?
Will the Java gRPC parser support ```"mysql"``` later?
I believe users can click the URL and go to the arXiv page.
Nope. TiDB provided a MySQL parser in Go. :)
Published or Publication?
Not sure if Youtube videos are publications, so I used the word published.
Maybe we don't need to create the user in Dockerfile, please take a look at the comment: https://github.com/sql-machine-learning/sqlflow/pull/1650#issuecomment-580991442 , thanks.

`ResolveSQLProgram` should not take `datasource, modelDir string, loadModel bool` arguments, since it only generates a workflow to run Couler
Done.

https://google.github.io/styleguide/javaguide.html#s3.3.1-wildcard-imports
I am afraid that 12345 is a magic number. Consider that in the future we want to add another gRPC server -- if we allow default port, we might accidentally set its default port to 12345 too and make a conflict.

A safe approach might be that the program `log.Fatal` if there is no valid value of `SQLFLOW_PARSER_SERVER_PORT`.
12345 is a magic number.  Another use of this number is at https://github.com/sql-machine-learning/sqlflow/pull/1792/files#diff-f612dacf52e3192f6479782d99b95e1cR55. Let us either remove it or define a global constant. I think we can remove it.
I suggest we keep only the port environment variable and remove the IP one.

Referring to https://golang.org/pkg/net/?m=all#Dial, we see that this function could return `fmt.Sprintf(":%d", port)` without the IP.  In this case, the Go net package tries to connect to the port bound to any of the network interfaces.
Following my suggestions above, we can remove this function definition.
I am not sure, but I vaguely remember that we usually reuse a gRPC connection for many request/responses, other than establishing the connecting for every remote call.
Sure, I will remove the wildcard imports.
Sure, I will remove all occurrences of "12345" and define `SQLFLOW_PARSER_SERVER_PORT` in the Dockerfile.

> A safe approach might be that the program log.Fatal if there is no valid value of SQLFLOW_PARSER_SERVER_PORT.

Agree.
I will remove it.
Sounds good.
Sure, I will remove this function.
You are right. It is encouraged to reuse a gRPC connection. I will update the code.

ref: https://github.com/grpc/grpc-go/pull/2034/files
Can we do not assume the existence of curl as a dependency?

```go
// Below init function
func TestNETServer_Run(t *testing.T) {
    // Simply check that the server is up and can
    // accept connections.
    conn, err := net.Dial("tcp", ":1123")
    if err != nil {
        t.Error("could not connect to server: ", err)
    }
    defer conn.Close()
}
```
unable => Unable 
Maybe I am wrong, but I am following https://github.com/golang/go/wiki/CodeReviewComments#error-strings where error strings should not be capitalized.
Thanks for the suggestion, I will try out `net.Dial`. I previous attempt on `grpc.Dial` gives nil error while the server doesn't exist.
